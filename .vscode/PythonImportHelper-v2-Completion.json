[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "mkdir",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "get_asgi_application",
        "importPath": "django.core.asgi",
        "description": "django.core.asgi",
        "isExtraImport": true,
        "detail": "django.core.asgi",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "settings",
        "importPath": "django.conf",
        "description": "django.conf",
        "isExtraImport": true,
        "detail": "django.conf",
        "documentation": {}
    },
    {
        "label": "settings",
        "importPath": "django.conf",
        "description": "django.conf",
        "isExtraImport": true,
        "detail": "django.conf",
        "documentation": {}
    },
    {
        "label": "static",
        "importPath": "django.conf.urls.static",
        "description": "django.conf.urls.static",
        "isExtraImport": true,
        "detail": "django.conf.urls.static",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "include",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "home",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "log_click",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "log_star",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "home",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "movie_detail",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "search",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "sasrec",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "kprn",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "general_mf",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "ngcf",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "delete_movie_interaction",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "movie.views",
        "description": "movie.views",
        "isExtraImport": true,
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "get_wsgi_application",
        "importPath": "django.core.wsgi",
        "description": "django.core.wsgi",
        "isExtraImport": true,
        "detail": "django.core.wsgi",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "boto3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "boto3",
        "description": "boto3",
        "detail": "boto3",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "Key",
        "importPath": "boto3.dynamodb.conditions",
        "description": "boto3.dynamodb.conditions",
        "isExtraImport": true,
        "detail": "boto3.dynamodb.conditions",
        "documentation": {}
    },
    {
        "label": "Attr",
        "importPath": "boto3.dynamodb.conditions",
        "description": "boto3.dynamodb.conditions",
        "isExtraImport": true,
        "detail": "boto3.dynamodb.conditions",
        "documentation": {}
    },
    {
        "label": "Key",
        "importPath": "boto3.dynamodb.conditions",
        "description": "boto3.dynamodb.conditions",
        "isExtraImport": true,
        "detail": "boto3.dynamodb.conditions",
        "documentation": {}
    },
    {
        "label": "Attr",
        "importPath": "boto3.dynamodb.conditions",
        "description": "boto3.dynamodb.conditions",
        "isExtraImport": true,
        "detail": "boto3.dynamodb.conditions",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "MessagesPlaceholder",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "SystemMessagePromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "HumanMessagePromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain.schema.output_parser",
        "description": "langchain.schema.output_parser",
        "isExtraImport": true,
        "detail": "langchain.schema.output_parser",
        "documentation": {}
    },
    {
        "label": "RunnablePassthrough",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "RunnablePassthrough",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "RunnablePassthrough",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "RunnablePassthrough",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "RunnablePassthrough",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "Tool",
        "importPath": "langchain.agents",
        "description": "langchain.agents",
        "isExtraImport": true,
        "detail": "langchain.agents",
        "documentation": {}
    },
    {
        "label": "AgentExecutor",
        "importPath": "langchain.agents",
        "description": "langchain.agents",
        "isExtraImport": true,
        "detail": "langchain.agents",
        "documentation": {}
    },
    {
        "label": "create_react_agent",
        "importPath": "langchain.agents",
        "description": "langchain.agents",
        "isExtraImport": true,
        "detail": "langchain.agents",
        "documentation": {}
    },
    {
        "label": "tool",
        "importPath": "langchain.agents",
        "description": "langchain.agents",
        "isExtraImport": true,
        "detail": "langchain.agents",
        "documentation": {}
    },
    {
        "label": "create_tool_calling_agent",
        "importPath": "langchain.agents",
        "description": "langchain.agents",
        "isExtraImport": true,
        "detail": "langchain.agents",
        "documentation": {}
    },
    {
        "label": "AgentExecutor",
        "importPath": "langchain.agents",
        "description": "langchain.agents",
        "isExtraImport": true,
        "detail": "langchain.agents",
        "documentation": {}
    },
    {
        "label": "ContextualCompressionRetriever",
        "importPath": "langchain.retrievers.contextual_compression",
        "description": "langchain.retrievers.contextual_compression",
        "isExtraImport": true,
        "detail": "langchain.retrievers.contextual_compression",
        "documentation": {}
    },
    {
        "label": "LLMChainFilter",
        "importPath": "langchain.retrievers.document_compressors",
        "description": "langchain.retrievers.document_compressors",
        "isExtraImport": true,
        "detail": "langchain.retrievers.document_compressors",
        "documentation": {}
    },
    {
        "label": "hub",
        "importPath": "langchain",
        "description": "langchain",
        "isExtraImport": true,
        "detail": "langchain",
        "documentation": {}
    },
    {
        "label": "hub",
        "importPath": "langchain",
        "description": "langchain",
        "isExtraImport": true,
        "detail": "langchain",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain_openai",
        "description": "langchain_openai",
        "isExtraImport": true,
        "detail": "langchain_openai",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain_openai",
        "description": "langchain_openai",
        "isExtraImport": true,
        "detail": "langchain_openai",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain_openai",
        "description": "langchain_openai",
        "isExtraImport": true,
        "detail": "langchain_openai",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain_openai",
        "description": "langchain_openai",
        "isExtraImport": true,
        "detail": "langchain_openai",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain_openai",
        "description": "langchain_openai",
        "isExtraImport": true,
        "detail": "langchain_openai",
        "documentation": {}
    },
    {
        "label": "ChatGoogleGenerativeAI",
        "importPath": "langchain_google_genai",
        "description": "langchain_google_genai",
        "isExtraImport": true,
        "detail": "langchain_google_genai",
        "documentation": {}
    },
    {
        "label": "ChatGoogleGenerativeAI",
        "importPath": "langchain_google_genai",
        "description": "langchain_google_genai",
        "isExtraImport": true,
        "detail": "langchain_google_genai",
        "documentation": {}
    },
    {
        "label": "DuckDuckGoSearchRun",
        "importPath": "langchain.tools",
        "description": "langchain.tools",
        "isExtraImport": true,
        "detail": "langchain.tools",
        "documentation": {}
    },
    {
        "label": "DuckDuckGoSearchRun",
        "importPath": "langchain.tools",
        "description": "langchain.tools",
        "isExtraImport": true,
        "detail": "langchain.tools",
        "documentation": {}
    },
    {
        "label": "DuckDuckGoSearchRun",
        "importPath": "langchain.tools",
        "description": "langchain.tools",
        "isExtraImport": true,
        "detail": "langchain.tools",
        "documentation": {}
    },
    {
        "label": "ConversationBufferWindowMemory",
        "importPath": "langchain.memory",
        "description": "langchain.memory",
        "isExtraImport": true,
        "detail": "langchain.memory",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "langchain.embeddings",
        "description": "langchain.embeddings",
        "isExtraImport": true,
        "detail": "langchain.embeddings",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "isExtraImport": true,
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "nan",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "loads",
        "importPath": "json",
        "description": "json",
        "isExtraImport": true,
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "CSVLoader",
        "importPath": "langchain_community.document_loaders.csv_loader",
        "description": "langchain_community.document_loaders.csv_loader",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders.csv_loader",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "product",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "langchain.schema",
        "description": "langchain.schema",
        "isExtraImport": true,
        "detail": "langchain.schema",
        "documentation": {}
    },
    {
        "label": "HumanMessage",
        "importPath": "langchain.schema",
        "description": "langchain.schema",
        "isExtraImport": true,
        "detail": "langchain.schema",
        "documentation": {}
    },
    {
        "label": "HumanMessage",
        "importPath": "langchain.schema",
        "description": "langchain.schema",
        "isExtraImport": true,
        "detail": "langchain.schema",
        "documentation": {}
    },
    {
        "label": "SystemMessage",
        "importPath": "langchain.schema",
        "description": "langchain.schema",
        "isExtraImport": true,
        "detail": "langchain.schema",
        "documentation": {}
    },
    {
        "label": "AIMessage",
        "importPath": "langchain.schema",
        "description": "langchain.schema",
        "isExtraImport": true,
        "detail": "langchain.schema",
        "documentation": {}
    },
    {
        "label": "HumanMessage",
        "importPath": "langchain.schema",
        "description": "langchain.schema",
        "isExtraImport": true,
        "detail": "langchain.schema",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "UpstageLayoutAnalysisLoader",
        "importPath": "langchain_upstage",
        "description": "langchain_upstage",
        "isExtraImport": true,
        "detail": "langchain_upstage",
        "documentation": {}
    },
    {
        "label": "UpstageGroundednessCheck",
        "importPath": "langchain_upstage",
        "description": "langchain_upstage",
        "isExtraImport": true,
        "detail": "langchain_upstage",
        "documentation": {}
    },
    {
        "label": "ChatUpstage",
        "importPath": "langchain_upstage",
        "description": "langchain_upstage",
        "isExtraImport": true,
        "detail": "langchain_upstage",
        "documentation": {}
    },
    {
        "label": "UpstageEmbeddings",
        "importPath": "langchain_upstage",
        "description": "langchain_upstage",
        "isExtraImport": true,
        "detail": "langchain_upstage",
        "documentation": {}
    },
    {
        "label": "ChatUpstage",
        "importPath": "langchain_upstage",
        "description": "langchain_upstage",
        "isExtraImport": true,
        "detail": "langchain_upstage",
        "documentation": {}
    },
    {
        "label": "UpstageEmbeddings",
        "importPath": "langchain_upstage",
        "description": "langchain_upstage",
        "isExtraImport": true,
        "detail": "langchain_upstage",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "difflib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "difflib",
        "description": "difflib",
        "detail": "difflib",
        "documentation": {}
    },
    {
        "label": "GoogleSearchAPIWrapper",
        "importPath": "langchain.utilities",
        "description": "langchain.utilities",
        "isExtraImport": true,
        "detail": "langchain.utilities",
        "documentation": {}
    },
    {
        "label": "WebResearchRetriever",
        "importPath": "langchain.retrievers.web_research",
        "description": "langchain.retrievers.web_research",
        "isExtraImport": true,
        "detail": "langchain.retrievers.web_research",
        "documentation": {}
    },
    {
        "label": "StreamingStdOutCallbackHandler",
        "importPath": "langchain.callbacks.streaming_stdout",
        "description": "langchain.callbacks.streaming_stdout",
        "isExtraImport": true,
        "detail": "langchain.callbacks.streaming_stdout",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "get_interacted_movie_ids",
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "get_history_with_newline",
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "get_sasrec_recomm_mids",
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "get_landing_page_recommendation",
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "get_user_logs_df",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_username_sid",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_username_sid",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "log_tracking",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_user_logs_df",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_interacted_movie_dicts",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "add_past_rating",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "add_rank",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_username_sid",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_user_logs_df",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "log_tracking",
        "importPath": "movie.utils",
        "description": "movie.utils",
        "isExtraImport": true,
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "END",
        "importPath": "langgraph.graph",
        "description": "langgraph.graph",
        "isExtraImport": true,
        "detail": "langgraph.graph",
        "documentation": {}
    },
    {
        "label": "StateGraph",
        "importPath": "langgraph.graph",
        "description": "langgraph.graph",
        "isExtraImport": true,
        "detail": "langgraph.graph",
        "documentation": {}
    },
    {
        "label": "StateGraph",
        "importPath": "langgraph.graph",
        "description": "langgraph.graph",
        "isExtraImport": true,
        "detail": "langgraph.graph",
        "documentation": {}
    },
    {
        "label": "END",
        "importPath": "langgraph.graph",
        "description": "langgraph.graph",
        "isExtraImport": true,
        "detail": "langgraph.graph",
        "documentation": {}
    },
    {
        "label": "StateGraph",
        "importPath": "langgraph.graph",
        "description": "langgraph.graph",
        "isExtraImport": true,
        "detail": "langgraph.graph",
        "documentation": {}
    },
    {
        "label": "END",
        "importPath": "langgraph.graph",
        "description": "langgraph.graph",
        "isExtraImport": true,
        "detail": "langgraph.graph",
        "documentation": {}
    },
    {
        "label": "SearchManager",
        "importPath": "llmrec.utils.kyeongchan.search_engine",
        "description": "llmrec.utils.kyeongchan.search_engine",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.search_engine",
        "documentation": {}
    },
    {
        "label": "SearchManager",
        "importPath": "llmrec.utils.kyeongchan.search_engine",
        "description": "llmrec.utils.kyeongchan.search_engine",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.search_engine",
        "documentation": {}
    },
    {
        "label": "SearchManager",
        "importPath": "llmrec.utils.kyeongchan.search_engine",
        "description": "llmrec.utils.kyeongchan.search_engine",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.search_engine",
        "documentation": {}
    },
    {
        "label": "MysqlClient",
        "importPath": "clients",
        "description": "clients",
        "isExtraImport": true,
        "detail": "clients",
        "documentation": {}
    },
    {
        "label": "MysqlClient",
        "importPath": "clients",
        "description": "clients",
        "isExtraImport": true,
        "detail": "clients",
        "documentation": {}
    },
    {
        "label": "MysqlClient",
        "importPath": "clients",
        "description": "clients",
        "isExtraImport": true,
        "detail": "clients",
        "documentation": {}
    },
    {
        "label": "MysqlClient",
        "importPath": "clients",
        "description": "clients",
        "isExtraImport": true,
        "detail": "clients",
        "documentation": {}
    },
    {
        "label": "MysqlClient",
        "importPath": "clients",
        "description": "clients",
        "isExtraImport": true,
        "detail": "clients",
        "documentation": {}
    },
    {
        "label": "MysqlClient",
        "importPath": "clients",
        "description": "clients",
        "isExtraImport": true,
        "detail": "clients",
        "documentation": {}
    },
    {
        "label": "HumanMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "AnyMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "SystemMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "HumanMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "AIMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "ChatMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "BaseMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "FunctionMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "HumanMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "BaseMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "SystemMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "HumanMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "PromptTemplates",
        "importPath": "llmrec.utils.kyeongchan.prompts",
        "description": "llmrec.utils.kyeongchan.prompts",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.prompts",
        "documentation": {}
    },
    {
        "label": "operator",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "operator",
        "description": "operator",
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "SqliteSaver",
        "importPath": "langgraph.checkpoint.sqlite",
        "description": "langgraph.checkpoint.sqlite",
        "isExtraImport": true,
        "detail": "langgraph.checkpoint.sqlite",
        "documentation": {}
    },
    {
        "label": "queryAnalysis",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "queryAnalRouter",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "WebSearchNode",
        "importPath": "websearch",
        "description": "websearch",
        "isExtraImport": true,
        "detail": "websearch",
        "documentation": {}
    },
    {
        "label": "ExpertisedNode",
        "importPath": "expertised",
        "description": "expertised",
        "isExtraImport": true,
        "detail": "expertised",
        "documentation": {}
    },
    {
        "label": "ChatMessagesNode",
        "importPath": "chat",
        "description": "chat",
        "isExtraImport": true,
        "detail": "chat",
        "documentation": {}
    },
    {
        "label": "TicketNode",
        "importPath": "ticket",
        "description": "ticket",
        "isExtraImport": true,
        "detail": "ticket",
        "documentation": {}
    },
    {
        "label": "QANode",
        "importPath": "qa",
        "description": "qa",
        "isExtraImport": true,
        "detail": "qa",
        "documentation": {}
    },
    {
        "label": "qaRouter",
        "importPath": "qa",
        "description": "qa",
        "isExtraImport": true,
        "detail": "qa",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain.chat_models",
        "description": "langchain.chat_models",
        "isExtraImport": true,
        "detail": "langchain.chat_models",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain.chat_models",
        "description": "langchain.chat_models",
        "isExtraImport": true,
        "detail": "langchain.chat_models",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain.chat_models",
        "description": "langchain.chat_models",
        "isExtraImport": true,
        "detail": "langchain.chat_models",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain.prompts.prompt",
        "description": "langchain.prompts.prompt",
        "isExtraImport": true,
        "detail": "langchain.prompts.prompt",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "langchain.embeddings.openai",
        "description": "langchain.embeddings.openai",
        "isExtraImport": true,
        "detail": "langchain.embeddings.openai",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "retry",
        "description": "retry",
        "isExtraImport": true,
        "detail": "retry",
        "documentation": {}
    },
    {
        "label": "default_timer",
        "importPath": "timeit",
        "description": "timeit",
        "isExtraImport": true,
        "detail": "timeit",
        "documentation": {}
    },
    {
        "label": "GraphDatabase",
        "importPath": "neo4j",
        "description": "neo4j",
        "isExtraImport": true,
        "detail": "neo4j",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "DynamoDBClient",
        "importPath": "db_clients.dynamodb",
        "description": "db_clients.dynamodb",
        "isExtraImport": true,
        "detail": "db_clients.dynamodb",
        "documentation": {}
    },
    {
        "label": "DynamoDBClient",
        "importPath": "db_clients.dynamodb",
        "description": "db_clients.dynamodb",
        "isExtraImport": true,
        "detail": "db_clients.dynamodb",
        "documentation": {}
    },
    {
        "label": "DynamoDBClient",
        "importPath": "db_clients.dynamodb",
        "description": "db_clients.dynamodb",
        "isExtraImport": true,
        "detail": "db_clients.dynamodb",
        "documentation": {}
    },
    {
        "label": "DynamoDBClient",
        "importPath": "db_clients.dynamodb",
        "description": "db_clients.dynamodb",
        "isExtraImport": true,
        "detail": "db_clients.dynamodb",
        "documentation": {}
    },
    {
        "label": "DynamoDBClient",
        "importPath": "db_clients.dynamodb",
        "description": "db_clients.dynamodb",
        "isExtraImport": true,
        "detail": "db_clients.dynamodb",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "llmrec_hyeonwoo",
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "isExtraImport": true,
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_namjoon",
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "isExtraImport": true,
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_kyeongchan",
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "isExtraImport": true,
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_minsang",
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "isExtraImport": true,
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_soonhyeok",
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "isExtraImport": true,
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "isExtraImport": true,
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "JsonResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "StreamingHttpResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "JsonResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "HttpResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "JsonResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "JsonResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "JsonResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "redirect",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "csrf_exempt",
        "importPath": "django.views.decorators.csrf",
        "description": "django.views.decorators.csrf",
        "isExtraImport": true,
        "detail": "django.views.decorators.csrf",
        "documentation": {}
    },
    {
        "label": "csrf_exempt",
        "importPath": "django.views.decorators.csrf",
        "description": "django.views.decorators.csrf",
        "isExtraImport": true,
        "detail": "django.views.decorators.csrf",
        "documentation": {}
    },
    {
        "label": "csrf_exempt",
        "importPath": "django.views.decorators.csrf",
        "description": "django.views.decorators.csrf",
        "isExtraImport": true,
        "detail": "django.views.decorators.csrf",
        "documentation": {}
    },
    {
        "label": "get_chain",
        "importPath": "llmrec.utils.gyungah.load_chain",
        "description": "llmrec.utils.gyungah.load_chain",
        "isExtraImport": true,
        "detail": "llmrec.utils.gyungah.load_chain",
        "documentation": {}
    },
    {
        "label": "router",
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "isExtraImport": true,
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "kyeongchan_model",
        "importPath": "llmrec.utils.kyeongchan.get_model",
        "description": "llmrec.utils.kyeongchan.get_model",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.get_model",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "GraphState",
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "isExtraImport": true,
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "log_llm",
        "importPath": "llmrec.utils.log_questions",
        "description": "llmrec.utils.log_questions",
        "isExtraImport": true,
        "detail": "llmrec.utils.log_questions",
        "documentation": {}
    },
    {
        "label": "get_results",
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "isExtraImport": true,
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "KPRN",
        "importPath": "pytorch_models.kprn",
        "description": "pytorch_models.kprn",
        "isExtraImport": true,
        "detail": "pytorch_models.kprn",
        "documentation": {}
    },
    {
        "label": "predict",
        "importPath": "pytorch_models.kprn",
        "description": "pytorch_models.kprn",
        "isExtraImport": true,
        "detail": "pytorch_models.kprn",
        "documentation": {}
    },
    {
        "label": "my_collate",
        "importPath": "pytorch_models.kprn",
        "description": "pytorch_models.kprn",
        "isExtraImport": true,
        "detail": "pytorch_models.kprn",
        "documentation": {}
    },
    {
        "label": "sort_batch",
        "importPath": "pytorch_models.kprn",
        "description": "pytorch_models.kprn",
        "isExtraImport": true,
        "detail": "pytorch_models.kprn",
        "documentation": {}
    },
    {
        "label": "format_paths",
        "importPath": "pytorch_models.kprn.kprn_data.format",
        "description": "pytorch_models.kprn.kprn_data.format",
        "isExtraImport": true,
        "detail": "pytorch_models.kprn.kprn_data.format",
        "documentation": {}
    },
    {
        "label": "find_paths_user_to_movies",
        "importPath": "pytorch_models.kprn.kprn_data.path_extraction",
        "description": "pytorch_models.kprn.kprn_data.path_extraction",
        "isExtraImport": true,
        "detail": "pytorch_models.kprn.kprn_data.path_extraction",
        "documentation": {}
    },
    {
        "label": "BPRMFTrainer",
        "importPath": "pytorch_models.general_mf.models.neural_bpr_MF",
        "description": "pytorch_models.general_mf.models.neural_bpr_MF",
        "isExtraImport": true,
        "detail": "pytorch_models.general_mf.models.neural_bpr_MF",
        "documentation": {}
    },
    {
        "label": "BPRMFTrainer",
        "importPath": "pytorch_models.general_mf.models.neural_bpr_MF",
        "description": "pytorch_models.general_mf.models.neural_bpr_MF",
        "isExtraImport": true,
        "detail": "pytorch_models.general_mf.models.neural_bpr_MF",
        "documentation": {}
    },
    {
        "label": "dgl",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dgl",
        "description": "dgl",
        "detail": "dgl",
        "documentation": {}
    },
    {
        "label": "dgl.function",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dgl.function",
        "description": "dgl.function",
        "detail": "dgl.function",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "pytorch_models.ngcf.model",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytorch_models.ngcf.model",
        "description": "pytorch_models.ngcf.model",
        "detail": "pytorch_models.ngcf.model",
        "documentation": {}
    },
    {
        "label": "NGCF",
        "importPath": "pytorch_models.ngcf.model",
        "description": "pytorch_models.ngcf.model",
        "isExtraImport": true,
        "detail": "pytorch_models.ngcf.model",
        "documentation": {}
    },
    {
        "label": "NGCF",
        "importPath": "pytorch_models.ngcf.model",
        "description": "pytorch_models.ngcf.model",
        "isExtraImport": true,
        "detail": "pytorch_models.ngcf.model",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "importPath": "pytorch_models.ngcf.utility.parser",
        "description": "pytorch_models.ngcf.utility.parser",
        "isExtraImport": true,
        "detail": "pytorch_models.ngcf.utility.parser",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "importPath": "pytorch_models.ngcf.utility.parser",
        "description": "pytorch_models.ngcf.utility.parser",
        "isExtraImport": true,
        "detail": "pytorch_models.ngcf.utility.parser",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "importPath": "pytorch_models.ngcf.utility.parser",
        "description": "pytorch_models.ngcf.utility.parser",
        "isExtraImport": true,
        "detail": "pytorch_models.ngcf.utility.parser",
        "documentation": {}
    },
    {
        "label": "faiss",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss",
        "description": "faiss",
        "detail": "faiss",
        "documentation": {}
    },
    {
        "label": "pytorch_models.ngcf.utility.metrics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "pytorch_models.ngcf.utility.load_data",
        "description": "pytorch_models.ngcf.utility.load_data",
        "isExtraImport": true,
        "detail": "pytorch_models.ngcf.utility.load_data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "pytorch_models.ngcf.utility.load_data",
        "description": "pytorch_models.ngcf.utility.load_data",
        "isExtraImport": true,
        "detail": "pytorch_models.ngcf.utility.load_data",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "isExtraImport": true,
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "pytorch_models.Data.daum.train_test_split",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "DaumMovies",
        "importPath": "movie.models",
        "description": "movie.models",
        "isExtraImport": true,
        "detail": "movie.models",
        "documentation": {}
    },
    {
        "label": "DaumMovies",
        "importPath": "movie.models",
        "description": "movie.models",
        "isExtraImport": true,
        "detail": "movie.models",
        "documentation": {}
    },
    {
        "label": "mf_predictor",
        "importPath": "movie.predictors.mf_predictor",
        "description": "movie.predictors.mf_predictor",
        "isExtraImport": true,
        "detail": "movie.predictors.mf_predictor",
        "documentation": {}
    },
    {
        "label": "ngcf_predictor",
        "importPath": "movie.predictors.ngcf_predictor",
        "description": "movie.predictors.ngcf_predictor",
        "isExtraImport": true,
        "detail": "movie.predictors.ngcf_predictor",
        "documentation": {}
    },
    {
        "label": "get_pop",
        "importPath": "utils.pop_movies",
        "description": "utils.pop_movies",
        "isExtraImport": true,
        "detail": "utils.pop_movies",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "notebooks.kyeongchan_prod2vec.util.data_loader",
        "description": "notebooks.kyeongchan_prod2vec.util.data_loader",
        "isExtraImport": true,
        "detail": "notebooks.kyeongchan_prod2vec.util.data_loader",
        "documentation": {}
    },
    {
        "label": "MetricCalculator",
        "importPath": "notebooks.kyeongchan_prod2vec.util.metric_calculator",
        "description": "notebooks.kyeongchan_prod2vec.util.metric_calculator",
        "isExtraImport": true,
        "detail": "notebooks.kyeongchan_prod2vec.util.metric_calculator",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "notebooks.kyeongchan_prod2vec.util.models",
        "description": "notebooks.kyeongchan_prod2vec.util.models",
        "isExtraImport": true,
        "detail": "notebooks.kyeongchan_prod2vec.util.models",
        "documentation": {}
    },
    {
        "label": "RecommendResult",
        "importPath": "notebooks.kyeongchan_prod2vec.util.models",
        "description": "notebooks.kyeongchan_prod2vec.util.models",
        "isExtraImport": true,
        "detail": "notebooks.kyeongchan_prod2vec.util.models",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "notebooks.kyeongchan_prod2vec.util.models",
        "description": "notebooks.kyeongchan_prod2vec.util.models",
        "isExtraImport": true,
        "detail": "notebooks.kyeongchan_prod2vec.util.models",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "Metrics",
        "importPath": "util.models",
        "description": "util.models",
        "isExtraImport": true,
        "detail": "util.models",
        "documentation": {}
    },
    {
        "label": "RecommendResult",
        "importPath": "util.models",
        "description": "util.models",
        "isExtraImport": true,
        "detail": "util.models",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "util.models",
        "description": "util.models",
        "isExtraImport": true,
        "detail": "util.models",
        "documentation": {}
    },
    {
        "label": "dataclasses",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dataclasses",
        "description": "dataclasses",
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "BaseRecommender",
        "importPath": "src.base_recommender",
        "description": "src.base_recommender",
        "isExtraImport": true,
        "detail": "src.base_recommender",
        "documentation": {}
    },
    {
        "label": "gensim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gensim",
        "description": "gensim",
        "detail": "gensim",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "NoSuchElementException",
        "importPath": "selenium.common.exceptions",
        "description": "selenium.common.exceptions",
        "isExtraImport": true,
        "detail": "selenium.common.exceptions",
        "documentation": {}
    },
    {
        "label": "NoSuchElementException",
        "importPath": "selenium.common.exceptions",
        "description": "selenium.common.exceptions",
        "isExtraImport": true,
        "detail": "selenium.common.exceptions",
        "documentation": {}
    },
    {
        "label": "StaleElementReferenceException",
        "importPath": "selenium.common.exceptions",
        "description": "selenium.common.exceptions",
        "isExtraImport": true,
        "detail": "selenium.common.exceptions",
        "documentation": {}
    },
    {
        "label": "NoSuchElementException",
        "importPath": "selenium.common.exceptions",
        "description": "selenium.common.exceptions",
        "isExtraImport": true,
        "detail": "selenium.common.exceptions",
        "documentation": {}
    },
    {
        "label": "StaleElementReferenceException",
        "importPath": "selenium.common.exceptions",
        "description": "selenium.common.exceptions",
        "isExtraImport": true,
        "detail": "selenium.common.exceptions",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "Service",
        "importPath": "selenium.webdriver.chrome.service",
        "description": "selenium.webdriver.chrome.service",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.service",
        "documentation": {}
    },
    {
        "label": "Service",
        "importPath": "selenium.webdriver.chrome.service",
        "description": "selenium.webdriver.chrome.service",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.service",
        "documentation": {}
    },
    {
        "label": "Service",
        "importPath": "selenium.webdriver.chrome.service",
        "description": "selenium.webdriver.chrome.service",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.service",
        "documentation": {}
    },
    {
        "label": "ChromeDriverManager",
        "importPath": "webdriver_manager.chrome",
        "description": "webdriver_manager.chrome",
        "isExtraImport": true,
        "detail": "webdriver_manager.chrome",
        "documentation": {}
    },
    {
        "label": "ChromeDriverManager",
        "importPath": "webdriver_manager.chrome",
        "description": "webdriver_manager.chrome",
        "isExtraImport": true,
        "detail": "webdriver_manager.chrome",
        "documentation": {}
    },
    {
        "label": "ChromeDriverManager",
        "importPath": "webdriver_manager.chrome",
        "description": "webdriver_manager.chrome",
        "isExtraImport": true,
        "detail": "webdriver_manager.chrome",
        "documentation": {}
    },
    {
        "label": "multiprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Process",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "IntegrityError",
        "importPath": "pymysql.err",
        "description": "pymysql.err",
        "isExtraImport": true,
        "detail": "pymysql.err",
        "documentation": {}
    },
    {
        "label": "markdownx.models",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "markdownx.models",
        "description": "markdownx.models",
        "detail": "markdownx.models",
        "documentation": {}
    },
    {
        "label": "MarkdownxField",
        "importPath": "markdownx.models",
        "description": "markdownx.models",
        "isExtraImport": true,
        "detail": "markdownx.models",
        "documentation": {}
    },
    {
        "label": "django.db.models.deletion",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "django.db.models.deletion",
        "description": "django.db.models.deletion",
        "detail": "django.db.models.deletion",
        "documentation": {}
    },
    {
        "label": "markdown",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "markdown",
        "description": "markdown",
        "detail": "markdown",
        "documentation": {}
    },
    {
        "label": "template",
        "importPath": "django",
        "description": "django",
        "isExtraImport": true,
        "detail": "django",
        "documentation": {}
    },
    {
        "label": "forms",
        "importPath": "django",
        "description": "django",
        "isExtraImport": true,
        "detail": "django",
        "documentation": {}
    },
    {
        "label": "mark_safe",
        "importPath": "django.utils.safestring",
        "description": "django.utils.safestring",
        "isExtraImport": true,
        "detail": "django.utils.safestring",
        "documentation": {}
    },
    {
        "label": "MarkdownxModelAdmin",
        "importPath": "markdownx.admin",
        "description": "markdownx.admin",
        "isExtraImport": true,
        "detail": "markdownx.admin",
        "documentation": {}
    },
    {
        "label": "markdown",
        "importPath": "markdownx.utils",
        "description": "markdownx.utils",
        "isExtraImport": true,
        "detail": "markdownx.utils",
        "documentation": {}
    },
    {
        "label": "markdown",
        "importPath": "markdownx.utils",
        "description": "markdownx.utils",
        "isExtraImport": true,
        "detail": "markdownx.utils",
        "documentation": {}
    },
    {
        "label": "User",
        "importPath": "users.models",
        "description": "users.models",
        "isExtraImport": true,
        "detail": "users.models",
        "documentation": {}
    },
    {
        "label": "User",
        "importPath": "users.models",
        "description": "users.models",
        "isExtraImport": true,
        "detail": "users.models",
        "documentation": {}
    },
    {
        "label": "User",
        "importPath": "users.models",
        "description": "users.models",
        "isExtraImport": true,
        "detail": "users.models",
        "documentation": {}
    },
    {
        "label": "TableExtension",
        "importPath": "markdown.extensions.tables",
        "description": "markdown.extensions.tables",
        "isExtraImport": true,
        "detail": "markdown.extensions.tables",
        "documentation": {}
    },
    {
        "label": "ExtraExtension",
        "importPath": "markdown.extensions.extra",
        "description": "markdown.extensions.extra",
        "isExtraImport": true,
        "detail": "markdown.extensions.extra",
        "documentation": {}
    },
    {
        "label": "highlight",
        "importPath": "pygments",
        "description": "pygments",
        "isExtraImport": true,
        "detail": "pygments",
        "documentation": {}
    },
    {
        "label": "HtmlFormatter",
        "importPath": "pygments.formatters",
        "description": "pygments.formatters",
        "isExtraImport": true,
        "detail": "pygments.formatters",
        "documentation": {}
    },
    {
        "label": "get_lexer_by_name",
        "importPath": "pygments.lexers",
        "description": "pygments.lexers",
        "isExtraImport": true,
        "detail": "pygments.lexers",
        "documentation": {}
    },
    {
        "label": "Post",
        "importPath": "paper_review.models",
        "description": "paper_review.models",
        "isExtraImport": true,
        "detail": "paper_review.models",
        "documentation": {}
    },
    {
        "label": "PostMonthlyPseudorec",
        "importPath": "paper_review.models",
        "description": "paper_review.models",
        "isExtraImport": true,
        "detail": "paper_review.models",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "sparse",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "embed",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "constants.consts",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "constants.consts",
        "description": "constants.consts",
        "detail": "constants.consts",
        "documentation": {}
    },
    {
        "label": "linecache",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "linecache",
        "description": "linecache",
        "detail": "linecache",
        "documentation": {}
    },
    {
        "label": "mean",
        "importPath": "statistics",
        "description": "statistics",
        "isExtraImport": true,
        "detail": "statistics",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "kserve",
        "description": "kserve",
        "isExtraImport": true,
        "detail": "kserve",
        "documentation": {}
    },
    {
        "label": "ModelServer",
        "importPath": "kserve",
        "description": "kserve",
        "isExtraImport": true,
        "detail": "kserve",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "kserve",
        "description": "kserve",
        "isExtraImport": true,
        "detail": "kserve",
        "documentation": {}
    },
    {
        "label": "ModelServer",
        "importPath": "kserve",
        "description": "kserve",
        "isExtraImport": true,
        "detail": "kserve",
        "documentation": {}
    },
    {
        "label": "NGCF",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "NGCF",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "SASRec",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "importPath": "utility.parser",
        "description": "utility.parser",
        "isExtraImport": true,
        "detail": "utility.parser",
        "documentation": {}
    },
    {
        "label": "ngcf_predictor",
        "importPath": "movie.predictors",
        "description": "movie.predictors",
        "isExtraImport": true,
        "detail": "movie.predictors",
        "documentation": {}
    },
    {
        "label": "heapq",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "heapq",
        "description": "heapq",
        "detail": "heapq",
        "documentation": {}
    },
    {
        "label": "metrics",
        "importPath": "pytorch_models.ngcf.utility",
        "description": "pytorch_models.ngcf.utility",
        "isExtraImport": true,
        "detail": "pytorch_models.ngcf.utility",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utility.batch_test",
        "description": "utility.batch_test",
        "isExtraImport": true,
        "detail": "utility.batch_test",
        "documentation": {}
    },
    {
        "label": "early_stopping",
        "importPath": "utility.helper",
        "description": "utility.helper",
        "isExtraImport": true,
        "detail": "utility.helper",
        "documentation": {}
    },
    {
        "label": "django.contrib.auth.models",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "django.contrib.auth.models",
        "description": "django.contrib.auth.models",
        "detail": "django.contrib.auth.models",
        "documentation": {}
    },
    {
        "label": "AbstractUser",
        "importPath": "django.contrib.auth.models",
        "description": "django.contrib.auth.models",
        "isExtraImport": true,
        "detail": "django.contrib.auth.models",
        "documentation": {}
    },
    {
        "label": "django.contrib.auth.validators",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "django.contrib.auth.validators",
        "description": "django.contrib.auth.validators",
        "detail": "django.contrib.auth.validators",
        "documentation": {}
    },
    {
        "label": "django.utils.timezone",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "django.utils.timezone",
        "description": "django.utils.timezone",
        "detail": "django.utils.timezone",
        "documentation": {}
    },
    {
        "label": "UserAdmin",
        "importPath": "django.contrib.auth.admin",
        "description": "django.contrib.auth.admin",
        "isExtraImport": true,
        "detail": "django.contrib.auth.admin",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "django.core.exceptions",
        "description": "django.core.exceptions",
        "isExtraImport": true,
        "detail": "django.core.exceptions",
        "documentation": {}
    },
    {
        "label": "login_view",
        "importPath": "users.views",
        "description": "users.views",
        "isExtraImport": true,
        "detail": "users.views",
        "documentation": {}
    },
    {
        "label": "logout_view",
        "importPath": "users.views",
        "description": "users.views",
        "isExtraImport": true,
        "detail": "users.views",
        "documentation": {}
    },
    {
        "label": "signup",
        "importPath": "users.views",
        "description": "users.views",
        "isExtraImport": true,
        "detail": "users.views",
        "documentation": {}
    },
    {
        "label": "authenticate",
        "importPath": "django.contrib.auth",
        "description": "django.contrib.auth",
        "isExtraImport": true,
        "detail": "django.contrib.auth",
        "documentation": {}
    },
    {
        "label": "login",
        "importPath": "django.contrib.auth",
        "description": "django.contrib.auth",
        "isExtraImport": true,
        "detail": "django.contrib.auth",
        "documentation": {}
    },
    {
        "label": "logout",
        "importPath": "django.contrib.auth",
        "description": "django.contrib.auth",
        "isExtraImport": true,
        "detail": "django.contrib.auth",
        "documentation": {}
    },
    {
        "label": "LoginForm",
        "importPath": "users.forms",
        "description": "users.forms",
        "isExtraImport": true,
        "detail": "users.forms",
        "documentation": {}
    },
    {
        "label": "SignupForm",
        "importPath": "users.forms",
        "description": "users.forms",
        "isExtraImport": true,
        "detail": "users.forms",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "pytz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytz",
        "description": "pytz",
        "detail": "pytz",
        "documentation": {}
    },
    {
        "label": "pymysql",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pymysql",
        "description": "pymysql",
        "detail": "pymysql",
        "documentation": {}
    },
    {
        "label": "create_engine",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "KafkaConsumer",
        "importPath": "kafka",
        "description": "kafka",
        "isExtraImport": true,
        "detail": "kafka",
        "documentation": {}
    },
    {
        "label": "KafkaProducer",
        "importPath": "kafka",
        "description": "kafka",
        "isExtraImport": true,
        "detail": "kafka",
        "documentation": {}
    },
    {
        "label": "wait_for_kafka_broker",
        "importPath": "producer",
        "description": "producer",
        "isExtraImport": true,
        "detail": "producer",
        "documentation": {}
    },
    {
        "label": "download_kprn_model",
        "importPath": "utils.download_models",
        "description": "utils.download_models",
        "isExtraImport": true,
        "detail": "utils.download_models",
        "documentation": {}
    },
    {
        "label": "download_vectordb",
        "importPath": "utils.download_vectordb",
        "description": "utils.download_vectordb",
        "isExtraImport": true,
        "detail": "utils.download_vectordb",
        "documentation": {}
    },
    {
        "label": "get_broker_url",
        "importPath": "utils.kafka",
        "description": "utils.kafka",
        "isExtraImport": true,
        "detail": "utils.kafka",
        "documentation": {}
    },
    {
        "label": "application",
        "kind": 5,
        "importPath": "config.asgi",
        "description": "config.asgi",
        "peekOfCode": "application = get_asgi_application()",
        "detail": "config.asgi",
        "documentation": {}
    },
    {
        "label": "AUTH_USER_MODEL",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "AUTH_USER_MODEL = 'users.User'\nBASE_DIR = Path(__file__).resolve().parent.parent\nTEMPLATES_DIR = BASE_DIR / \"templates\"\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/4.2/howto/deployment/checklist/\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = 'django-insecure-=$#jed1amhyw0c5^%ltvxx)84!coez=h_qtmm5&1ms^#7fbpjq'\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = ['13.209.69.81', '127.0.0.1', 'localhost', '3.36.208.188', '0.0.0.0', 'www.pseudorec.com',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "BASE_DIR = Path(__file__).resolve().parent.parent\nTEMPLATES_DIR = BASE_DIR / \"templates\"\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/4.2/howto/deployment/checklist/\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = 'django-insecure-=$#jed1amhyw0c5^%ltvxx)84!coez=h_qtmm5&1ms^#7fbpjq'\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = ['13.209.69.81', '127.0.0.1', 'localhost', '3.36.208.188', '0.0.0.0', 'www.pseudorec.com',\n                 'pseudorec.com']",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "TEMPLATES_DIR",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "TEMPLATES_DIR = BASE_DIR / \"templates\"\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/4.2/howto/deployment/checklist/\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = 'django-insecure-=$#jed1amhyw0c5^%ltvxx)84!coez=h_qtmm5&1ms^#7fbpjq'\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = ['13.209.69.81', '127.0.0.1', 'localhost', '3.36.208.188', '0.0.0.0', 'www.pseudorec.com',\n                 'pseudorec.com']\n# Application definition",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "SECRET_KEY",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "SECRET_KEY = 'django-insecure-=$#jed1amhyw0c5^%ltvxx)84!coez=h_qtmm5&1ms^#7fbpjq'\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = ['13.209.69.81', '127.0.0.1', 'localhost', '3.36.208.188', '0.0.0.0', 'www.pseudorec.com',\n                 'pseudorec.com']\n# Application definition\nINSTALLED_APPS = [\n    'markdownx',\n    'users',  #    \n    'movie',  # daum movie   ",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "DEBUG = True\nALLOWED_HOSTS = ['13.209.69.81', '127.0.0.1', 'localhost', '3.36.208.188', '0.0.0.0', 'www.pseudorec.com',\n                 'pseudorec.com']\n# Application definition\nINSTALLED_APPS = [\n    'markdownx',\n    'users',  #    \n    'movie',  # daum movie   \n    'paper_review',  #    \n    'django.contrib.admin',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "ALLOWED_HOSTS",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "ALLOWED_HOSTS = ['13.209.69.81', '127.0.0.1', 'localhost', '3.36.208.188', '0.0.0.0', 'www.pseudorec.com',\n                 'pseudorec.com']\n# Application definition\nINSTALLED_APPS = [\n    'markdownx',\n    'users',  #    \n    'movie',  # daum movie   \n    'paper_review',  #    \n    'django.contrib.admin',\n    'django.contrib.auth',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "INSTALLED_APPS",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "INSTALLED_APPS = [\n    'markdownx',\n    'users',  #    \n    'movie',  # daum movie   \n    'paper_review',  #    \n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "MIDDLEWARE",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "MIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'allauth.account.middleware.AccountMiddleware',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "ROOT_URLCONF",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "ROOT_URLCONF = 'config.urls'\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [TEMPLATES_DIR],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "TEMPLATES",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "TEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [TEMPLATES_DIR],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "WSGI_APPLICATION",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "WSGI_APPLICATION = 'config.wsgi.application'\n# Database\n# https://docs.djangoproject.com/en/4.2/ref/settings/#databases\n# DATABASES = {\n#     'default': {\n#         'ENGINE': 'django.db.backends.sqlite3',\n#         'NAME': BASE_DIR / 'db.sqlite3',\n#     }\n# }\nDATABASES = {",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "DATABASES",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.mysql',  # engine: mysql\n        'NAME': 'movielens25m',  # DB Name\n        'USER': 'admin',  # DB User\n        'PASSWORD': os.getenv('RDS_MYSQL_PW'),  # Password\n        'HOST': \"pseudorec.cvhv2t0obyv3.ap-northeast-2.rds.amazonaws.com\",  #   \n        'PORT': '3306',  #  \n        'OPTIONS': {\n            'init_command': \"SET sql_mode='STRICT_TRANS_TABLES'\",",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "AUTH_PASSWORD_VALIDATORS",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "AUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n    },",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_CODE",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "LANGUAGE_CODE = 'ko-kr'\nTIME_ZONE = 'Asia/Seoul'\nUSE_I18N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/4.2/howto/static-files/\nSTATIC_URL = '/static/'\nSTATIC_ROOT = os.path.join(BASE_DIR, '_static')\nSTATICFILES_DIRS = [\n    BASE_DIR / 'static',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "TIME_ZONE = 'Asia/Seoul'\nUSE_I18N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/4.2/howto/static-files/\nSTATIC_URL = '/static/'\nSTATIC_ROOT = os.path.join(BASE_DIR, '_static')\nSTATICFILES_DIRS = [\n    BASE_DIR / 'static',\n]",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "USE_I18N",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "USE_I18N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/4.2/howto/static-files/\nSTATIC_URL = '/static/'\nSTATIC_ROOT = os.path.join(BASE_DIR, '_static')\nSTATICFILES_DIRS = [\n    BASE_DIR / 'static',\n]\nMEDIA_URL = '/media/'",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "USE_TZ",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "USE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/4.2/howto/static-files/\nSTATIC_URL = '/static/'\nSTATIC_ROOT = os.path.join(BASE_DIR, '_static')\nSTATICFILES_DIRS = [\n    BASE_DIR / 'static',\n]\nMEDIA_URL = '/media/'\nMEDIA_ROOT = os.path.join(BASE_DIR, '_media')",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "STATIC_URL",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "STATIC_URL = '/static/'\nSTATIC_ROOT = os.path.join(BASE_DIR, '_static')\nSTATICFILES_DIRS = [\n    BASE_DIR / 'static',\n]\nMEDIA_URL = '/media/'\nMEDIA_ROOT = os.path.join(BASE_DIR, '_media')\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "STATIC_ROOT",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "STATIC_ROOT = os.path.join(BASE_DIR, '_static')\nSTATICFILES_DIRS = [\n    BASE_DIR / 'static',\n]\nMEDIA_URL = '/media/'\nMEDIA_ROOT = os.path.join(BASE_DIR, '_media')\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nSESSION_ENGINE = 'django.contrib.sessions.backends.db'",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "STATICFILES_DIRS",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "STATICFILES_DIRS = [\n    BASE_DIR / 'static',\n]\nMEDIA_URL = '/media/'\nMEDIA_ROOT = os.path.join(BASE_DIR, '_media')\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nSESSION_ENGINE = 'django.contrib.sessions.backends.db'\n# markdown",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "MEDIA_URL",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "MEDIA_URL = '/media/'\nMEDIA_ROOT = os.path.join(BASE_DIR, '_media')\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nSESSION_ENGINE = 'django.contrib.sessions.backends.db'\n# markdown\nMARKDOWNX_MARKDOWN_EXTENSIONS = [\n    'markdown.extensions.codehilite',\n    'markdown.extensions.fenced_code',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "MEDIA_ROOT",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "MEDIA_ROOT = os.path.join(BASE_DIR, '_media')\n# Default primary key field type\n# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nSESSION_ENGINE = 'django.contrib.sessions.backends.db'\n# markdown\nMARKDOWNX_MARKDOWN_EXTENSIONS = [\n    'markdown.extensions.codehilite',\n    'markdown.extensions.fenced_code',\n    'markdown.extensions.extra',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "DEFAULT_AUTO_FIELD",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nSESSION_ENGINE = 'django.contrib.sessions.backends.db'\n# markdown\nMARKDOWNX_MARKDOWN_EXTENSIONS = [\n    'markdown.extensions.codehilite',\n    'markdown.extensions.fenced_code',\n    'markdown.extensions.extra',\n    'markdown.extensions.toc'\n]\n# MARKDOWNX_MARKDOWN_EXTENSIONS = ['fenced_code', 'codehilite']",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "SESSION_ENGINE",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "SESSION_ENGINE = 'django.contrib.sessions.backends.db'\n# markdown\nMARKDOWNX_MARKDOWN_EXTENSIONS = [\n    'markdown.extensions.codehilite',\n    'markdown.extensions.fenced_code',\n    'markdown.extensions.extra',\n    'markdown.extensions.toc'\n]\n# MARKDOWNX_MARKDOWN_EXTENSIONS = ['fenced_code', 'codehilite']\nMARKDOWNX_MARKDOWN_EXTENSION_CONFIGS = {",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "MARKDOWNX_MARKDOWN_EXTENSIONS",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "MARKDOWNX_MARKDOWN_EXTENSIONS = [\n    'markdown.extensions.codehilite',\n    'markdown.extensions.fenced_code',\n    'markdown.extensions.extra',\n    'markdown.extensions.toc'\n]\n# MARKDOWNX_MARKDOWN_EXTENSIONS = ['fenced_code', 'codehilite']\nMARKDOWNX_MARKDOWN_EXTENSION_CONFIGS = {\n    'markdown.extensions.codehilite': {\n        'linenums': False,",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "MARKDOWNX_MARKDOWN_EXTENSION_CONFIGS",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "MARKDOWNX_MARKDOWN_EXTENSION_CONFIGS = {\n    'markdown.extensions.codehilite': {\n        'linenums': False,\n        'use_pygments': True,\n        'noclasses': True,\n        'pygments_style': 'native',\n    }\n}\nAUTHENTICATION_BACKENDS = (\n    'django.contrib.auth.backends.ModelBackend',",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "AUTHENTICATION_BACKENDS",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "AUTHENTICATION_BACKENDS = (\n    'django.contrib.auth.backends.ModelBackend',\n    'allauth.account.auth_backends.AuthenticationBackend',\n)\nSITE_ID = 1\nACCOUNT_EMAIL_REQUIRED = True\nACCOUNT_EMAIL_VERIFICATION = 'none'\nLOGIN_REDIRECT_URL = '/'\nACCOUNT_DEFAULT_HTTP_PROTOCOL = 'https'\nSOCIALACCOUNT_LOGIN_ON_GET = True",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "SITE_ID",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "SITE_ID = 1\nACCOUNT_EMAIL_REQUIRED = True\nACCOUNT_EMAIL_VERIFICATION = 'none'\nLOGIN_REDIRECT_URL = '/'\nACCOUNT_DEFAULT_HTTP_PROTOCOL = 'https'\nSOCIALACCOUNT_LOGIN_ON_GET = True\nSECURE_SSL_REDIRECT = False\nCSRF_TRUSTED_ORIGINS = [\"http://127.0.0.1\", \"https://pseudorec.com\", \"https://www.pseudorec.com\"]",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "ACCOUNT_EMAIL_REQUIRED",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "ACCOUNT_EMAIL_REQUIRED = True\nACCOUNT_EMAIL_VERIFICATION = 'none'\nLOGIN_REDIRECT_URL = '/'\nACCOUNT_DEFAULT_HTTP_PROTOCOL = 'https'\nSOCIALACCOUNT_LOGIN_ON_GET = True\nSECURE_SSL_REDIRECT = False\nCSRF_TRUSTED_ORIGINS = [\"http://127.0.0.1\", \"https://pseudorec.com\", \"https://www.pseudorec.com\"]",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "ACCOUNT_EMAIL_VERIFICATION",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "ACCOUNT_EMAIL_VERIFICATION = 'none'\nLOGIN_REDIRECT_URL = '/'\nACCOUNT_DEFAULT_HTTP_PROTOCOL = 'https'\nSOCIALACCOUNT_LOGIN_ON_GET = True\nSECURE_SSL_REDIRECT = False\nCSRF_TRUSTED_ORIGINS = [\"http://127.0.0.1\", \"https://pseudorec.com\", \"https://www.pseudorec.com\"]",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "LOGIN_REDIRECT_URL",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "LOGIN_REDIRECT_URL = '/'\nACCOUNT_DEFAULT_HTTP_PROTOCOL = 'https'\nSOCIALACCOUNT_LOGIN_ON_GET = True\nSECURE_SSL_REDIRECT = False\nCSRF_TRUSTED_ORIGINS = [\"http://127.0.0.1\", \"https://pseudorec.com\", \"https://www.pseudorec.com\"]",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "ACCOUNT_DEFAULT_HTTP_PROTOCOL",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "ACCOUNT_DEFAULT_HTTP_PROTOCOL = 'https'\nSOCIALACCOUNT_LOGIN_ON_GET = True\nSECURE_SSL_REDIRECT = False\nCSRF_TRUSTED_ORIGINS = [\"http://127.0.0.1\", \"https://pseudorec.com\", \"https://www.pseudorec.com\"]",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "SOCIALACCOUNT_LOGIN_ON_GET",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "SOCIALACCOUNT_LOGIN_ON_GET = True\nSECURE_SSL_REDIRECT = False\nCSRF_TRUSTED_ORIGINS = [\"http://127.0.0.1\", \"https://pseudorec.com\", \"https://www.pseudorec.com\"]",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "SECURE_SSL_REDIRECT",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "SECURE_SSL_REDIRECT = False\nCSRF_TRUSTED_ORIGINS = [\"http://127.0.0.1\", \"https://pseudorec.com\", \"https://www.pseudorec.com\"]",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "CSRF_TRUSTED_ORIGINS",
        "kind": 5,
        "importPath": "config.settings",
        "description": "config.settings",
        "peekOfCode": "CSRF_TRUSTED_ORIGINS = [\"http://127.0.0.1\", \"https://pseudorec.com\", \"https://www.pseudorec.com\"]",
        "detail": "config.settings",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "config.test",
        "description": "config.test",
        "peekOfCode": "BASE_DIR = Path(__file__).resolve().parent.parent\nprint(f\"BASE_DIR : {BASE_DIR}\")",
        "detail": "config.test",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "config.urls",
        "description": "config.urls",
        "peekOfCode": "urlpatterns = [\n    path(\"admin/\", admin.site.urls),\n    path(\"users/\", include(\"users.urls\")),\n    path(\"movie/\", include(\"movie.urls\")),\n    path('', home),\n    path('log_click/', log_click, name='log_click'),\n    path('log_star/', log_star, name='log_star'),\n    path('archive/', include('paper_review.urls')),\n    # path('paper_review/', include('paper_review.urls')),\n    # path('monthly_pseudorec/', include('paper_review.urls')),",
        "detail": "config.urls",
        "documentation": {}
    },
    {
        "label": "application",
        "kind": 5,
        "importPath": "config.wsgi",
        "description": "config.wsgi",
        "peekOfCode": "application = get_wsgi_application()",
        "detail": "config.wsgi",
        "documentation": {}
    },
    {
        "label": "DynamoDBClient",
        "kind": 6,
        "importPath": "db_clients.dynamodb",
        "description": "db_clients.dynamodb",
        "peekOfCode": "class DynamoDBClient:\n    def __init__(self, table_name: str):\n        self.resource = boto3.resource(\n            'dynamodb',\n            aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],\n            aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'],\n            region_name=os.environ['AWS_REGION_NAME'],\n        )\n        self.client = boto3.client(\n            'dynamodb',",
        "detail": "db_clients.dynamodb",
        "documentation": {}
    },
    {
        "label": "classify_chain",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "def classify_chain(question):\n    template_classify = f\"\"\"   ( ),  ,    : \\{question}\\ \\n \n      'movie_query', 'general_conversation', 'external_search'   .\"\"\"\n    classify_prompt = PromptTemplate.from_template(template_classify)\n    try:\n        chain = classify_prompt | gemini_llm | StrOutputParser()\n        return chain.invoke({\"question\": question})\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return \"classification_error\"",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "load_memory",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "def load_memory(input):\n    global memory\n    return memory.load_memory_variables({})[\"chat_history\"]\ndef chat_chain(question):\n    global memory\n    template_chat = ''' PseudoRec  AI . \n        '  AI  () . \n              . \n      2   ,     .'''\n    chat_prompt = ChatPromptTemplate.from_messages([",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "chat_chain",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "def chat_chain(question):\n    global memory\n    template_chat = ''' PseudoRec  AI . \n        '  AI  () . \n              . \n      2   ,     .'''\n    chat_prompt = ChatPromptTemplate.from_messages([\n        (\"system\", template_chat),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{question}\"),",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "react_search_chain",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "def react_search_chain(query):\n    react_prompt = hub.pull(\"hwchase17/react\")\n    tools = [\n        Tool(\n            name=\"Search\",\n            func=search.run,\n            description=\"\"\n        )\n    ]\n    #  ",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "search_chain",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "def search_chain(context, question):\n    global memory\n    template_search = \"\"\"\n     PseudoRec  AI . \n      ()        . \n     <>    . \n      ,      . \n    <> \n    {context}\n    </> ",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "contextual_compression_retriever",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "def contextual_compression_retriever(query):\n    # LLM  LLMChainFilter  .\n    _filter = LLMChainFilter.from_llm(gemini_llm)\n    compression_retriever = ContextualCompressionRetriever(\n        # LLMChainFilter retriever  ContextualCompressionRetriever  .\n        base_compressor=_filter,\n        base_retriever=retriever,\n    )\n    compressed_docs = compression_retriever.get_relevant_documents(\n        query",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "react_agent_rag",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "def react_agent_rag(query):\n    prompt = hub.pull(\"hwchase17/react\")\n    tools = [\n        Tool(\n            name=\"Movie recommender\",\n            func=contextual_compression_retriever,\n            description=\"    \"\n        )\n    ]\n    #  ",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "rag_chain",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "def rag_chain(context, question):\n    global memory\n    template_search = \"\"\"\n     PseudoRec  AI . \n          . \n              . \n          :\n    1.   .\n    2.  ,   1.~, 2.~, 3.~  .\n    3.    , ,   ,     . ",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "openai_api_key",
        "kind": 5,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "openai_api_key = os.getenv('OPENAI_API_KEY')\ndeepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\ngemini_api_key = os.getenv('CHO_GOOGLE_API_KEY')\n# huggingface_api = os.getenv('HUGGINGFACE_CHO')\n# class \n# deepseek_llm = ChatOpenAI(\n#     model='deepseek-chat',\n#     openai_api_key=deepseek_api_key,\n#     openai_api_base='https://api.deepseek.com/v1',\n#     temperature=0.85,",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "deepseek_api_key",
        "kind": 5,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\ngemini_api_key = os.getenv('CHO_GOOGLE_API_KEY')\n# huggingface_api = os.getenv('HUGGINGFACE_CHO')\n# class \n# deepseek_llm = ChatOpenAI(\n#     model='deepseek-chat',\n#     openai_api_key=deepseek_api_key,\n#     openai_api_base='https://api.deepseek.com/v1',\n#     temperature=0.85,\n#     max_tokens=800)",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "gemini_api_key",
        "kind": 5,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "gemini_api_key = os.getenv('CHO_GOOGLE_API_KEY')\n# huggingface_api = os.getenv('HUGGINGFACE_CHO')\n# class \n# deepseek_llm = ChatOpenAI(\n#     model='deepseek-chat',\n#     openai_api_key=deepseek_api_key,\n#     openai_api_base='https://api.deepseek.com/v1',\n#     temperature=0.85,\n#     max_tokens=800)\ngemini_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", ",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "gemini_llm",
        "kind": 5,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", \n                                    api_key=gemini_api_key,\n                                    max_output_tokens=800,\n                                    temperature=0.85)\nsearch = DuckDuckGoSearchRun()\nmemory = ConversationBufferWindowMemory(k=2,\n                                        memory_key=\"chat_history\",\n                                        return_messages=True)\nembed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\ndb = Chroma(persist_directory=\"llmrec/vector_dbs/gyungah\", embedding_function=embed_model)",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "search",
        "kind": 5,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "search = DuckDuckGoSearchRun()\nmemory = ConversationBufferWindowMemory(k=2,\n                                        memory_key=\"chat_history\",\n                                        return_messages=True)\nembed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\ndb = Chroma(persist_directory=\"llmrec/vector_dbs/gyungah\", embedding_function=embed_model)\nretriever = db.as_retriever(search_kwargs={'k': 3})\n#  \ndef classify_chain(question):\n    template_classify = f\"\"\"   ( ),  ,    : \\{question}\\ \\n ",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "memory",
        "kind": 5,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "memory = ConversationBufferWindowMemory(k=2,\n                                        memory_key=\"chat_history\",\n                                        return_messages=True)\nembed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\ndb = Chroma(persist_directory=\"llmrec/vector_dbs/gyungah\", embedding_function=embed_model)\nretriever = db.as_retriever(search_kwargs={'k': 3})\n#  \ndef classify_chain(question):\n    template_classify = f\"\"\"   ( ),  ,    : \\{question}\\ \\n \n      'movie_query', 'general_conversation', 'external_search'   .\"\"\"",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "embed_model",
        "kind": 5,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\ndb = Chroma(persist_directory=\"llmrec/vector_dbs/gyungah\", embedding_function=embed_model)\nretriever = db.as_retriever(search_kwargs={'k': 3})\n#  \ndef classify_chain(question):\n    template_classify = f\"\"\"   ( ),  ,    : \\{question}\\ \\n \n      'movie_query', 'general_conversation', 'external_search'   .\"\"\"\n    classify_prompt = PromptTemplate.from_template(template_classify)\n    try:\n        chain = classify_prompt | gemini_llm | StrOutputParser()",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "db = Chroma(persist_directory=\"llmrec/vector_dbs/gyungah\", embedding_function=embed_model)\nretriever = db.as_retriever(search_kwargs={'k': 3})\n#  \ndef classify_chain(question):\n    template_classify = f\"\"\"   ( ),  ,    : \\{question}\\ \\n \n      'movie_query', 'general_conversation', 'external_search'   .\"\"\"\n    classify_prompt = PromptTemplate.from_template(template_classify)\n    try:\n        chain = classify_prompt | gemini_llm | StrOutputParser()\n        return chain.invoke({\"question\": question})",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "retriever",
        "kind": 5,
        "importPath": "llmrec.utils.gyungah.utils.langchain",
        "description": "llmrec.utils.gyungah.utils.langchain",
        "peekOfCode": "retriever = db.as_retriever(search_kwargs={'k': 3})\n#  \ndef classify_chain(question):\n    template_classify = f\"\"\"   ( ),  ,    : \\{question}\\ \\n \n      'movie_query', 'general_conversation', 'external_search'   .\"\"\"\n    classify_prompt = PromptTemplate.from_template(template_classify)\n    try:\n        chain = classify_prompt | gemini_llm | StrOutputParser()\n        return chain.invoke({\"question\": question})\n    except Exception as e:",
        "detail": "llmrec.utils.gyungah.utils.langchain",
        "documentation": {}
    },
    {
        "label": "router",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.load_chain",
        "description": "llmrec.utils.gyungah.load_chain",
        "peekOfCode": "def router(question):\n    print(Fore.BLACK + f': {question}' + Style.RESET_ALL + '\\n')\n    chain = classify_chain(question)\n    new_response = \"None\"\n    if \"movie\" in chain:\n        #  RAG\n        react_result = react_agent_rag(question)\n        new_response = rag_chain(react_result, question)\n        print(f\": {chain}\")\n    elif (\"search\" in chain) or (\"\" in new_response):",
        "detail": "llmrec.utils.gyungah.load_chain",
        "documentation": {}
    },
    {
        "label": "get_chain",
        "kind": 2,
        "importPath": "llmrec.utils.gyungah.load_chain",
        "description": "llmrec.utils.gyungah.load_chain",
        "peekOfCode": "def get_chain(question):\n    response = router(question)\n    return response",
        "detail": "llmrec.utils.gyungah.load_chain",
        "documentation": {}
    },
    {
        "label": "responses_form",
        "kind": 2,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "def responses_form(movie_titles):\n    #   title_synopsis_dict       .\n    # title_synopsis_dict      \n    #    .\n    response = \"\\n\"\n    #           .\n    for i, title in enumerate(movie_titles, start=1):\n        synopsis = title_synopsis_dict.get(title, \"  .\")\n        synopsis = synopsis if len(synopsis) <= 2000 else synopsis[0:2000//2][-2000//2:]\n        if synopsis == \"  .\": ",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "invoke_form",
        "kind": 2,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "def invoke_form(doc): \n    content = f\"\"\"\n        : {doc.metadata[\" \"]}\n        : {doc.metadata[\" \"]}\n        : {doc.metadata[\" \"]}\n        : \n        {doc.metadata[\" \"]}\n        : \n            1. {eval(doc.metadata[\" \"])[0]}\n            :",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "format_docs",
        "kind": 2,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "def format_docs(docs):\n    return \"\\n\\n\".join(invoke_form(doc) for doc in docs[0:1])\ndef get_chain(key): \n    if key == \"title\":\n        rag_chain = (\n            {\"context\": title_retriever | format_docs, \"question\": RunnablePassthrough()}\n            | custom_rec_prompt1 # prompt\n            | ChatUpstage() # chat\n            | StrOutputParser() # output parser\n        )",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "get_chain",
        "kind": 2,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "def get_chain(key): \n    if key == \"title\":\n        rag_chain = (\n            {\"context\": title_retriever | format_docs, \"question\": RunnablePassthrough()}\n            | custom_rec_prompt1 # prompt\n            | ChatUpstage() # chat\n            | StrOutputParser() # output parser\n        )\n    if key == \"content\":\n        rag_chain = (",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "find_closest_match",
        "kind": 2,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "def find_closest_match(search_result, dictionary_keys):   \n    #     \n    matches = difflib.get_close_matches(search_result, dictionary_keys, n=1, cutoff=0)\n    #   \n    return matches[0] if matches else None\ndef rec_by_intent(intent, question):\n    print(\"   :\", intent)\n    rag_chain = (\n        custom_rec_prompt2\n        | ChatUpstage() # chat",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "rec_by_intent",
        "kind": 2,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "def rec_by_intent(intent, question):\n    print(\"   :\", intent)\n    rag_chain = (\n        custom_rec_prompt2\n        | ChatUpstage() # chat\n        | StrOutputParser() # output parser\n    )\n    responses = None\n    if '' in intent: \n        #    ",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "router",
        "kind": 2,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "def router(question): \n    # print(Fore.BLACK+f'### Iteration: {num} ###'+Style.RESET_ALL+'\\n')\n    print(Fore.BLACK+f': {question}'+Style.RESET_ALL+'\\n')\n    intent = chain1.invoke(question) #  /  /  \n    new_response = \"\"\n    print(\" :\", intent)\n    if \"\" in intent: \n        intent2 = chain2.invoke(question) # ``, ``, ``, ``\n        new_response = rec_by_intent(intent2, question)\n    elif (\"\" in intent) or (\"search\" in intent) or (new_response == None): ",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "embeddings_model",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\nos.environ[\"UPSTAGE_API_KEY\"] = os.environ[\"UPSTAGE_API_KEY\"]\nos.environ[\"SOLAR_API_KEY\"] = os.environ[\"UPSTAGE_API_KEY\"]\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/title_synopsis_dict.json', 'r', encoding='utf-8') as f:\n    title_synopsis_dict = json.load(f)\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/title_rec.json', 'r', encoding='utf-8') as f:\n    title_rec = json.load(f)\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/actor_rec.json', 'r', encoding='utf-8') as f:\n    actor_rec = json.load(f)\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/director_rec.json', 'r', encoding='utf-8') as f:",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "os.environ[\"UPSTAGE_API_KEY\"]",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "os.environ[\"UPSTAGE_API_KEY\"] = os.environ[\"UPSTAGE_API_KEY\"]\nos.environ[\"SOLAR_API_KEY\"] = os.environ[\"UPSTAGE_API_KEY\"]\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/title_synopsis_dict.json', 'r', encoding='utf-8') as f:\n    title_synopsis_dict = json.load(f)\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/title_rec.json', 'r', encoding='utf-8') as f:\n    title_rec = json.load(f)\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/actor_rec.json', 'r', encoding='utf-8') as f:\n    actor_rec = json.load(f)\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/director_rec.json', 'r', encoding='utf-8') as f:\n    director_rec = json.load(f)",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "os.environ[\"SOLAR_API_KEY\"]",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "os.environ[\"SOLAR_API_KEY\"] = os.environ[\"UPSTAGE_API_KEY\"]\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/title_synopsis_dict.json', 'r', encoding='utf-8') as f:\n    title_synopsis_dict = json.load(f)\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/title_rec.json', 'r', encoding='utf-8') as f:\n    title_rec = json.load(f)\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/actor_rec.json', 'r', encoding='utf-8') as f:\n    actor_rec = json.load(f)\nwith open('llmrec/vector_dbs/hyeonwoo/dictionary/director_rec.json', 'r', encoding='utf-8') as f:\n    director_rec = json.load(f)\n# Router 1 :   , ,    Router ",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "chain1",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "chain1 = PromptTemplate.from_template(\"\"\"   , ``, ``  ``   .                                     \n    .  3  . (, , )\n . \n<>\n{question}\n</>\n, \n1. !  ? :  \n2.    :  \n3.    :  ",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "chain2",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "chain2 = PromptTemplate.from_template(\"\"\"  <> ,   ``, ``, ``, ``   .                                     \n<>\n{question}\n</>\n, \n1.    :  \n2.    :  \n3.     :  \n4.      :  \n5.      :  ",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "search",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "search = DuckDuckGoSearchRun()\ntemplate_search1 = \"\"\"    .    . \n\" \"             .          .         .\n ( )\n       .            .        ,        .            .         .   ,    ,       .             ,        .\n          .     ,       .     :\n- \",     .    , ...\" (  )\n- \" ,     !\" (   )\n- \",     ...\" (    )\n- \"   .    !\" (  )",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "template_search1",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "template_search1 = \"\"\"    .    . \n\" \"             .          .         .\n ( )\n       .            .        ,        .            .         .   ,    ,       .             ,        .\n          .     ,       .     :\n- \",     .    , ...\" (  )\n- \" ,     !\" (   )\n- \",     ...\" (    )\n- \"   .    !\" (  )\n- \",     .   !\" (   )",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "custom_search_prompt",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "custom_search_prompt = PromptTemplate.from_template(template_search1)\n#   \n# 1.     \n# 2.        \ntemplate_rec1 = \"\"\"   .    . \n\" \"             .          .         .\n  ( )\n      .            .        ,        .            .         .   ,    ,       .             ,        .\n          .     ,       .     :\n- \",     .    , ...\" (  )",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "template_rec1",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "template_rec1 = \"\"\"   .    . \n\" \"             .          .         .\n  ( )\n      .            .        ,        .            .         .   ,    ,       .             ,        .\n          .     ,       .     :\n- \",     .    , ...\" (  )\n- \" ,     !\" (   )\n- \",     ...\" (    )\n- \"   .    !\" (  )\n- \",     .   !\" (   )",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "template_rec2",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "template_rec2 = \"\"\"<>\n{question}\n</>\n<>  .    ,  .\"\"\"\ntemplate_rec2 = \"\"\"<>\n{question}\n</>\n \n- <> {format} . \n-  .\"\"\"",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "template_rec2",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "template_rec2 = \"\"\"<>\n{question}\n</>\n \n- <> {format} . \n-  .\"\"\"\ncustom_rec_prompt1 = PromptTemplate.from_template(template_rec1)\ncustom_rec_prompt2 = PromptTemplate.from_template(template_rec2)\ntemplate_chat = \"\"\"\n   .    . ",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "custom_rec_prompt1",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "custom_rec_prompt1 = PromptTemplate.from_template(template_rec1)\ncustom_rec_prompt2 = PromptTemplate.from_template(template_rec2)\ntemplate_chat = \"\"\"\n   .    . \n\" \"             .          .         .\n  ( )\n      .            .        ,        .            .         .   ,    ,       .             ,        .\n         .     ,       .     :\n- \",     .    , ...\" (  )\n- \" ,     !\" (   )",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "custom_rec_prompt2",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "custom_rec_prompt2 = PromptTemplate.from_template(template_rec2)\ntemplate_chat = \"\"\"\n   .    . \n\" \"             .          .         .\n  ( )\n      .            .        ,        .            .         .   ,    ,       .             ,        .\n         .     ,       .     :\n- \",     .    , ...\" (  )\n- \" ,     !\" (   )\n- \",     ...\" (    )",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "template_chat",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "template_chat = \"\"\"\n   .    . \n\" \"             .          .         .\n  ( )\n      .            .        ,        .            .         .   ,    ,       .             ,        .\n         .     ,       .     :\n- \",     .    , ...\" (  )\n- \" ,     !\" (   )\n- \",     ...\" (    )\n- \"   .    !\" (  )",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "custom_chat_prompt",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "custom_chat_prompt = PromptTemplate.from_template(template_chat)\ndef responses_form(movie_titles):\n    #   title_synopsis_dict       .\n    # title_synopsis_dict      \n    #    .\n    response = \"\\n\"\n    #           .\n    for i, title in enumerate(movie_titles, start=1):\n        synopsis = title_synopsis_dict.get(title, \"  .\")\n        synopsis = synopsis if len(synopsis) <= 2000 else synopsis[0:2000//2][-2000//2:]",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "embeddings_model",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\ntitle_db = Chroma(persist_directory='../vector_dbs/hyeonwoo/chroma_db_title_0614', embedding_function=embeddings_model)\ntitle_retriever = title_db.as_retriever(\n    search_type=\"similarity_score_threshold\", \n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01}) # Query    (K=4)\ncontent_db = Chroma(persist_directory='../vector_dbs/hyeonwoo/chroma_db_content_0614', embedding_function=embeddings_model)\ncontent_retriever = content_db.as_retriever(\n    search_type=\"similarity_score_threshold\", \n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01}) # Query    (K=4)\ndef find_closest_match(search_result, dictionary_keys):   ",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "title_db",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "title_db = Chroma(persist_directory='../vector_dbs/hyeonwoo/chroma_db_title_0614', embedding_function=embeddings_model)\ntitle_retriever = title_db.as_retriever(\n    search_type=\"similarity_score_threshold\", \n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01}) # Query    (K=4)\ncontent_db = Chroma(persist_directory='../vector_dbs/hyeonwoo/chroma_db_content_0614', embedding_function=embeddings_model)\ncontent_retriever = content_db.as_retriever(\n    search_type=\"similarity_score_threshold\", \n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01}) # Query    (K=4)\ndef find_closest_match(search_result, dictionary_keys):   \n    #     ",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "title_retriever",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "title_retriever = title_db.as_retriever(\n    search_type=\"similarity_score_threshold\", \n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01}) # Query    (K=4)\ncontent_db = Chroma(persist_directory='../vector_dbs/hyeonwoo/chroma_db_content_0614', embedding_function=embeddings_model)\ncontent_retriever = content_db.as_retriever(\n    search_type=\"similarity_score_threshold\", \n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01}) # Query    (K=4)\ndef find_closest_match(search_result, dictionary_keys):   \n    #     \n    matches = difflib.get_close_matches(search_result, dictionary_keys, n=1, cutoff=0)",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "content_db",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "content_db = Chroma(persist_directory='../vector_dbs/hyeonwoo/chroma_db_content_0614', embedding_function=embeddings_model)\ncontent_retriever = content_db.as_retriever(\n    search_type=\"similarity_score_threshold\", \n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01}) # Query    (K=4)\ndef find_closest_match(search_result, dictionary_keys):   \n    #     \n    matches = difflib.get_close_matches(search_result, dictionary_keys, n=1, cutoff=0)\n    #   \n    return matches[0] if matches else None\ndef rec_by_intent(intent, question):",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "content_retriever",
        "kind": 5,
        "importPath": "llmrec.utils.hyeonwoo.load_chain",
        "description": "llmrec.utils.hyeonwoo.load_chain",
        "peekOfCode": "content_retriever = content_db.as_retriever(\n    search_type=\"similarity_score_threshold\", \n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01}) # Query    (K=4)\ndef find_closest_match(search_result, dictionary_keys):   \n    #     \n    matches = difflib.get_close_matches(search_result, dictionary_keys, n=1, cutoff=0)\n    #   \n    return matches[0] if matches else None\ndef rec_by_intent(intent, question):\n    print(\"   :\", intent)",
        "detail": "llmrec.utils.hyeonwoo.load_chain",
        "documentation": {}
    },
    {
        "label": "kyeongchan_model",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.get_model",
        "description": "llmrec.utils.kyeongchan.get_model",
        "peekOfCode": "kyeongchan_model = ChatOpenAI()",
        "detail": "llmrec.utils.kyeongchan.get_model",
        "documentation": {}
    },
    {
        "label": "GraphState",
        "kind": 6,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "class GraphState(TypedDict):\n    is_movie_recommendation_query: str  #    \n    question: str\n    query: str\n    filter: str  #    \n    type_: str  #   \n    username: str\n    id: str\n    genre_ids: List[str]\n    name: str",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "is_recommend",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def is_recommend(state: GraphState) -> str:\n    # print(f\"is_recommend\".center(60, '-'))\n    question = state[\"question\"]\n    #    YES or NO  \n    system_template = \"\"\"\n### GOAL\n* You are a bot that assists with movie recommendations.\n* Classify responses based on the input. Categorize them as 'General Conversation', 'Movie Recommendation'\n* If the query content is general conversation, return 'General'.\n* If the query content is related to movie recommendations, return 'Recommend'.",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "is_recommend_yes_or_no",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def is_recommend_yes_or_no(state: StateGraph):\n    # print(f\"is_recommend_yes_or_no\".center(60, '-'))\n    is_movie_recommendation_query = state['is_movie_recommendation_query']\n    if is_movie_recommendation_query == \"'General Conversation'\":\n        # print(f\"NO\")\n        return \"NO\"\n    else:\n        # print(f\"YES\")\n        return \"YES\"\ndef ask_only_movie(state: StateGraph):",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "ask_only_movie",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def ask_only_movie(state: StateGraph):\n    # print(f\"ask_only_movie\".center(60, '-'))\n    state['final_answer'] = '    .'\n    return state\ndef meta_detection(state: GraphState) -> GraphState:\n    print(f\"Mete detection(self-querying)\".center(60, '-'))\n    question = state['question']\n    system_template = \"\"\"\nYour goal is to structure the user's query to match the request schema provided below.\n<< Structured Request Schema >>",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "meta_detection",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def meta_detection(state: GraphState) -> GraphState:\n    print(f\"Mete detection(self-querying)\".center(60, '-'))\n    question = state['question']\n    system_template = \"\"\"\nYour goal is to structure the user's query to match the request schema provided below.\n<< Structured Request Schema >>\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\n```json\n{{\n    \"query\": string \\ text string to compare to document contents",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "self_query_retrieval_yes_or_no",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def self_query_retrieval_yes_or_no(state: GraphState):\n    # print(f\"self_query_retrieval_yes_or_no\".center(60, '-'))\n    result = state['candidate']\n    if len(result) > 0:\n        # print(f\"YES\")\n        return \"YES\"\n    else:\n        # print(f\"NO\")\n        return \"NO\"\ndef self_query_retrieval(state: GraphState) -> GraphState:",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "self_query_retrieval",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def self_query_retrieval(state: GraphState) -> GraphState:\n    print(f\"Self-Querying Retrieval\".center(60, '-'))\n    question = state['question']\n    search_manager = SearchManager(\n        api_key=os.getenv(\"OPENAI_API_KEY\"),\n        index=\"86f92d0e-e8ec-459a-abb8-0262bbf794a2\",\n        top_k=10,\n        score_threshold=0.7\n    )\n    search_manager.add_engine(\"self\")",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "call_sasrec",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def call_sasrec(state: GraphState):\n    print(f\"Get SASRec candidates' info\".center(60, '-'))\n    user_logs_df = get_user_logs_df(state['username'], None)\n    history_mids = get_interacted_movie_ids(user_logs_df)\n    # SASRec  \n    sasrec_recomm_mids = get_sasrec_recomm_mids(history_mids)\n    sasrec_recomm_mids = [mid for mid in sasrec_recomm_mids if mid not in [int(_) for _ in history_mids]]  #   \n    candidates_lst = get_recomm_movies_titles(sasrec_recomm_mids)\n    print(f\"sasrec_recomm_mids : {sasrec_recomm_mids}\")\n    print(f\"candidates_lst : {candidates_lst}\")",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "meta_detection_yes_or_no",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def meta_detection_yes_or_no(state: GraphState):\n    # print(f\"meta_detection_yes_or_no\".center(60, '-'))\n    filter = state['filter']\n    if len(filter) > 0:\n        # print(f\"YES\")\n        return \"YES\"\n    else:\n        # print(f\"NO\")\n        return \"NO\"\ndef classification(state: GraphState) -> GraphState:",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "classification",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def classification(state: GraphState) -> GraphState:\n    # print(f\"classification\".center(60, '-'))\n    question = state[\"question\"]\n    if question == \"\":\n        state['type_'] = 'MAIN'\n        return state\n    else:\n        system_template = \"\"\"\nYou are a kind assistant for classifying user query type into the follwing categories:\nGENRE, NAME, PERSON",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "query_router",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def query_router(state: GraphState):\n    # print(f\"query_router\".center(60, '-'))\n    if state['type_'] == \"GENRE\":\n        return \"GENRE\"\n    if state['type_'] == \"NAME\":\n        return \"NAME\"\n    if state['type_'] == \"PERSON\":\n        return \"PERSON\"\n    if state['type_'] == \"DATE\":\n        return \"DATE\"",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "user_profile",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def user_profile(state: GraphState):\n    print(f\"user_profile\".center(60, '-'))\n    history = '\\n'.join(map(str, state['history']))\n    system_template = \"\"\"###GOAL\n* You are a bot that analyzes user preferences based on their movie viewing history.\n* Check for patterns in the user's preferences based on the meta information (movie title, genre, keywords) of the movies in HISTORY.\n* Express the user's taste in one sentence based on the identified patterns.\n* The response must be generated in Korean. His/her name is {username}\nHISTORY:\n{{'movie': ' ', 'genres': ['', ''], 'keyword': [\"assassination\", \"washington dc, usa\", \"paris, france\", \"based on novel or book\", \"politics\", \"dictator\", \"1970s\", \"hearing\", \"dictatorship\", \"based on true story\", \"military dictatorship\", \"assassination of president\", \"korea president\", \"park chung-hee\", \"south korea\"]}}",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "get_user_history",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def get_user_history(state: GraphState):\n    print(f\"get_user_history\".center(60, '-'))\n    username = state['username']\n    user_logs_df = get_user_logs_df(username, None)\n    # print(user_logs_df)\n    # user_history = ['', '', '']\n    if not len(user_logs_df):\n        print(f\"No histories\")\n        state['history'] = None\n        return state",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "get_candidate_movie_info_from_tmdb",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def get_candidate_movie_info_from_tmdb(state: GraphState):\n    print(f\"Get candidate's movie info from TMDB\".center(60, '-'))\n    # recommend_movies = ['', ' ', '', ' ', '', '', '2']\n    candidates = []\n    for candidate in state['candidate']:\n        title = candidate['metadata']['titleKo']\n        dic_ = {}\n        movie_id = get_tmdb_movie_id(title)\n        if movie_id is None:\n            continue",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "candidate_exist",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def candidate_exist(state: GraphState):\n    # print(f\"candidate_exist\".center(60, '-'))\n    if len(state['candidate']) == 0:\n        # print(f\"YES\")\n        return \"NO\"\n    else:\n        # print(f\"YES\")\n        return \"YES\"\ndef recommend_movie(state: GraphState):\n    # print(f\"recommend_movie\".center(60, '-'))",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "recommend_movie",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def recommend_movie(state: GraphState):\n    # print(f\"recommend_movie\".center(60, '-'))\n    system_template = \"\"\"### GOLE:\n* You are a bot that recommends movies based on user preferences.\n* Select and recommend movies from a pool of candidates that fit the user's \"query\" while considering their \"preferences\".\n* Follow the steps below to review and generate a response.\n* Please announce the username in the last output answer.\n### PROCEDURE\n* Reference the user's PREFERENCE to extract one movie from CANDIDATE.\n* Then, recommend the best movie that matchs the QUERY.",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "relevance_check",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def relevance_check(state: GraphState):\n    # print(f\"relevance_check\".center(60, '-'))\n    # print(\"YES\")\n    return 'YES'\ndef get_tmdb_movie_id(movie_name: str):\n    # # print(f\"get_movie_id(movie_name={movie_name})\".ljust(60, '+'))\n    query = movie_name\n    url = f'https://api.themoviedb.org/3/search/movie?query={query}&include_adult=false&language=ko-KR&page=1'\n    headers = {\n        'Authorization': f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\",",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "get_tmdb_movie_id",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def get_tmdb_movie_id(movie_name: str):\n    # # print(f\"get_movie_id(movie_name={movie_name})\".ljust(60, '+'))\n    query = movie_name\n    url = f'https://api.themoviedb.org/3/search/movie?query={query}&include_adult=false&language=ko-KR&page=1'\n    headers = {\n        'Authorization': f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\",\n        'accept': 'application/json'\n    }\n    response = requests.get(url, headers=headers).json()\n    if len(response['results']) > 0:",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "get_genre_by_movie_id",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def get_genre_by_movie_id(movie_id: str) -> List:\n    # # print(f\"get_genre_by_movie_id(movie_id={movie_id})\".ljust(60, '+'))\n    \"\"\"Search genre by movie_id\"\"\"\n    url = f\"https://api.themoviedb.org/3/movie/{movie_id}?language=ko-KR\"\n    headers = {\n        'Authorization': f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\",\n        'accept': 'application/json'\n    }\n    response = requests.get(url, headers=headers).json()\n    genres = [genre['name'] for genre in response['genres']]",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "get_keyword_by_movie_id",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def get_keyword_by_movie_id(movie_id: str) -> List:\n    # # print(f\"get_keyword_by_movie_id(movie_id={movie_id})\".ljust(60, '+'))\n    \"\"\"Search movies by movie keyword\"\"\"\n    url = f'https://api.themoviedb.org/3/movie/{movie_id}/keywords'\n    headers = {\n        'Authorization': f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\",\n        'accept': 'application/json'\n    }\n    response = requests.get(url, headers=headers).json()\n    # movie_id = response['id']",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "get_movie_info_by_name",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def get_movie_info_by_name(state: GraphState):\n    # print(f\"get_movie_info_by_name\".center(60, '-'))\n    '''\n    input: GraphState\n    output: GraphState\n        genre_ids : movie genre\n        name : movie_name\n    '''\n    query = state[\"query\"]\n    url = f'https://api.themoviedb.org/3/search/movie?query={query}&include_adult=false&language=ko-KR&page=1'",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "post_process_answer",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def post_process_answer(state: GraphState):\n    # print(f\"post_process_answer\".center(60, '-'))\n    # print(f\"state['answer'] : {state['answer']}\")\n    # print(f\"type(state['answer']) : {type(state['answer'])}\")\n    recommended_mid = state['answer']['pseudorec_movie_id']\n    sql = f\"\"\"\n    SELECT dm.movieId,\n           dm.posterUrl,\n           dmsp.synopsis_prep\n    FROM daum_movies dm",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "out_no_history",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def out_no_history(state):\n    print(f\"out_no_history\".center(60, '-'))\n    response = llm.invoke(input=f\"You are a Movie Curator. Say sorry mention to {state['username']} that his/her history interactions of movies are not found. Tell them that go to home and rate or click some movies and comeback to analyze his/her preference. No other mentions. Utter their name. Only speak in Korean.\")\n    state['final_answer'] = (\n            response.content +\n            \"<br><br>\" +\n            \"<a href='https://www.pseudorec.com/'><strong> </strong></a>\")\n    return state\ndef exist_history(state):\n    if state['history'] is None:",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "exist_history",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "def exist_history(state):\n    if state['history'] is None:\n        return 'NO'\n    else:\n        return 'YES'\nworkflow = StateGraph(GraphState)\nworkflow.add_node(\"is_recommend\", is_recommend)\nworkflow.add_node(\"ask_only_movie\", ask_only_movie)\nworkflow.add_node(\"get_user_history\", get_user_history)\nworkflow.add_node(\"user_profile\", user_profile)",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "mysql",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "mysql = MysqlClient()\nload_dotenv('.env.dev')\nllm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", api_key=os.getenv('KYEONGCHAN_GEMINI_API_KEY'))\nclass GraphState(TypedDict):\n    is_movie_recommendation_query: str  #    \n    question: str\n    query: str\n    filter: str  #    \n    type_: str  #   ",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "llm",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", api_key=os.getenv('KYEONGCHAN_GEMINI_API_KEY'))\nclass GraphState(TypedDict):\n    is_movie_recommendation_query: str  #    \n    question: str\n    query: str\n    filter: str  #    \n    type_: str  #   \n    username: str\n    id: str",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "workflow",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "workflow = StateGraph(GraphState)\nworkflow.add_node(\"is_recommend\", is_recommend)\nworkflow.add_node(\"ask_only_movie\", ask_only_movie)\nworkflow.add_node(\"get_user_history\", get_user_history)\nworkflow.add_node(\"user_profile\", user_profile)\n# workflow.add_node(\"classification\", classification)\nworkflow.add_node(\"get_candidate_movie_info_from_tmdb\", get_candidate_movie_info_from_tmdb)\nworkflow.add_node(\"recommend_movie\", recommend_movie)\nworkflow.add_node(\"meta_detection\", meta_detection)\nworkflow.add_node(\"call_sasrec\", call_sasrec)",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.langgraph_test",
        "description": "llmrec.utils.kyeongchan.langgraph_test",
        "peekOfCode": "app = workflow.compile()\n# from langchain_core.runnables import RunnableConfig\n# config = RunnableConfig(recursion_limit=100, configurable={\"thread_id\": \"movie\"})\n# inputs = GraphState(question=\"\")\n# app.invoke(inputs, config=config)\n# for output in app.stream(inputs, config=config):\n#     for key, value in output.items():\n#         # print(f\"Output from node '{key}':\")\n#         # print(\"---\")\n#         print(value)",
        "detail": "llmrec.utils.kyeongchan.langgraph_test",
        "documentation": {}
    },
    {
        "label": "PromptTemplates",
        "kind": 6,
        "importPath": "llmrec.utils.kyeongchan.prompts",
        "description": "llmrec.utils.kyeongchan.prompts",
        "peekOfCode": "class PromptTemplates:\n    preference_prompt_template = PromptTemplate(\n        template=\"\"\" {username}   .    {username}    .     .\n   : \n1 \n : 1987\n : 2017\n : , , \n : 1987 1,       .       ,        .       .          ,       .         ...\n : , , , , , , , ",
        "detail": "llmrec.utils.kyeongchan.prompts",
        "documentation": {}
    },
    {
        "label": "SearchEngine",
        "kind": 6,
        "importPath": "llmrec.utils.kyeongchan.search_engine",
        "description": "llmrec.utils.kyeongchan.search_engine",
        "peekOfCode": "class SearchEngine:\n    BASE_URL = \"http://3.36.208.188:8989\"\n    ALLOWED_TYPES = {\"self\", \"ensemble\", \"dense\", \"sparse\"}\n    def __init__(self, type, endpoint):\n        if type not in self.ALLOWED_TYPES:\n            raise TypeError(f\"Invalid type '{type}'. Allowed types are: {', '.join(self.ALLOWED_TYPES)}\")\n        self.type = type\n        self.endpoint = self.BASE_URL + endpoint\n    def search(self, query, api_key, score_threshold, top_k, index):\n        payload = {",
        "detail": "llmrec.utils.kyeongchan.search_engine",
        "documentation": {}
    },
    {
        "label": "SearchManager",
        "kind": 6,
        "importPath": "llmrec.utils.kyeongchan.search_engine",
        "description": "llmrec.utils.kyeongchan.search_engine",
        "peekOfCode": "class SearchManager:\n    def __init__(\n            self,\n            api_key: str,\n            index: str,\n            top_k: float,\n            score_threshold: float\n    ):\n        self.engines = {}\n        self.api_key = api_key",
        "detail": "llmrec.utils.kyeongchan.search_engine",
        "documentation": {}
    },
    {
        "label": "tmdb_movie_genre_search",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "def tmdb_movie_genre_search(movie_id: str) -> List:\n    \"\"\"Search genre by movie_id\"\"\"\n    url = f\"https://api.themoviedb.org/3/movie/{movie_id}?language=ko-KR\"\n    headers = {\n        # 'Authorization': f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\",\n        'accept': 'application/json'\n    }\n    response = requests.get(url, headers=headers).json()\n    genres = [genre['name'] for genre in response['genres']]\n    return genres",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "tmdb_keyword_search",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "def tmdb_keyword_search(movie_id: str) -> List:\n    \"\"\"Search movies by movie keyword\"\"\"\n    url = f'https://api.themoviedb.org/3/movie/{movie_id}/keywords'\n    headers = {\n        # 'Authorization': f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\",\n        'accept': 'application/json'\n    }\n    response = requests.get(url, headers=headers).json()\n    # movie_id = response['id']\n    keyword = response['keywords']",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "tmdb_now_play_search",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "def tmdb_now_play_search() -> List:\n    \"\"\"Search now-playing movies\"\"\"\n    url = f'https://api.themoviedb.org/3/movie/now_playing?language=ko-KR&page=1'\n    headers = {\n        # 'Authorization': f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\",\n        'accept': 'application/json'\n    }\n    response = requests.get(url, headers=headers).json()\n    movie_titles = [result['title'] for result in response['results']]\n    return movie_titles",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "tmdb_movie_id_search",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "def tmdb_movie_id_search(query: str) -> str:\n    \"\"\"Search movie_id by movie name\"\"\"\n    url = f'https://api.themoviedb.org/3/search/movie?query={query}&include_adult=false&language=ko-KR&page=1'\n    headers = {\n        # 'Authorization': f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\",\n        'accept': 'application/json'\n    }\n    response = requests.get(url, headers=headers).json()\n    movie_id = response['results'][0]['id']\n    return str(movie_id)",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "tools",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "tools = [\n    tmdb_movie_id_search,\n    tmdb_keyword_search,\n    tmdb_now_play_search,\n    tmdb_movie_genre_search\n]\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"\"\nfrom langchain_openai import ChatOpenAI\nllm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "os.environ[\"OPENAI_API_KEY\"]",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "os.environ[\"OPENAI_API_KEY\"] = \"\"\nfrom langchain_openai import ChatOpenAI\nllm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\nprompt = hub.pull(\"hwchase17/openai-functions-agent\")\nagent = create_tool_calling_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    verbose=True,\n    return_intermediate_steps=True",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "llm",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\nprompt = hub.pull(\"hwchase17/openai-functions-agent\")\nagent = create_tool_calling_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    verbose=True,\n    return_intermediate_steps=True\n)\nresponse = agent_executor.invoke({\"input\" : \"    \"})",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "prompt",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\nagent = create_tool_calling_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    verbose=True,\n    return_intermediate_steps=True\n)\nresponse = agent_executor.invoke({\"input\" : \"    \"})\nprint(response)",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "agent",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "agent = create_tool_calling_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    verbose=True,\n    return_intermediate_steps=True\n)\nresponse = agent_executor.invoke({\"input\" : \"    \"})\nprint(response)\n#",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "agent_executor",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "agent_executor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    verbose=True,\n    return_intermediate_steps=True\n)\nresponse = agent_executor.invoke({\"input\" : \"    \"})\nprint(response)\n#\n# if __name__ == '__main__':",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.tools",
        "description": "llmrec.utils.kyeongchan.tools",
        "peekOfCode": "response = agent_executor.invoke({\"input\" : \"    \"})\nprint(response)\n#\n# if __name__ == '__main__':\n#     # tmdb_keyword_search(movie_id=\"42190\")\n#     # print(tmdb_now_play_search())\n#     print(tmdb_movie_genre_search(movie_id=\"42190\"))",
        "detail": "llmrec.utils.kyeongchan.tools",
        "documentation": {}
    },
    {
        "label": "get_interacted_movie_ids",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "def get_interacted_movie_ids(user_logs_df, last_k=10):\n    sorted_df = user_logs_df[['movieId', 'timestamp']].sort_values(by='timestamp')\n    history_mids = []\n    cnt = 0\n    for mid in sorted_df['movieId']:\n        if mid not in history_mids:\n            history_mids.append(mid)\n            cnt += 1\n        if cnt == last_k:\n            break",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "get_history_with_newline",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "def get_history_with_newline(history_mids):\n    sql = \"\"\"\n    SELECT *\n    FROM daum_movies\n    WHERE movieId in ({history_mids})\n    \"\"\"\n    sql = sql.format(history_mids=', '.join([str(hmid) for hmid in history_mids]))\n    history_df = pd.read_sql(sql, mysql.engine)\n    history_with_newline = ', '.join(history_df['titleKo'].tolist())\n    return history_df, history_with_newline",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "get_sasrec_recomm_mids",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "def get_sasrec_recomm_mids(history_mids):\n    url = \"http://15.165.169.138:7001/sasrec/\"\n    headers = {\n        \"accept\": \"application/json\",\n        \"Content-Type\": \"application/json\"\n    }\n    data = {\n        \"movie_ids\": history_mids\n    }\n    response = requests.post(url, headers=headers, data=json.dumps(data))",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "get_recomm_movies_titles",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "def get_recomm_movies_titles(sasrec_recomm_mids):\n    sql = f\"\"\"\n    SELECT *\n    FROM daum_movies\n    WHERE movieId IN ({','.join(map(str, sasrec_recomm_mids))})\n    \"\"\"\n    df = pd.read_sql(sql, mysql.engine)\n    df_sorted = df.set_index('movieId').loc[sasrec_recomm_mids].reset_index()\n    candidates_lst = []\n    for _, row in df_sorted[['movieId', 'titleKo']].iterrows():",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "tmdb_search_title",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "def tmdb_search_title(title):\n    url = f\"https://api.themoviedb.org/3/search/movie?query={title}&include_adult=true&language=ko-KR&page=1\"\n    headers = {\n        \"accept\": \"application/json\",\n        \"Authorization\": f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\"\n    }\n    response = requests.get(url, headers=headers)\n    return response.json()\ndef tmdb_movies_details(tmdb_movie_id):\n    url = f'https://api.themoviedb.org/3/movie/{tmdb_movie_id}?language=ko-KR'",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "tmdb_movies_details",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "def tmdb_movies_details(tmdb_movie_id):\n    url = f'https://api.themoviedb.org/3/movie/{tmdb_movie_id}?language=ko-KR'\n    headers = {\n        'Authorization': f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\",\n        'accept': 'application/json'\n    }\n    response = requests.get(url, headers=headers)\n    return response.json()\ndef tmdb_movies_credits(tmdb_movie_id):\n    url = f\"https://api.themoviedb.org/3/movie/{tmdb_movie_id}/credits?language=ko-KR\"",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "tmdb_movies_credits",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "def tmdb_movies_credits(tmdb_movie_id):\n    url = f\"https://api.themoviedb.org/3/movie/{tmdb_movie_id}/credits?language=ko-KR\"\n    headers = {\n        \"accept\": \"application/json\",\n        \"Authorization\": f\"Bearer {os.getenv('KC_TMDB_READ_ACCESS_TOKEN')}\"\n    }\n    response = requests.get(url, headers=headers)\n    return response.json()\ndef get_history_with_meta(history_df):\n    history_with_meta = ''",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "get_history_with_meta",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "def get_history_with_meta(history_df):\n    history_with_meta = ''\n    for i, row in history_df[['titleKo', 'titleEn']].iterrows():\n        title_ko = row['titleKo']\n        year = int(row['titleEn'][-4:])\n        # print(f\"movie info from daum_movies\".center(60, '-'))\n        # print(f\" : {title_ko}\")\n        # print(f\" : {year}\")\n        history_with_meta += f\"{str(i + 1)} \\n\"\n        history_with_meta += f\" : {title_ko}\\n\"",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "get_landing_page_recommendation",
        "kind": 2,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "def get_landing_page_recommendation(username, user_logs_df, kyeongchan_model):\n    history_mids = get_interacted_movie_ids(user_logs_df)\n    history_df, history_with_join = get_history_with_newline(history_mids)\n    # user preference\n    history_with_meta = get_history_with_meta(history_df)\n    print(f\"preference prompt\".center(100, '-'))\n    print(PromptTemplates.preference_prompt_template.format(username=username, history_with_meta=history_with_meta))\n    preference_response = kyeongchan_model([\n        HumanMessage(\n            PromptTemplates.preference_prompt_template.format(username=username, history_with_meta=history_with_meta))",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "mysql",
        "kind": 5,
        "importPath": "llmrec.utils.kyeongchan.utils",
        "description": "llmrec.utils.kyeongchan.utils",
        "peekOfCode": "mysql = MysqlClient()\ndef get_interacted_movie_ids(user_logs_df, last_k=10):\n    sorted_df = user_logs_df[['movieId', 'timestamp']].sort_values(by='timestamp')\n    history_mids = []\n    cnt = 0\n    for mid in sorted_df['movieId']:\n        if mid not in history_mids:\n            history_mids.append(mid)\n            cnt += 1\n        if cnt == last_k:",
        "detail": "llmrec.utils.kyeongchan.utils",
        "documentation": {}
    },
    {
        "label": "Chat",
        "kind": 6,
        "importPath": "llmrec.utils.namjoon.chat",
        "description": "llmrec.utils.namjoon.chat",
        "peekOfCode": "class Chat(TypedDict):\n    chat_history: str\ndef ChatMessagesNode(state):\n    \"\"\"\n      !\n    \"\"\"",
        "detail": "llmrec.utils.namjoon.chat",
        "documentation": {}
    },
    {
        "label": "ChatMessagesNode",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.chat",
        "description": "llmrec.utils.namjoon.chat",
        "peekOfCode": "def ChatMessagesNode(state):\n    \"\"\"\n      !\n    \"\"\"",
        "detail": "llmrec.utils.namjoon.chat",
        "documentation": {}
    },
    {
        "label": "ExpertisedSearchState",
        "kind": 6,
        "importPath": "llmrec.utils.namjoon.expertised",
        "description": "llmrec.utils.namjoon.expertised",
        "peekOfCode": "class ExpertisedSearchState(TypedDict):\n    question: str         #  \n    movie: str            # self query    \n    experts: List[str]    # , \n    result: str           #   ,   \ndef ExpertisedNode(state):\n    \"\"\"\n      !\n    \"\"\"",
        "detail": "llmrec.utils.namjoon.expertised",
        "documentation": {}
    },
    {
        "label": "ExpertisedNode",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.expertised",
        "description": "llmrec.utils.namjoon.expertised",
        "peekOfCode": "def ExpertisedNode(state):\n    \"\"\"\n      !\n    \"\"\"",
        "detail": "llmrec.utils.namjoon.expertised",
        "documentation": {}
    },
    {
        "label": "RecsysState",
        "kind": 6,
        "importPath": "llmrec.utils.namjoon.langgraph",
        "description": "llmrec.utils.namjoon.langgraph",
        "peekOfCode": "class RecsysState(TypedDict):\n    question: str                         # Query -  input\n    # question_type: str                    # Query  (,    ->   routing    )\n    # sub_question: List[str]               # Query anal    input\n    user_id: Optional[str]                #  \n    user_history: Optional[List[str]]               #  \n    web_search_result: Optional[str]      # web search \n    expertised_search: Optional[str]      #   \n    chat_messages: str                    #      \n    recommendations: Optional[List[str]]  #  ",
        "detail": "llmrec.utils.namjoon.langgraph",
        "documentation": {}
    },
    {
        "label": "GraphGenerate",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.langgraph",
        "description": "llmrec.utils.namjoon.langgraph",
        "peekOfCode": "def GraphGenerate():\n    graph = StateGraph(RecsysState)\n    graph.add_node(\"query\", queryAnalysis)\n    graph.add_node(\"web\", WebSearchNode)\n    graph.add_node(\"experts\", ExpertisedNode)\n    graph.add_node(\"chat\", ChatMessagesNode)\n    graph.add_node(\"ticket\", TicketNode)\n    graph.add_node(\"qa\", QANode)\n    graph.add_node(\"recommendation\", RecommendationNode)\n    # Set the Starting Edge",
        "detail": "llmrec.utils.namjoon.langgraph",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.langgraph",
        "description": "llmrec.utils.namjoon.langgraph",
        "peekOfCode": "def run(question):\n    app = GraphGenerate()\n    response = app.invoke({\n    \"messages\": [\n        HumanMessage(\n            content=question\n        )\n    ]})\n    return response",
        "detail": "llmrec.utils.namjoon.langgraph",
        "documentation": {}
    },
    {
        "label": "invoke_form",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "def invoke_form(doc):\n    content = f\"\"\"\n    <>\n    {doc.metadata[\" \"]}\n    </>\n    <>\n    {doc.metadata[\" \"]}\n    </>\n    <>\n    {doc.metadata[\" \"]}",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "format_docs",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "def format_docs(docs):\n    return \"\\n\\n\".join(invoke_form(doc) for doc in docs[0:1])\n# router ->  \n#   ?   \ndef router(chain, question):\n    # print(Fore.BLACK + f': {question}' + Style.RESET_ALL + '\\n')\n    response = chain.invoke(question)  #  /  / \n    new_response = \"None\"\n    # 1 \n    # DB ->  ",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "router",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "def router(chain, question):\n    # print(Fore.BLACK + f': {question}' + Style.RESET_ALL + '\\n')\n    response = chain.invoke(question)  #  /  / \n    new_response = \"None\"\n    # 1 \n    # DB ->  \n    if \"\" in response:\n        # print(\": \", response)\n        # DB    \n        #  ?   ",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "get_chain",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "def get_chain(question):\n    response = router(chain, question)\n    return response",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "embeddings_model",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\nvectorstore = Chroma(persist_directory='chromadb.sqlite', embedding_function=embeddings_model)\n# 1: ``` / ``` / ``` 3    \nchain = PromptTemplate.from_template(\"\"\"   , ``, ``  ``   .                                     \n    . \n<>\n{question}\n</>\n:\"\"\") | ChatUpstage() | StrOutputParser()\nsearch = DuckDuckGoSearchRun()",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "vectorstore",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "vectorstore = Chroma(persist_directory='chromadb.sqlite', embedding_function=embeddings_model)\n# 1: ``` / ``` / ``` 3    \nchain = PromptTemplate.from_template(\"\"\"   , ``, ``  ``   .                                     \n    . \n<>\n{question}\n</>\n:\"\"\") | ChatUpstage() | StrOutputParser()\nsearch = DuckDuckGoSearchRun()\nretriever = vectorstore.as_retriever(",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "chain",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "chain = PromptTemplate.from_template(\"\"\"   , ``, ``  ``   .                                     \n    . \n<>\n{question}\n</>\n:\"\"\") | ChatUpstage() | StrOutputParser()\nsearch = DuckDuckGoSearchRun()\nretriever = vectorstore.as_retriever(\n    search_type=\"similarity_score_threshold\",\n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01})  # Query    (K=4)",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "search",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "search = DuckDuckGoSearchRun()\nretriever = vectorstore.as_retriever(\n    search_type=\"similarity_score_threshold\",\n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01})  # Query    (K=4)\ntemplate_rec = \"\"\"\n  2      AI Chatbot PseudoRec.\n <>     . \n,    \"\" . \n<> \n{context}",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "retriever",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "retriever = vectorstore.as_retriever(\n    search_type=\"similarity_score_threshold\",\n    search_kwargs={\"k\": 1, \"score_threshold\": 0.01})  # Query    (K=4)\ntemplate_rec = \"\"\"\n  2      AI Chatbot PseudoRec.\n <>     . \n,    \"\" . \n<> \n{context}\n</> ",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "template_rec",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "template_rec = \"\"\"\n  2      AI Chatbot PseudoRec.\n <>     . \n,    \"\" . \n<> \n{context}\n</> \n<> \n{question}\n</> ",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "template_search",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "template_search = \"\"\"\n  2      AI Chatbot PseudoRec.\n<>\n{context}\n</>\n<> \n{question}\n</>\n <>   <>  . \n\"\"\"",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "template_chat",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "template_chat = \"\"\"\n  2      AI Chatbot PseudoRec.\n, ,     . \n<> \n{question}\n</>\n\"\"\"\ncustom_rec_prompt = PromptTemplate.from_template(template_rec)\ncustom_search_prompt = PromptTemplate.from_template(template_search)\ncustom_chat_prompt = PromptTemplate.from_template(template_chat)",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "custom_rec_prompt",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "custom_rec_prompt = PromptTemplate.from_template(template_rec)\ncustom_search_prompt = PromptTemplate.from_template(template_search)\ncustom_chat_prompt = PromptTemplate.from_template(template_chat)\n# {doc.metadata[\"  \"]}\ndef invoke_form(doc):\n    content = f\"\"\"\n    <>\n    {doc.metadata[\" \"]}\n    </>\n    <>",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "custom_search_prompt",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "custom_search_prompt = PromptTemplate.from_template(template_search)\ncustom_chat_prompt = PromptTemplate.from_template(template_chat)\n# {doc.metadata[\"  \"]}\ndef invoke_form(doc):\n    content = f\"\"\"\n    <>\n    {doc.metadata[\" \"]}\n    </>\n    <>\n    {doc.metadata[\" \"]}",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "custom_chat_prompt",
        "kind": 5,
        "importPath": "llmrec.utils.namjoon.namjoon_agent",
        "description": "llmrec.utils.namjoon.namjoon_agent",
        "peekOfCode": "custom_chat_prompt = PromptTemplate.from_template(template_chat)\n# {doc.metadata[\"  \"]}\ndef invoke_form(doc):\n    content = f\"\"\"\n    <>\n    {doc.metadata[\" \"]}\n    </>\n    <>\n    {doc.metadata[\" \"]}\n    </>",
        "detail": "llmrec.utils.namjoon.namjoon_agent",
        "documentation": {}
    },
    {
        "label": "QANode",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.qa",
        "description": "llmrec.utils.namjoon.qa",
        "peekOfCode": "def QANode(state):\n    \"\"\"\n        .\n    \"\"\"\ndef qaRouter(state):\n    \"\"\"\n         ,\n       .\n    \"\"\"\n    messages = state[\"messages\"]",
        "detail": "llmrec.utils.namjoon.qa",
        "documentation": {}
    },
    {
        "label": "qaRouter",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.qa",
        "description": "llmrec.utils.namjoon.qa",
        "peekOfCode": "def qaRouter(state):\n    \"\"\"\n         ,\n       .\n    \"\"\"\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if 'SUCCESS' in last_message:\n        return 'SUCCESS'\n    if 'web' in last_message:",
        "detail": "llmrec.utils.namjoon.qa",
        "documentation": {}
    },
    {
        "label": "RecommendationState",
        "kind": 6,
        "importPath": "llmrec.utils.namjoon.recommendation",
        "description": "llmrec.utils.namjoon.recommendation",
        "peekOfCode": "class RecommendationState(TypedDict):\n    \"\"\"\n       .\n     ,  state class     .\n    \"\"\"\n    question: str               # Query -  input\n    # question_type: str                  # Query  (,    ->   routing    )\n    # sub_question: List[str]             # Query anal    input\n    recommendations: str        #   \n    num_rec: str                #   ",
        "detail": "llmrec.utils.namjoon.recommendation",
        "documentation": {}
    },
    {
        "label": "queryClassifier",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.recommendation",
        "description": "llmrec.utils.namjoon.recommendation",
        "peekOfCode": "def queryClassifier(state):\n    \"\"\"\n        ,     .\n    \"\"\"\n    llm = ChatOpenAI(model = 'gpt-3.5-turbo')\n    prompt = \"\"\"\n    QUESTION:\n    {question}\n    GOAL:\n    * You are a bot that categorizes what kind of recommendation the user wants based on their input.",
        "detail": "llmrec.utils.namjoon.recommendation",
        "documentation": {}
    },
    {
        "label": "metaRecommend",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.recommendation",
        "description": "llmrec.utils.namjoon.recommendation",
        "peekOfCode": "def metaRecommend(state):\n    \"\"\"\n      .\n    RAG .\n    !\n    \"\"\"\n    answer = '   .'\n    return answer\ndef personalizedRecommend(state):\n    \"\"\"",
        "detail": "llmrec.utils.namjoon.recommendation",
        "documentation": {}
    },
    {
        "label": "personalizedRecommend",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.recommendation",
        "description": "llmrec.utils.namjoon.recommendation",
        "peekOfCode": "def personalizedRecommend(state):\n    \"\"\"\n     !\n    !\n    \"\"\"\n    answer = ['1','2','3']\n    return answer\ndef evaluation(state):\n    \"\"\"\n        .",
        "detail": "llmrec.utils.namjoon.recommendation",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.recommendation",
        "description": "llmrec.utils.namjoon.recommendation",
        "peekOfCode": "def evaluation(state):\n    \"\"\"\n        .\n    meta /      .\n    \"\"\"\n    if True:\n        return 'SUCCESS'\n    if False:\n        return 'REPEAT_META'\n    if False:",
        "detail": "llmrec.utils.namjoon.recommendation",
        "documentation": {}
    },
    {
        "label": "query_router",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.recommendation",
        "description": "llmrec.utils.namjoon.recommendation",
        "peekOfCode": "def query_router(state):\n    \"\"\"\n       .\n        .\n    \"\"\"\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if 'personal' in last_message:\n        return 'PERSONALIZED'\n    if 'meta' in last_message:",
        "detail": "llmrec.utils.namjoon.recommendation",
        "documentation": {}
    },
    {
        "label": "eval_router",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.recommendation",
        "description": "llmrec.utils.namjoon.recommendation",
        "peekOfCode": "def eval_router(state):\n    \"\"\"\n           .\n    \"\"\"\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if 'SUCCESS' in last_message:\n        return 'SUCCESS'\n    if 'MEAT_REPEAT' in last_message:\n        return 'REPEAT_META'",
        "detail": "llmrec.utils.namjoon.recommendation",
        "documentation": {}
    },
    {
        "label": "RecommendationNode",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.recommendation",
        "description": "llmrec.utils.namjoon.recommendation",
        "peekOfCode": "def RecommendationNode():\n    \"\"\"\n        .\n    \"\"\"\n    # Initialize a new graph\n    graph = StateGraph(RecommendationState)\n    # Define the two Nodes we will cycle between\n    graph.add_node(\"classifier\", queryClassifier)\n    graph.add_node(\"meta\", metaRecommend)\n    graph.add_node(\"personal\", personalizedRecommend)",
        "detail": "llmrec.utils.namjoon.recommendation",
        "documentation": {}
    },
    {
        "label": "ReservationState",
        "kind": 6,
        "importPath": "llmrec.utils.namjoon.ticket",
        "description": "llmrec.utils.namjoon.ticket",
        "peekOfCode": "class ReservationState(TypedDict):\n    question: str         #  \n    movie: str            # self query    \n    location: str         # \n    num_tickets: int      # \ndef TicketNode(state):\n    \"\"\"\n      !\n    \"\"\"",
        "detail": "llmrec.utils.namjoon.ticket",
        "documentation": {}
    },
    {
        "label": "TicketNode",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.ticket",
        "description": "llmrec.utils.namjoon.ticket",
        "peekOfCode": "def TicketNode(state):\n    \"\"\"\n      !\n    \"\"\"",
        "detail": "llmrec.utils.namjoon.ticket",
        "documentation": {}
    },
    {
        "label": "queryAnalysis",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.utils",
        "description": "llmrec.utils.namjoon.utils",
        "peekOfCode": "def queryAnalysis(state):\n    \"\"\"\n     input  routing  query .\n    (     .)\n    \"\"\"\n    llm = ChatOpenAI(model = 'gpt-3.5-turbo')\n    prompt = \"\"\"\n      QUESTION:\n      {question}\n      GOAL:",
        "detail": "llmrec.utils.namjoon.utils",
        "documentation": {}
    },
    {
        "label": "queryAnalRouter",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.utils",
        "description": "llmrec.utils.namjoon.utils",
        "peekOfCode": "def queryAnalRouter(state):\n    \"\"\"\n     input      .\n    \"\"\"\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if '' in last_message:\n        return 'chat'\n    if '' in last_message:\n        return 'recommendation'",
        "detail": "llmrec.utils.namjoon.utils",
        "documentation": {}
    },
    {
        "label": "WebSearchState",
        "kind": 6,
        "importPath": "llmrec.utils.namjoon.websearch",
        "description": "llmrec.utils.namjoon.websearch",
        "peekOfCode": "class WebSearchState(TypedDict):\n    question: str\n    sub_question: List[str]\n    num_search: int\n    num_repeat: int\n    inspection_results: List[str]\ndef WebSearchNode(state):\n    \"\"\"\n      !\n    \"\"\"",
        "detail": "llmrec.utils.namjoon.websearch",
        "documentation": {}
    },
    {
        "label": "WebSearchNode",
        "kind": 2,
        "importPath": "llmrec.utils.namjoon.websearch",
        "description": "llmrec.utils.namjoon.websearch",
        "peekOfCode": "def WebSearchNode(state):\n    \"\"\"\n      !\n    \"\"\"",
        "detail": "llmrec.utils.namjoon.websearch",
        "documentation": {}
    },
    {
        "label": "run_query",
        "kind": 2,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "def run_query(uri, user, password, query, params):\n    driver = GraphDatabase.driver(uri, auth=(user, password))\n    with driver.session() as session:\n        # print(params)\n        result = session.run(query, params)\n        # print(result)\n        return [record for record in result]\ndef vector_graph_qa(query):\n    query_vector = embeddings.embed_query(query)\n    # print(query_vector)",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "vector_graph_qa",
        "kind": 2,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "def vector_graph_qa(query):\n    query_vector = embeddings.embed_query(query)\n    # print(query_vector)\n    uri = neo4j_uri\n    user = neo4j_user\n    password = neo4j_password\n    params = {'queryVector':query_vector}\n    cypher_query = \"\"\"\n    CALL db.index.vector.queryNodes('queryVector', 5, $queryVector)\n    YIELD node AS doc, score",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "get_results",
        "kind": 2,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "def get_results(question):\n    start = timer()\n    try:\n        chat_llm = ChatOpenAI(\n            model = \"gpt-3.5-turbo-0125\",\n            temperature=0,\n            openai_api_key=openai_key,\n        )   \n        df = vector_graph_qa(question)\n        # print('df : ', df)",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "os.environ[\"OPENAI_API_KEY\"]",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") \nopenai_key = os.environ[\"OPENAI_API_KEY\"]\nos.environ[\"NEO4J_URI\"] = os.getenv(\"NEO4J_URI\")\nos.environ[\"NEO4J_USERNAME\"] =os.getenv(\"NEO4J_USERNAME\")\nos.environ[\"NEO4J_PASSWORD\"] =os.getenv(\"NEO4J_PASSWORD\")\nneo4j_uri = os.environ[\"NEO4J_URI\"]\nneo4j_user = os.environ[\"NEO4J_USERNAME\"]\nneo4j_password = os.environ[\"NEO4J_PASSWORD\"] \nSYSTEM_PROMPT = \"\"\"You are a movie expert who recommends movies.\n* Create answers in Korean",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "openai_key",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "openai_key = os.environ[\"OPENAI_API_KEY\"]\nos.environ[\"NEO4J_URI\"] = os.getenv(\"NEO4J_URI\")\nos.environ[\"NEO4J_USERNAME\"] =os.getenv(\"NEO4J_USERNAME\")\nos.environ[\"NEO4J_PASSWORD\"] =os.getenv(\"NEO4J_PASSWORD\")\nneo4j_uri = os.environ[\"NEO4J_URI\"]\nneo4j_user = os.environ[\"NEO4J_USERNAME\"]\nneo4j_password = os.environ[\"NEO4J_PASSWORD\"] \nSYSTEM_PROMPT = \"\"\"You are a movie expert who recommends movies.\n* Create answers in Korean\n* If the question is not about a movie recommendation, please answer like this:",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "os.environ[\"NEO4J_URI\"]",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "os.environ[\"NEO4J_URI\"] = os.getenv(\"NEO4J_URI\")\nos.environ[\"NEO4J_USERNAME\"] =os.getenv(\"NEO4J_USERNAME\")\nos.environ[\"NEO4J_PASSWORD\"] =os.getenv(\"NEO4J_PASSWORD\")\nneo4j_uri = os.environ[\"NEO4J_URI\"]\nneo4j_user = os.environ[\"NEO4J_USERNAME\"]\nneo4j_password = os.environ[\"NEO4J_PASSWORD\"] \nSYSTEM_PROMPT = \"\"\"You are a movie expert who recommends movies.\n* Create answers in Korean\n* If the question is not about a movie recommendation, please answer like this:\nSorry, I can only answer questions related to movie recommendations.",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "neo4j_uri",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "neo4j_uri = os.environ[\"NEO4J_URI\"]\nneo4j_user = os.environ[\"NEO4J_USERNAME\"]\nneo4j_password = os.environ[\"NEO4J_PASSWORD\"] \nSYSTEM_PROMPT = \"\"\"You are a movie expert who recommends movies.\n* Create answers in Korean\n* If the question is not about a movie recommendation, please answer like this:\nSorry, I can only answer questions related to movie recommendations.\n* Don't answer the same sentence repeatedly.\n\"\"\"\nPROMPT_TEMPLATE = \"\"\"",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "neo4j_user",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "neo4j_user = os.environ[\"NEO4J_USERNAME\"]\nneo4j_password = os.environ[\"NEO4J_PASSWORD\"] \nSYSTEM_PROMPT = \"\"\"You are a movie expert who recommends movies.\n* Create answers in Korean\n* If the question is not about a movie recommendation, please answer like this:\nSorry, I can only answer questions related to movie recommendations.\n* Don't answer the same sentence repeatedly.\n\"\"\"\nPROMPT_TEMPLATE = \"\"\"\n{questions}",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "neo4j_password",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "neo4j_password = os.environ[\"NEO4J_PASSWORD\"] \nSYSTEM_PROMPT = \"\"\"You are a movie expert who recommends movies.\n* Create answers in Korean\n* If the question is not about a movie recommendation, please answer like this:\nSorry, I can only answer questions related to movie recommendations.\n* Don't answer the same sentence repeatedly.\n\"\"\"\nPROMPT_TEMPLATE = \"\"\"\n{questions}\nHere is the context in JSON format. This dataset contains information about movies that will be recommended to the user.",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "SYSTEM_PROMPT",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "SYSTEM_PROMPT = \"\"\"You are a movie expert who recommends movies.\n* Create answers in Korean\n* If the question is not about a movie recommendation, please answer like this:\nSorry, I can only answer questions related to movie recommendations.\n* Don't answer the same sentence repeatedly.\n\"\"\"\nPROMPT_TEMPLATE = \"\"\"\n{questions}\nHere is the context in JSON format. This dataset contains information about movies that will be recommended to the user.\n<context>",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "PROMPT_TEMPLATE",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "PROMPT_TEMPLATE = \"\"\"\n{questions}\nHere is the context in JSON format. This dataset contains information about movies that will be recommended to the user.\n<context>\n{context}\n</context>\nWhen recommending movies to a user related to a question, make sure to recommend at least five movies included in the context!\nCreate answers in Korean\nPlease add the following phrase at the end of your answer : \nWere you satisfied with the answer through GraphRAG? ",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "PROMPT",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "PROMPT = PromptTemplate(\n    input_variables=[\"questions\",\"context\"], template= PROMPT_TEMPLATE\n)\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\ndef run_query(uri, user, password, query, params):\n    driver = GraphDatabase.driver(uri, auth=(user, password))\n    with driver.session() as session:\n        # print(params)\n        result = session.run(query, params)\n        # print(result)",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "llmrec.utils.soonhyeok.GraphRAG",
        "description": "llmrec.utils.soonhyeok.GraphRAG",
        "peekOfCode": "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\ndef run_query(uri, user, password, query, params):\n    driver = GraphDatabase.driver(uri, auth=(user, password))\n    with driver.session() as session:\n        # print(params)\n        result = session.run(query, params)\n        # print(result)\n        return [record for record in result]\ndef vector_graph_qa(query):\n    query_vector = embeddings.embed_query(query)",
        "detail": "llmrec.utils.soonhyeok.GraphRAG",
        "documentation": {}
    },
    {
        "label": "log_llm",
        "kind": 2,
        "importPath": "llmrec.utils.log_questions",
        "description": "llmrec.utils.log_questions",
        "peekOfCode": "def log_llm(request, model_name, question='', answer='', _from=''):\n    username, session_id = get_username_sid(request, _from=_from)\n    log = {\n        'userId': username,\n        'sessionId': session_id,\n        'model': model_name,\n        'timestamp': int(time.time()),\n        'question' : question,\n        'answer': answer\n    }",
        "detail": "llmrec.utils.log_questions",
        "documentation": {}
    },
    {
        "label": "table_llm",
        "kind": 5,
        "importPath": "llmrec.utils.log_questions",
        "description": "llmrec.utils.log_questions",
        "peekOfCode": "table_llm = DynamoDBClient(table_name='llm')\ndef log_llm(request, model_name, question='', answer='', _from=''):\n    username, session_id = get_username_sid(request, _from=_from)\n    log = {\n        'userId': username,\n        'sessionId': session_id,\n        'model': model_name,\n        'timestamp': int(time.time()),\n        'question' : question,\n        'answer': answer",
        "detail": "llmrec.utils.log_questions",
        "documentation": {}
    },
    {
        "label": "LlmrecConfig",
        "kind": 6,
        "importPath": "llmrec.apps",
        "description": "llmrec.apps",
        "peekOfCode": "class LlmrecConfig(AppConfig):\n    default_auto_field = 'django.db.models.BigAutoField'\n    name = 'llmrec'",
        "detail": "llmrec.apps",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "llmrec.urls",
        "description": "llmrec.urls",
        "peekOfCode": "urlpatterns = [\n    path(\"pplrec/\", pplrec),\n    path(\"hyeonwoo/\", llmrec_hyeonwoo),\n    path(\"namjoon/\", llmrec_namjoon),\n    path(\"kyeongchan/\", llmrec_kyeongchan),\n    # path('get_initial_recommendation/', get_initial_recommendation, name='get_initial_recommendation'),\n    path(\"minsang/\", llmrec_minsang),\n    path(\"soonhyeok/\", llmrec_soonhyeok),\n    path(\"gyungah/\", llmrec_gyungah),\n    path(\"stream_chat\", llmrec_kyeongchan),",
        "detail": "llmrec.urls",
        "documentation": {}
    },
    {
        "label": "get_model_kyeongchan",
        "kind": 2,
        "importPath": "llmrec.utils",
        "description": "llmrec.utils",
        "peekOfCode": "def get_model_kyeongchan():\n    return ChatOpenAI(model='gpt-3.5-turbo', openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\nkyeongchan_model = get_model_kyeongchan()",
        "detail": "llmrec.utils",
        "documentation": {}
    },
    {
        "label": "kyeongchan_model",
        "kind": 5,
        "importPath": "llmrec.utils",
        "description": "llmrec.utils",
        "peekOfCode": "kyeongchan_model = get_model_kyeongchan()",
        "detail": "llmrec.utils",
        "documentation": {}
    },
    {
        "label": "pplrec",
        "kind": 2,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "def pplrec(request):\n    log_tracking(request=request, view='pplrec')\n    username, session_id = get_username_sid(request, _from='llmrec/pplrec GET')\n    if request.method == 'POST':\n        try:\n            data = json.loads(request.body.decode('utf-8'))\n            message = data.get('message', '')\n            #  message   \n            question = message.get('text')\n            log_llm(request=request, question=question, model_name='pplrec')",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_hyeonwoo",
        "kind": 2,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "def llmrec_hyeonwoo(request):\n    log_tracking(request=request, view='hyeonwoo')\n    if request.method == 'POST':\n        try:\n            data = json.loads(request.body.decode('utf-8'))\n            message = data.get('message', '')\n            #  message   \n            question = message.get('text')\n            log_llm(request=request, question=question, model_name='hyeonwoo')\n            print(f\"[{message.get('timestamp')}]{message.get('sender')} : {message.get('text')}\")",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_namjoon",
        "kind": 2,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "def llmrec_namjoon(request):\n    log_tracking(request=request, view='namjoon')\n    if request.method == 'POST':\n        try:\n            data = json.loads(request.body.decode('utf-8'))\n            message = data.get('message', '')\n            question = message.get('text')\n            log_llm(request=request, question=question, model_name='namjoon')\n            #  message   \n            # TODO :    multi-turn?    . , ,    .",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_kyeongchan",
        "kind": 2,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "def llmrec_kyeongchan(request):\n    username, session_id = get_username_sid(request, _from='llmrec_kyeongchan')\n    if request.method == 'GET':\n        log_tracking(request=request, view='kyeongchan')\n        user_logs_df = get_user_logs_df(username, session_id)\n        print(f\"user_logs_df : \\n{user_logs_df}\")\n        if len(user_logs_df):\n            interacted_movie_d = get_interacted_movie_dicts(user_logs_df)\n            context = {\n                'description1': \" - LLM   \",",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_minsang",
        "kind": 2,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "def llmrec_minsang(request):\n    log_tracking(request=request, view='minsang')\n    if request.method == 'POST':\n        try:\n            data = json.loads(request.body.decode('utf-8'))\n            message = data.get('message', '')\n            question = message.get('text')\n            log_llm(request=request, question=question, model_name='minsang')\n            #  message   \n            # TODO :    multi-turn?    . , ,    .",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_soonhyeok",
        "kind": 2,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "def llmrec_soonhyeok(request):\n    log_tracking(request=request, view='soonhyeok')\n    if request.method == 'POST':\n        try:\n            data = json.loads(request.body.decode('utf-8'))\n            message = data.get('message', '')\n            question = message.get('text')\n            log_llm(request=request, question=question, model_name='soonhyeok')\n            #  message   \n            # TODO :    multi-turn?    . , ,    .",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "llmrec_gyungah",
        "kind": 2,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "def llmrec_gyungah(request):\n    log_tracking(request=request, view='gyungah')\n    if request.method == 'POST':\n        try:\n            data = json.loads(request.body.decode('utf-8'))\n            message = data.get('message', '')\n            question = message.get('text')\n            log_llm(request=request, question=question, model_name='gyungah')\n            new_response = g_get_chain(question)\n            log_llm(request=request, answer=new_response, model_name='gyungah')",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "mysql",
        "kind": 5,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "mysql = MysqlClient()\nload_dotenv('.env.dev')\ntable_llm = DynamoDBClient(table_name='llm')\ntable_clicklog = DynamoDBClient(table_name='clicklog')\n@csrf_exempt\ndef pplrec(request):\n    log_tracking(request=request, view='pplrec')\n    username, session_id = get_username_sid(request, _from='llmrec/pplrec GET')\n    if request.method == 'POST':\n        try:",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "table_llm",
        "kind": 5,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "table_llm = DynamoDBClient(table_name='llm')\ntable_clicklog = DynamoDBClient(table_name='clicklog')\n@csrf_exempt\ndef pplrec(request):\n    log_tracking(request=request, view='pplrec')\n    username, session_id = get_username_sid(request, _from='llmrec/pplrec GET')\n    if request.method == 'POST':\n        try:\n            data = json.loads(request.body.decode('utf-8'))\n            message = data.get('message', '')",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "table_clicklog",
        "kind": 5,
        "importPath": "llmrec.views",
        "description": "llmrec.views",
        "peekOfCode": "table_clicklog = DynamoDBClient(table_name='clicklog')\n@csrf_exempt\ndef pplrec(request):\n    log_tracking(request=request, view='pplrec')\n    username, session_id = get_username_sid(request, _from='llmrec/pplrec GET')\n    if request.method == 'POST':\n        try:\n            data = json.loads(request.body.decode('utf-8'))\n            message = data.get('message', '')\n            #  message   ",
        "detail": "llmrec.views",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "movie.migrations.0001_initial",
        "description": "movie.migrations.0001_initial",
        "peekOfCode": "class Migration(migrations.Migration):\n    initial = True\n    dependencies = [\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='WatchedMovie',\n            fields=[\n                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('name', models.CharField(max_length=30)),",
        "detail": "movie.migrations.0001_initial",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "movie.migrations.0002_daummovies_delete_watchedmovie",
        "description": "movie.migrations.0002_daummovies_delete_watchedmovie",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('movie', '0001_initial'),\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='DaumMovies',\n            fields=[\n                ('movieid', models.AutoField(db_column='movieId', primary_key=True, serialize=False)),\n                ('titleko', models.CharField(blank=True, db_column='titleKo', max_length=100, null=True)),",
        "detail": "movie.migrations.0002_daummovies_delete_watchedmovie",
        "documentation": {}
    },
    {
        "label": "KPRNPredictor",
        "kind": 6,
        "importPath": "movie.predictors.kprn_predictor",
        "description": "movie.predictors.kprn_predictor",
        "peekOfCode": "class KPRNPredictor:\n    def __init__(self):\n        self.dir = 'pytorch_models/kprn'\n        self.topk = 30\n        params = self.load_params()\n        self.model = KPRN(params[\"ENTITY_EMB_DIM\"], params[\"TYPE_EMB_DIM\"], params[\"REL_EMB_DIM\"], params[\"HIDDEN_DIM\"],\n                 params[\"ENTITY_NUM\"], params[\"TYPE_NUM\"], params[\"RELATION_NUM\"], params[\"TAG_SIZE\"], False)\n        checkpoint = torch.load(os.path.join(self.dir, 'kprn.pt'), map_location=torch.device(\"cpu\"))\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.model.eval()",
        "detail": "movie.predictors.kprn_predictor",
        "documentation": {}
    },
    {
        "label": "kprn_predictor",
        "kind": 5,
        "importPath": "movie.predictors.kprn_predictor",
        "description": "movie.predictors.kprn_predictor",
        "peekOfCode": "kprn_predictor = KPRNPredictor()",
        "detail": "movie.predictors.kprn_predictor",
        "documentation": {}
    },
    {
        "label": "MFPredictor",
        "kind": 6,
        "importPath": "movie.predictors.mf_predictor",
        "description": "movie.predictors.mf_predictor",
        "peekOfCode": "class MFPredictor:\n    def __init__(self):\n        self.dir = 'pytorch_models/general_mf'\n        self.topk = 30\n        params = self.load_params()\n        self.mf_model = BPRMFTrainer(self.dir, params[\"n_features\"], params[\"learning_rate\"], \n                                     params[\"reg_lambda\"], params[\"num_epochs\"], params[\"batch_size\"], params[\"patience\"], \n                                     params[\"num_negatives\"], path=self.dir+'/pth/bpr_mf_model_20.pth')\n        self.item_id_map = self.load_dict_from_pickle(self.dir+'/data/item_dict.pkl')\n        self.pop_movie = self.load_dict_from_pickle(self.dir+'/data/pop_movie200.pkl')",
        "detail": "movie.predictors.mf_predictor",
        "documentation": {}
    },
    {
        "label": "mf_predictor",
        "kind": 5,
        "importPath": "movie.predictors.mf_predictor",
        "description": "movie.predictors.mf_predictor",
        "peekOfCode": "mf_predictor = MFPredictor()",
        "detail": "movie.predictors.mf_predictor",
        "documentation": {}
    },
    {
        "label": "NgcfPredictor",
        "kind": 6,
        "importPath": "movie.predictors.ngcf_predictor",
        "description": "movie.predictors.ngcf_predictor",
        "peekOfCode": "class NgcfPredictor:\n    def __init__(self):\n        self.args = parse_args()\n        self.device = 'cuda'\n        self.num_recommendations = 30\n        self.num_epochs = 10\n    def sample(self, users, items):\n        def sample_pos_items_for_u(u, num):\n            # sample num pos items for u-th user\n            pos_items = items",
        "detail": "movie.predictors.ngcf_predictor",
        "documentation": {}
    },
    {
        "label": "ngcf_predictor",
        "kind": 5,
        "importPath": "movie.predictors.ngcf_predictor",
        "description": "movie.predictors.ngcf_predictor",
        "peekOfCode": "ngcf_predictor = NgcfPredictor()",
        "detail": "movie.predictors.ngcf_predictor",
        "documentation": {}
    },
    {
        "label": "NgcfPredictor",
        "kind": 6,
        "importPath": "movie.predictors.ngcf_predictor_embed",
        "description": "movie.predictors.ngcf_predictor_embed",
        "peekOfCode": "class NgcfPredictor:\n    def __init__(self):\n        self.args = parse_args()\n        self.device = 'cpu'\n        self.num_recommendations = 20\n        self.index_path = \"pytorch_models/ngcf/ngcf-item-embed.index\"\n    def predict(self, interacted_items):\n        \"\"\" #   (          or    checkpoint     new_num_user  ) ->  ..\n        checkpoint = torch.load('NGCF.pkl')\n        checkpoint_dict = dict(OrderedDict(checkpoint))",
        "detail": "movie.predictors.ngcf_predictor_embed",
        "documentation": {}
    },
    {
        "label": "ngcf_predictor",
        "kind": 5,
        "importPath": "movie.predictors.ngcf_predictor_embed",
        "description": "movie.predictors.ngcf_predictor_embed",
        "peekOfCode": "ngcf_predictor = NgcfPredictor()",
        "detail": "movie.predictors.ngcf_predictor_embed",
        "documentation": {}
    },
    {
        "label": "MovieConfig",
        "kind": 6,
        "importPath": "movie.apps",
        "description": "movie.apps",
        "peekOfCode": "class MovieConfig(AppConfig):\n    default_auto_field = 'django.db.models.BigAutoField'\n    name = 'movie'",
        "detail": "movie.apps",
        "documentation": {}
    },
    {
        "label": "DaumMovies",
        "kind": 6,
        "importPath": "movie.models",
        "description": "movie.models",
        "peekOfCode": "class DaumMovies(models.Model):\n    movieid = models.AutoField(db_column='movieId', primary_key=True)  # Field name made lowercase.\n    titleko = models.CharField(db_column='titleKo', max_length=100, blank=True, null=True)  # Field name made lowercase.\n    titleen = models.CharField(db_column='titleEn', max_length=100, blank=True, null=True)  # Field name made lowercase.\n    synopsis = models.TextField(blank=True, null=True)\n    cast = models.CharField(max_length=10000, blank=True, null=True)\n    mainpageurl = models.TextField(db_column='mainPageUrl', blank=True, null=True)  # Field name made lowercase.\n    posterurl = models.TextField(db_column='posterUrl', blank=True, null=True)  # Field name made lowercase.\n    numofsiteratings = models.IntegerField(db_column='numOfSiteRatings', blank=True, null=True)  # Field name made lowercase.\n    class Meta:",
        "detail": "movie.models",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "movie.urls",
        "description": "movie.urls",
        "peekOfCode": "urlpatterns = [\n    path(\"\", home),\n    path(\"movierecommendation/\", home),\n    path(\"<int:movie_id>\", movie_detail),\n    path(\"search/<str:keyword>/\", search),\n    path(\"sasrec/\", sasrec),\n    path(\"ngcf/\", ngcf),\n    path(\"kprn/\", kprn),\n    path(\"mf/\", general_mf),\n    path('delete_movie_interaction/', delete_movie_interaction, name='delete_movie_interaction'),",
        "detail": "movie.urls",
        "documentation": {}
    },
    {
        "label": "get_pop",
        "kind": 2,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "def get_pop(mysql):\n    print(f\"get popular movies..\")\n    daum_ratings = mysql.get_daum_ratings()\n    daum_ratings = daum_ratings[daum_ratings['nickName'].map(lambda x: x not in [' ', '', '  ', ''])]\n    daum_movies = mysql.get_daum_movies()\n    merged = pd.merge(left=daum_ratings, right=daum_movies, how='left', on='movieId')[\n        ['nickName', 'movieId', 'titleKo', 'rating', 'timestamp', 'numOfSiteRatings']]\n    average_ratings = merged.groupby('movieId')['rating'].mean().reset_index()\n    #    \n    rating_mean_dict = dict(zip(average_ratings['movieId'], average_ratings['rating']))",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "add_past_rating",
        "kind": 2,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "def add_past_rating(username, session_id, recomm_result: List[Dict]):\n    if username != 'Anonymous':\n        user_logs_df = table_clicklog.get_a_user_logs(user_name=username)\n    elif username == 'Anonymous' and session_id is not None:\n        user_logs_df = table_clicklog.get_a_session_logs(session_id=session_id)\n    elif session_id is None:\n        user_logs_df = pd.DataFrame()\n    if 'star' in user_logs_df.columns:\n        star_df = user_logs_df[user_logs_df['star'].notnull()].drop_duplicates(subset=['titleKo'], keep='last')\n        movie2rating = dict(zip(star_df['movieId'].astype(int), star_df['star'].astype(int)))",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "add_rank",
        "kind": 2,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "def add_rank(recomm_result):\n    for rank, one_movie_d in enumerate(recomm_result, start=1):\n        one_movie_d['rank'] = rank\n    return recomm_result\ndef get_username_sid(request, _from=''):\n    if not request.user.is_authenticated:\n        print(f\"[{_from}/get_username_sid()] user not authenticated. username : Anonymous\")\n        username = 'Anonymous'\n    else:\n        username = request.user.username",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_username_sid",
        "kind": 2,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "def get_username_sid(request, _from=''):\n    if not request.user.is_authenticated:\n        print(f\"[{_from}/get_username_sid()] user not authenticated. username : Anonymous\")\n        username = 'Anonymous'\n    else:\n        username = request.user.username\n    session_id = request.session.session_key\n    print(f\"[{_from}/get_username_sid()] username : {username}, session_id : {session_id}\")\n    return username, session_id\ndef get_user_logs_df(username, session_id):",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_user_logs_df",
        "kind": 2,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "def get_user_logs_df(username, session_id):\n    if username != 'Anonymous':\n        user_logs_df = table_clicklog.get_a_user_logs(user_name=username)\n    elif username == 'Anonymous' and session_id is not None:\n        user_logs_df = table_clicklog.get_a_session_logs(session_id=session_id)\n    elif session_id is None:\n        user_logs_df = pd.DataFrame()\n    return user_logs_df\ndef get_interacted_movie_dicts(user_logs_df, k=50):\n    user_logs_df['timestamp'] = user_logs_df['timestamp'].astype(int)  # timestamp   ",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_interacted_movie_dicts",
        "kind": 2,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "def get_interacted_movie_dicts(user_logs_df, k=50):\n    user_logs_df['timestamp'] = user_logs_df['timestamp'].astype(int)  # timestamp   \n    top_k_logs_df = user_logs_df.nlargest(k, 'timestamp')\n    if 'star' in top_k_logs_df:\n        top_k_logs_df['star'] = top_k_logs_df['star'].map(lambda x: float(int(x) / 2) if not pd.isna(x) else 'click')\n    else:\n        top_k_logs_df['star'] = 'click'\n    interacted_movie_d = top_k_logs_df[['movieId', 'titleKo', 'timestamp', 'star']].to_dict(orient='records')\n    movie_ids = [int(obs['movieId']) for obs in interacted_movie_d]\n    poster_urls = get_poster_urls(movie_ids)",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "log_tracking",
        "kind": 2,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "def log_tracking(request, view):\n    username, session_id = get_username_sid(request, _from='log_tracking')\n    log = {\n        'userId': username,\n        'sessionId': session_id,\n        'view': view,\n        'timestamp': int(time.time()),\n    }\n    table_tracking.put_item(click_log=log)\ndef get_poster_urls(movie_ids):",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "get_poster_urls",
        "kind": 2,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "def get_poster_urls(movie_ids):\n    movies = DaumMovies.objects.filter(movieid__in=movie_ids).values('movieid', 'posterurl')\n    return {movie['movieid']: movie['posterurl'] for movie in movies}",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "table_clicklog",
        "kind": 5,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "table_clicklog = DynamoDBClient(table_name='clicklog')\ntable_tracking = DynamoDBClient(table_name='tracking')\ndef get_pop(mysql):\n    print(f\"get popular movies..\")\n    daum_ratings = mysql.get_daum_ratings()\n    daum_ratings = daum_ratings[daum_ratings['nickName'].map(lambda x: x not in [' ', '', '  ', ''])]\n    daum_movies = mysql.get_daum_movies()\n    merged = pd.merge(left=daum_ratings, right=daum_movies, how='left', on='movieId')[\n        ['nickName', 'movieId', 'titleKo', 'rating', 'timestamp', 'numOfSiteRatings']]\n    average_ratings = merged.groupby('movieId')['rating'].mean().reset_index()",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "table_tracking",
        "kind": 5,
        "importPath": "movie.utils",
        "description": "movie.utils",
        "peekOfCode": "table_tracking = DynamoDBClient(table_name='tracking')\ndef get_pop(mysql):\n    print(f\"get popular movies..\")\n    daum_ratings = mysql.get_daum_ratings()\n    daum_ratings = daum_ratings[daum_ratings['nickName'].map(lambda x: x not in [' ', '', '  ', ''])]\n    daum_movies = mysql.get_daum_movies()\n    merged = pd.merge(left=daum_ratings, right=daum_movies, how='left', on='movieId')[\n        ['nickName', 'movieId', 'titleKo', 'rating', 'timestamp', 'numOfSiteRatings']]\n    average_ratings = merged.groupby('movieId')['rating'].mean().reset_index()\n    #    ",
        "detail": "movie.utils",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def home(request):\n    print(f\"movie/home view\".ljust(100, '>'))\n    log_tracking(request=request, view='home')\n    if request.method == \"POST\":\n        pass  # home POST   \n    else:\n        print(f\"Home - GET\")\n        username, session_id = get_username_sid(request, _from='movie/home GET')\n        user_logs_df = get_user_logs_df(username, session_id)\n        if len(user_logs_df):  #   ",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "sasrec",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def sasrec(request):\n    print(f\"movie/sasrec view\".ljust(100, '>'))\n    log_tracking(request=request, view='sasrec')\n    username, session_id = get_username_sid(request, _from='movie/sasrec')\n    user_logs_df = get_user_logs_df(username, session_id)\n    if len(user_logs_df):  #   \n        interacted_movie_ids = [int(mid) for mid in user_logs_df['movieId'] if mid is not None and not pd.isna(mid)]\n        interacted_movie_d = get_interacted_movie_dicts(user_logs_df)\n        # sasrec_recomm_mids = sasrec_predictor.predict(dbids=interacted_movie_ids)\n        url = \"http://15.165.169.138:7001/sasrec/\"",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "ngcf",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def ngcf(request):\n    print(f\"movie/ngcf view\".ljust(100, '>'))\n    log_tracking(request=request, view='ngcf')\n    username, session_id = get_username_sid(request, _from='movie/ngcf')\n    user_logs_df = get_user_logs_df(username, session_id)\n    if len(user_logs_df):  #   \n        interacted_movie_ids = [int(mid) for mid in user_logs_df['movieId'] if mid is not None and not pd.isna(mid)]\n        interacted_movie_dicts = get_interacted_movie_dicts(user_logs_df)\n            # FastAPI    \n        url = \"http://34.71.71.79:7000/ngcf/recommend/\"  # FastAPI  ",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "kprn",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def kprn(request):\n    print(f\"movie/kprn view\".ljust(100, '>'))\n    log_tracking(request=request, view='kprn')\n    username, session_id = get_username_sid(request, _from='movie_kprn')\n    user_logs_df = get_user_logs_df(username, session_id)\n    if len(user_logs_df):  #   \n        interacted_movie_ids = [int(mid) for mid in user_logs_df['movieId'] if mid is not None and not pd.isna(mid)]\n        interacted_movie_dicts = get_interacted_movie_dicts(user_logs_df)\n        url = \"http://15.165.169.138:7001/kprn/\"\n        headers = {",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "general_mf",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def general_mf(request):\n    print(f\"movie/general_mf view\".ljust(100, '>'))\n    log_tracking(request=request, view='general_mf')\n    username, session_id = get_username_sid(request, _from='movie_general_mf')\n    user_logs_df = get_user_logs_df(username, session_id)\n    if len(user_logs_df):  #   \n        interacted_movie_ids = [int(mid) for mid in user_logs_df['movieId'] if mid is not None and not pd.isna(mid)]\n        interacted_movie_dicts = get_interacted_movie_dicts(user_logs_df)\n        mf_recomm_mids = mf_predictor.predict(9360, dbids=interacted_movie_ids)\n        mf_recomm = list(DaumMovies.objects.filter(movieid__in=mf_recomm_mids).values())",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "log_click",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def log_click(request):\n    print(f\"movie/log_click view\".ljust(100, '>'))\n    log_tracking(request=request, view='click')\n    username, session_id = get_username_sid(request, _from='movie/log_click')\n    print(f\"[movie/log_click] method : {request.method}\")\n    if request.method == \"POST\":\n        data = json.loads(request.body.decode('utf-8'))\n        print(f\"[movie/log_click] data : {data}\")\n        movie_title = data.get('movie_title')\n        page_url = data.get('page_url')",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "log_star",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def log_star(request):\n    print(f\"movie/log_star view\".ljust(100, '>'))\n    log_tracking(request=request, view='star')\n    username, session_id = get_username_sid(request)\n    data = json.loads(request.body.decode('utf-8'))\n    percentage = data.get('percentage')\n    movie_title = data.get('movie_title')\n    page_url = data.get('page_url')\n    movie_id = data.get('movie_id')\n    click_log = {",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "movie_detail",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def movie_detail(request, movie_id):\n    print(f\"movie/movie_detail view\".ljust(100, '>'))\n    log_tracking(request=request, view='movie_detail')\n    context = {\n        'movie': DaumMovies.objects.get(movieid=movie_id)\n    }\n    print(f\"context completed : {context}\")\n    return render(request, \"movie_detail.html\", context=context)\n@csrf_exempt\ndef search(request, keyword):",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "search",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def search(request, keyword):\n    print(f\"movie/search view\".ljust(100, '>'))\n    log_tracking(request=request, view='search')\n    if keyword:\n        searched_movies = DaumMovies.objects.filter(titleko__contains=keyword)\n    else:\n        searched_movies = None\n    username, session_id = get_username_sid(request, _from='movie/sasrec')\n    user_logs_df = get_user_logs_df(username, session_id)\n    if len(user_logs_df):  #   ",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "delete_movie_interaction",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def delete_movie_interaction(request):\n    username, session_id = get_username_sid(request)\n    if request.method == 'POST':\n        # POST    JSON   .\n        data = json.loads(request.body)\n        timestamp = data.get('timestamp')\n        movie_id = data.get('movieId')\n        table_clicklog.table.delete_item(\n            Key={\"userId\": username, \"timestamp\": int(timestamp)},\n        )",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "delete_all_interactions",
        "kind": 2,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "def delete_all_interactions(request):\n    username, session_id = get_username_sid(request)\n    if request.method == 'POST':\n        user_logs_df = get_user_logs_df(username, session_id)\n        keys_to_delete = []\n        response = table_clicklog.table.scan(\n            FilterExpression=boto3.dynamodb.conditions.Attr('userId').eq(username)\n        )\n        for item in response['Items']:\n            keys_to_delete.append({",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "mysql",
        "kind": 5,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "mysql = MysqlClient()\npop_movies_ids = get_pop(mysql)\npop_movies = list(DaumMovies.objects.filter(movieid__in=pop_movies_ids).values())\npop_movies = sorted(pop_movies, key=lambda x: pop_movies_ids.index(x['movieid']))\ntable_clicklog = DynamoDBClient(table_name='clicklog')\ndef home(request):\n    print(f\"movie/home view\".ljust(100, '>'))\n    log_tracking(request=request, view='home')\n    if request.method == \"POST\":\n        pass  # home POST   ",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "pop_movies_ids",
        "kind": 5,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "pop_movies_ids = get_pop(mysql)\npop_movies = list(DaumMovies.objects.filter(movieid__in=pop_movies_ids).values())\npop_movies = sorted(pop_movies, key=lambda x: pop_movies_ids.index(x['movieid']))\ntable_clicklog = DynamoDBClient(table_name='clicklog')\ndef home(request):\n    print(f\"movie/home view\".ljust(100, '>'))\n    log_tracking(request=request, view='home')\n    if request.method == \"POST\":\n        pass  # home POST   \n    else:",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "pop_movies",
        "kind": 5,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "pop_movies = list(DaumMovies.objects.filter(movieid__in=pop_movies_ids).values())\npop_movies = sorted(pop_movies, key=lambda x: pop_movies_ids.index(x['movieid']))\ntable_clicklog = DynamoDBClient(table_name='clicklog')\ndef home(request):\n    print(f\"movie/home view\".ljust(100, '>'))\n    log_tracking(request=request, view='home')\n    if request.method == \"POST\":\n        pass  # home POST   \n    else:\n        print(f\"Home - GET\")",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "pop_movies",
        "kind": 5,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "pop_movies = sorted(pop_movies, key=lambda x: pop_movies_ids.index(x['movieid']))\ntable_clicklog = DynamoDBClient(table_name='clicklog')\ndef home(request):\n    print(f\"movie/home view\".ljust(100, '>'))\n    log_tracking(request=request, view='home')\n    if request.method == \"POST\":\n        pass  # home POST   \n    else:\n        print(f\"Home - GET\")\n        username, session_id = get_username_sid(request, _from='movie/home GET')",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "table_clicklog",
        "kind": 5,
        "importPath": "movie.views",
        "description": "movie.views",
        "peekOfCode": "table_clicklog = DynamoDBClient(table_name='clicklog')\ndef home(request):\n    print(f\"movie/home view\".ljust(100, '>'))\n    log_tracking(request=request, view='home')\n    if request.method == \"POST\":\n        pass  # home POST   \n    else:\n        print(f\"Home - GET\")\n        username, session_id = get_username_sid(request, _from='movie/home GET')\n        user_logs_df = get_user_logs_df(username, session_id)",
        "detail": "movie.views",
        "documentation": {}
    },
    {
        "label": "BaseRecommender",
        "kind": 6,
        "importPath": "notebooks.kyeongchan_prod2vec.src.base_recommender",
        "description": "notebooks.kyeongchan_prod2vec.src.base_recommender",
        "peekOfCode": "class BaseRecommender(ABC):\n    @abstractmethod\n    def recommend(self, dataset: Dataset, **kwargs) -> RecommendResult:\n        pass\n    def run_sample(self) -> None:\n        # Movielens  \n        movielens = DataLoader(num_users=1000, num_test_items=5, data_path=\"data/ml-10M100K/\").load()\n        #  \n        recommend_result = self.recommend(movielens)\n        #   ",
        "detail": "notebooks.kyeongchan_prod2vec.src.base_recommender",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "kind": 6,
        "importPath": "notebooks.kyeongchan_prod2vec.util.data_loader",
        "description": "notebooks.kyeongchan_prod2vec.util.data_loader",
        "peekOfCode": "class DataLoader:\n    def __init__(self, num_users: int = 1000, num_test_items: int = 5, data_path: str = \"../data/ml-10M100K/\"):\n        self.num_users = num_users\n        self.num_test_items = num_test_items\n        self.data_path = data_path\n    def load(self) -> Dataset:\n        ratings, movie_content = self._load()\n        movielens_train, movielens_test = self._split_data(ratings)\n        # ranking       4    \n        #   ID,      ID ",
        "detail": "notebooks.kyeongchan_prod2vec.util.data_loader",
        "documentation": {}
    },
    {
        "label": "MetricCalculator",
        "kind": 6,
        "importPath": "notebooks.kyeongchan_prod2vec.util.metric_calculator",
        "description": "notebooks.kyeongchan_prod2vec.util.metric_calculator",
        "peekOfCode": "class MetricCalculator:\n    def calc(\n        self,\n        true_rating: List[float],\n        pred_rating: List[float],\n        true_user2items: Dict[int, List[int]],\n        pred_user2items: Dict[int, List[int]],\n        k: int,\n    ) -> Metrics:\n        rmse = self._calc_rmse(true_rating, pred_rating)",
        "detail": "notebooks.kyeongchan_prod2vec.util.metric_calculator",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "kind": 6,
        "importPath": "notebooks.kyeongchan_prod2vec.util.models",
        "description": "notebooks.kyeongchan_prod2vec.util.models",
        "peekOfCode": "class Dataset:\n    #   \n    train: pd.DataFrame\n    #   \n    test: pd.DataFrame\n    #    .   ID,      ID \n    test_user2items: Dict[int, List[int]]\n    #   \n    item_content: pd.DataFrame\n@dataclasses.dataclass(frozen=True)",
        "detail": "notebooks.kyeongchan_prod2vec.util.models",
        "documentation": {}
    },
    {
        "label": "RecommendResult",
        "kind": 6,
        "importPath": "notebooks.kyeongchan_prod2vec.util.models",
        "description": "notebooks.kyeongchan_prod2vec.util.models",
        "peekOfCode": "class RecommendResult:\n    #    . RMSE \n    rating: pd.DataFrame\n    #   ID,    ID .   .\n    user2items: Dict[int, List[int]]\n@dataclasses.dataclass(frozen=True)\n#   \nclass Metrics:\n    rmse: float\n    precision_at_k: float",
        "detail": "notebooks.kyeongchan_prod2vec.util.models",
        "documentation": {}
    },
    {
        "label": "Metrics",
        "kind": 6,
        "importPath": "notebooks.kyeongchan_prod2vec.util.models",
        "description": "notebooks.kyeongchan_prod2vec.util.models",
        "peekOfCode": "class Metrics:\n    rmse: float\n    precision_at_k: float\n    recall_at_k: float\n    #      \n    def __repr__(self):\n        return f\"rmse={self.rmse:.3f}, Precision@K={self.precision_at_k:.3f}, Recall@K={self.recall_at_k:.3f}\"",
        "detail": "notebooks.kyeongchan_prod2vec.util.models",
        "documentation": {}
    },
    {
        "label": "Item2vecRecommender",
        "kind": 6,
        "importPath": "notebooks.kyeongchan_prod2vec.item2vec",
        "description": "notebooks.kyeongchan_prod2vec.item2vec",
        "peekOfCode": "class Item2vecRecommender(BaseRecommender):\n    def recommend(self, dataset: Dataset, **kwargs) -> RecommendResult:\n        #  \n        factors = kwargs.get(\"factors\", 100)\n        #  \n        n_epochs = kwargs.get(\"n_epochs\", 30)\n        # window \n        window = kwargs.get(\"window\", 100)\n        #  \n        use_skip_gram = kwargs.get(\"use_skip_gram\", 1)",
        "detail": "notebooks.kyeongchan_prod2vec.item2vec",
        "documentation": {}
    },
    {
        "label": "os.environ['RDS_MYSQL_PW']",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "os.environ['RDS_MYSQL_PW'] = ''\nos.environ['AWS_ACCESS_KEY_ID'] = os.getenv('AWS_ACCESS_KEY_ID')\nos.environ['AWS_SECRET_ACCESS_KEY'] = os.getenv('AWS_SECRET_ACCESS_KEY')\nos.environ['AWS_REGION_NAME'] = \"ap-northeast-2\"\n# driver = webdriver.Chrome(executable_path=\"../../Downloads/chromedriver-mac-arm64/chromedriver\")\ndriver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\nsunday_dt = dt.datetime(2013, 6, 23)\ndfs = []\nmovieid_regex = re.compile('movieId=([\\d]+)')\n# for _ in tqdm(range(2000)):",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "os.environ['AWS_ACCESS_KEY_ID']",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "os.environ['AWS_ACCESS_KEY_ID'] = os.getenv('AWS_ACCESS_KEY_ID')\nos.environ['AWS_SECRET_ACCESS_KEY'] = os.getenv('AWS_SECRET_ACCESS_KEY')\nos.environ['AWS_REGION_NAME'] = \"ap-northeast-2\"\n# driver = webdriver.Chrome(executable_path=\"../../Downloads/chromedriver-mac-arm64/chromedriver\")\ndriver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\nsunday_dt = dt.datetime(2013, 6, 23)\ndfs = []\nmovieid_regex = re.compile('movieId=([\\d]+)')\n# for _ in tqdm(range(2000)):\nwhile sunday_dt < dt.datetime.now() + dt.timedelta(days=7):",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "os.environ['AWS_SECRET_ACCESS_KEY']",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "os.environ['AWS_SECRET_ACCESS_KEY'] = os.getenv('AWS_SECRET_ACCESS_KEY')\nos.environ['AWS_REGION_NAME'] = \"ap-northeast-2\"\n# driver = webdriver.Chrome(executable_path=\"../../Downloads/chromedriver-mac-arm64/chromedriver\")\ndriver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\nsunday_dt = dt.datetime(2013, 6, 23)\ndfs = []\nmovieid_regex = re.compile('movieId=([\\d]+)')\n# for _ in tqdm(range(2000)):\nwhile sunday_dt < dt.datetime.now() + dt.timedelta(days=7):\n    driver.get(f\"https://movie.daum.net/ranking/boxoffice/weekly?date={sunday_dt.strftime('%Y%m%d')}\")",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "os.environ['AWS_REGION_NAME']",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "os.environ['AWS_REGION_NAME'] = \"ap-northeast-2\"\n# driver = webdriver.Chrome(executable_path=\"../../Downloads/chromedriver-mac-arm64/chromedriver\")\ndriver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\nsunday_dt = dt.datetime(2013, 6, 23)\ndfs = []\nmovieid_regex = re.compile('movieId=([\\d]+)')\n# for _ in tqdm(range(2000)):\nwhile sunday_dt < dt.datetime.now() + dt.timedelta(days=7):\n    driver.get(f\"https://movie.daum.net/ranking/boxoffice/weekly?date={sunday_dt.strftime('%Y%m%d')}\")\n    week_movies_lst = driver.find_elements(By.CSS_SELECTOR, '#mainContent > div > div.box_boxoffice > ol > li')",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "driver",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\nsunday_dt = dt.datetime(2013, 6, 23)\ndfs = []\nmovieid_regex = re.compile('movieId=([\\d]+)')\n# for _ in tqdm(range(2000)):\nwhile sunday_dt < dt.datetime.now() + dt.timedelta(days=7):\n    driver.get(f\"https://movie.daum.net/ranking/boxoffice/weekly?date={sunday_dt.strftime('%Y%m%d')}\")\n    week_movies_lst = driver.find_elements(By.CSS_SELECTOR, '#mainContent > div > div.box_boxoffice > ol > li')\n    for movie in week_movies_lst:\n        try:",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "sunday_dt",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "sunday_dt = dt.datetime(2013, 6, 23)\ndfs = []\nmovieid_regex = re.compile('movieId=([\\d]+)')\n# for _ in tqdm(range(2000)):\nwhile sunday_dt < dt.datetime.now() + dt.timedelta(days=7):\n    driver.get(f\"https://movie.daum.net/ranking/boxoffice/weekly?date={sunday_dt.strftime('%Y%m%d')}\")\n    week_movies_lst = driver.find_elements(By.CSS_SELECTOR, '#mainContent > div > div.box_boxoffice > ol > li')\n    for movie in week_movies_lst:\n        try:\n            a_title = movie.find_element(By.CSS_SELECTOR, 'div > div.thumb_cont > strong > a')",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "dfs",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "dfs = []\nmovieid_regex = re.compile('movieId=([\\d]+)')\n# for _ in tqdm(range(2000)):\nwhile sunday_dt < dt.datetime.now() + dt.timedelta(days=7):\n    driver.get(f\"https://movie.daum.net/ranking/boxoffice/weekly?date={sunday_dt.strftime('%Y%m%d')}\")\n    week_movies_lst = driver.find_elements(By.CSS_SELECTOR, '#mainContent > div > div.box_boxoffice > ol > li')\n    for movie in week_movies_lst:\n        try:\n            a_title = movie.find_element(By.CSS_SELECTOR, 'div > div.thumb_cont > strong > a')\n            mainpageurl = a_title.get_attribute('href')",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "movieid_regex",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "movieid_regex = re.compile('movieId=([\\d]+)')\n# for _ in tqdm(range(2000)):\nwhile sunday_dt < dt.datetime.now() + dt.timedelta(days=7):\n    driver.get(f\"https://movie.daum.net/ranking/boxoffice/weekly?date={sunday_dt.strftime('%Y%m%d')}\")\n    week_movies_lst = driver.find_elements(By.CSS_SELECTOR, '#mainContent > div > div.box_boxoffice > ol > li')\n    for movie in week_movies_lst:\n        try:\n            a_title = movie.find_element(By.CSS_SELECTOR, 'div > div.thumb_cont > strong > a')\n            mainpageurl = a_title.get_attribute('href')\n            movie_id = re.search(movieid_regex, mainpageurl).group(1)",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "df = pd.DataFrame(dfs, columns=[\"mainPageUrl\", \"titleKo\", \"movieId\", \"posterUrl\"])\ndf = df.drop_duplicates()\ndf.to_csv(\"daum_movie.csv\", index=False)\n# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n#\n# dfs = []\n# for movie_id in tqdm(range(100000)):\n#     driver.get(f\"https://movie.daum.net/moviedb/main?movieId={movie_id}\")\n#     week_movies_lst = driver.find_elements(By.CSS_SELECTOR, '#mainContent > div > div.box_boxoffice > ol > li')\n#",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "notebooks.crawling_daum_movie_local",
        "description": "notebooks.crawling_daum_movie_local",
        "peekOfCode": "df = df.drop_duplicates()\ndf.to_csv(\"daum_movie.csv\", index=False)\n# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n#\n# dfs = []\n# for movie_id in tqdm(range(100000)):\n#     driver.get(f\"https://movie.daum.net/moviedb/main?movieId={movie_id}\")\n#     week_movies_lst = driver.find_elements(By.CSS_SELECTOR, '#mainContent > div > div.box_boxoffice > ol > li')\n#\n#     for movie in week_movies_lst:",
        "detail": "notebooks.crawling_daum_movie_local",
        "documentation": {}
    },
    {
        "label": "wait_till_n_site",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_movies",
        "description": "notebooks.multiprocessing_crawling_daum_movies",
        "peekOfCode": "def wait_till_n_site(driver):\n    start = time.time()\n    while True:\n        try:\n            n_site_tag = driver.find_element(By.CSS_SELECTOR, 'span.txt_netizen')\n            if n_site_tag.text != '':\n                print(f\"!!!!!{n_site_tag.text}\")\n                break\n        except NoSuchElementException:\n            if time.time() - start > 2:",
        "detail": "notebooks.multiprocessing_crawling_daum_movies",
        "documentation": {}
    },
    {
        "label": "parse_poster_url",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_movies",
        "description": "notebooks.multiprocessing_crawling_daum_movies",
        "peekOfCode": "def parse_poster_url(driver):\n    poster_regex = re.compile(r\"\\\"(.+)\\\"\")\n    try:\n        poster_attr = driver.find_element(By.CSS_SELECTOR, 'span.bg_img').get_attribute('style')\n        poster_url = re.search(poster_regex, poster_attr).group(1)\n        return poster_url\n    except (NoSuchElementException, AttributeError):\n        return None\ndef insert_movie_info(mysql, update_values, mid):\n    with mysql.get_connection() as conn:",
        "detail": "notebooks.multiprocessing_crawling_daum_movies",
        "documentation": {}
    },
    {
        "label": "insert_movie_info",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_movies",
        "description": "notebooks.multiprocessing_crawling_daum_movies",
        "peekOfCode": "def insert_movie_info(mysql, update_values, mid):\n    with mysql.get_connection() as conn:\n        cursor = conn.cursor()\n        #   \n        update_query = \"\"\"\n            UPDATE daum_movies\n            SET {update_columns}\n            WHERE movieId = %s;\n        \"\"\".format(update_columns=\", \".join(f\"{key} = %s\" for key in update_values.keys()))\n        #  ",
        "detail": "notebooks.multiprocessing_crawling_daum_movies",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_movies",
        "description": "notebooks.multiprocessing_crawling_daum_movies",
        "peekOfCode": "def main(daum_movies):\n    mysql = MysqlClient()\n    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n    for mid in daum_movies['movieId']:\n        url = f\"https://movie.daum.net/moviedb/grade?movieId={mid}\"\n        driver.get(url)\n        #   \n        wait = wait_till_n_site(driver)\n        if wait == 'continue':\n            continue",
        "detail": "notebooks.multiprocessing_crawling_daum_movies",
        "documentation": {}
    },
    {
        "label": "click_more",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def click_more(driver, num):\n    for _ in range(num):\n        try:\n            driver.find_element(By.CSS_SELECTOR, '#alex-area > div > div > div > div.cmt_box > div.alex_more').click()\n            time.sleep(0.5)\n        except (StaleElementReferenceException, NoSuchElementException):\n            continue\ndef click_popup_more(driver, num):\n    for _ in range(num):\n        try:",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "click_popup_more",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def click_popup_more(driver, num):\n    for _ in range(num):\n        try:\n            driver.find_element(By.CSS_SELECTOR, 'div[data-reactid=\".0.0.1\"] div.alex_more').click()\n            time.sleep(0.1)\n        except (StaleElementReferenceException, NoSuchElementException):\n            continue\n#  \n#  ???!!!! movieId <-    \ndef one_box_parsing(box):",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "one_box_parsing",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def one_box_parsing(box):\n    import re\n    kor_dt_regex = re.compile('[-]')  #   \n    try:\n        review = box.find_element(By.CSS_SELECTOR, 'p.desc_txt').text\n        rating = box.find_element(By.CSS_SELECTOR, 'div.ratings').text\n        time_dt = box.find_element(By.CSS_SELECTOR, 'span.txt_date').text\n        if re.search(kor_dt_regex, time_dt):\n            return None\n        rating_dt = dt.datetime.strptime(time_dt, '%Y. %m. %d. %H:%M')",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "click_popup_x",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def click_popup_x(driver, title_ko, nname, movie_id, nickname, len_popupboxes):\n    while True:\n        try:\n            driver.find_element(By.CSS_SELECTOR,\n                                '#alex-area > div > div > div:nth-child(2) > div.my_layer.use_unfollow > div.my_header.no_divider > a > span').click()\n            break\n        except NoSuchElementException:\n            print(\n                f\"\\tL no popup x -> title_ko, movie id, nickname, len_popupboxes, in_nicknames : {title_ko}, {nname}, {movie_id}, {nickname}, {len_popupboxes}\")\n            continue",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "wait_till_popup",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def wait_till_popup(driver):\n    while True:\n        try:\n            popup = driver.find_element(By.CSS_SELECTOR, 'div[data-reactid=\".0.0.1\"]')\n            if popup:\n                break\n        except NoSuchElementException:\n            continue\ndef wait_till_close_popup(driver):\n    while True:",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "wait_till_close_popup",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def wait_till_close_popup(driver):\n    while True:\n        try:\n            x_mark = driver.find_element(By.CSS_SELECTOR,\n                                         '#alex-area > div > div > div:nth-child(2) > div.my_layer.use_unfollow > div.my_header.no_divider > a')\n            if x_mark:\n                continue\n        except NoSuchElementException:\n            break\ndef insert_data_ratings(data_to_insert):",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "insert_data_ratings",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def insert_data_ratings(data_to_insert):\n    with mysql.get_connection() as connection:\n        cursor = connection.cursor()\n        cursor.executemany(\n            \"INSERT INTO daum_ratings (nickName, movieId, rating, timestamp, userId, review) VALUES (%s, %s, %s, %s, %s, %s)\",\n            data_to_insert)\n        connection.commit()\nfrom pymysql.err import IntegrityError\ndef insert_data_ratings(mysql, data_to_insert, title_ko):\n    insert_query = \"\"\"",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "insert_data_ratings",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def insert_data_ratings(mysql, data_to_insert, title_ko):\n    insert_query = \"\"\"\n    INSERT INTO daum_ratings (nickName, movieId, rating, timestamp, userId, review) VALUES (%s, %s, %s, %s, %s, %s)\n    \"\"\"\n    try:\n        with mysql.get_connection() as connection:\n            cursor = connection.cursor()\n            # executemany     \n            i = 0\n            for row in data_to_insert:",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "insert_movie_if_not_exists",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def insert_movie_if_not_exists(mysql, movie_id):\n    # SQL :  (movieId, nickName)   \n    query = \"SELECT COUNT(*) FROM daum_movies WHERE movieId = %s\"\n    with mysql.get_connection() as connection:\n        cursor = connection.cursor()\n        cursor.execute(query, (movie_id,))\n        result = cursor.fetchone()[0]\n        #    \n        if result == 0:\n            #  ",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "process_movie_reviews",
        "kind": 2,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "def process_movie_reviews(title_ko, movie_id, shared_df, shared_nicknames):\n    mysql = MysqlClient()\n    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))  #      .\n    driver.get(f\"https://movie.daum.net/moviedb/grade?movieId={movie_id}\")\n    time.sleep(1)\n    click_more(driver, 3)\n    time.sleep(1)\n    rating_boxes = driver.find_elements(By.CSS_SELECTOR, 'div.wrap_alex ul.list_comment > li')\n    # for pop_i, box in tqdm(enumerate(rating_boxes), desc=f\"(box : {len(rating_boxes):3})\" + f'[{movie_id:6}] ' + title_ko):\n    for pop_i, box in enumerate(rating_boxes, start=1):",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "movieid_regex",
        "kind": 5,
        "importPath": "notebooks.multiprocessing_crawling_daum_ratings",
        "description": "notebooks.multiprocessing_crawling_daum_ratings",
        "peekOfCode": "movieid_regex = re.compile('movieId=([\\d]+)')\ndef click_more(driver, num):\n    for _ in range(num):\n        try:\n            driver.find_element(By.CSS_SELECTOR, '#alex-area > div > div > div > div.cmt_box > div.alex_more').click()\n            time.sleep(0.5)\n        except (StaleElementReferenceException, NoSuchElementException):\n            continue\ndef click_popup_more(driver, num):\n    for _ in range(num):",
        "detail": "notebooks.multiprocessing_crawling_daum_ratings",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0001_initial",
        "description": "paper_review.migrations.0001_initial",
        "peekOfCode": "class Migration(migrations.Migration):\n    initial = True\n    dependencies = [\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='Post',\n            fields=[\n                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('title', models.CharField(max_length=30)),",
        "detail": "paper_review.migrations.0001_initial",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0002_post_updated_at_alter_post_created_at",
        "description": "paper_review.migrations.0002_post_updated_at_alter_post_created_at",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0001_initial'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='post',\n            name='updated_at',\n            field=models.DateTimeField(auto_now=True),\n        ),",
        "detail": "paper_review.migrations.0002_post_updated_at_alter_post_created_at",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0003_alter_post_content",
        "description": "paper_review.migrations.0003_alter_post_content",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0002_post_updated_at_alter_post_created_at'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name='post',\n            name='content',\n            field=markdownx.models.MarkdownxField(),\n        ),",
        "detail": "paper_review.migrations.0003_alter_post_content",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0004_postmonthlypseudorec",
        "description": "paper_review.migrations.0004_postmonthlypseudorec",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0003_alter_post_content'),\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='PostMonthlyPseudorec',\n            fields=[\n                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('title', models.CharField(max_length=30)),",
        "detail": "paper_review.migrations.0004_postmonthlypseudorec",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0005_postmonthlypseudorec_author_and_more",
        "description": "paper_review.migrations.0005_postmonthlypseudorec_author_and_more",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0004_postmonthlypseudorec'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='postmonthlypseudorec',\n            name='author',\n            field=models.CharField(default='', max_length=50),\n        ),",
        "detail": "paper_review.migrations.0005_postmonthlypseudorec_author_and_more",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0006_postmonthlypseudorec_subtitle_alter_post_title_and_more",
        "description": "paper_review.migrations.0006_postmonthlypseudorec_subtitle_alter_post_title_and_more",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0005_postmonthlypseudorec_author_and_more'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='postmonthlypseudorec',\n            name='subtitle',\n            field=models.CharField(default=' ', max_length=100),\n        ),",
        "detail": "paper_review.migrations.0006_postmonthlypseudorec_subtitle_alter_post_title_and_more",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0007_postmonthlypseudorec_card_image",
        "description": "paper_review.migrations.0007_postmonthlypseudorec_card_image",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0006_postmonthlypseudorec_subtitle_alter_post_title_and_more'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='postmonthlypseudorec',\n            name='card_image',\n            field=models.ImageField(blank=True, upload_to='paper_review/card_imgs', verbose_name=' '),\n        ),",
        "detail": "paper_review.migrations.0007_postmonthlypseudorec_card_image",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0008_postmonthlypseudorec_month",
        "description": "paper_review.migrations.0008_postmonthlypseudorec_month",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0007_postmonthlypseudorec_card_image'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='postmonthlypseudorec',\n            name='month',\n            field=models.CharField(default='203004', max_length=10),\n        ),",
        "detail": "paper_review.migrations.0008_postmonthlypseudorec_month",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0009_postmonthlypseudorec_author_image",
        "description": "paper_review.migrations.0009_postmonthlypseudorec_author_image",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0008_postmonthlypseudorec_month'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='postmonthlypseudorec',\n            name='author_image',\n            field=models.ImageField(blank=True, upload_to='paper_review/author_imgs', verbose_name=' '),\n        ),",
        "detail": "paper_review.migrations.0009_postmonthlypseudorec_author_image",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0010_alter_postmonthlypseudorec_author_image",
        "description": "paper_review.migrations.0010_alter_postmonthlypseudorec_author_image",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0009_postmonthlypseudorec_author_image'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name='postmonthlypseudorec',\n            name='author_image',\n            field=models.ImageField(blank=True, upload_to='paper_review/author_imgs', verbose_name=' '),\n        ),",
        "detail": "paper_review.migrations.0010_alter_postmonthlypseudorec_author_image",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0011_comment",
        "description": "paper_review.migrations.0011_comment",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0010_alter_postmonthlypseudorec_author_image'),\n        migrations.swappable_dependency(settings.AUTH_USER_MODEL),\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='Comment',\n            fields=[\n                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),",
        "detail": "paper_review.migrations.0011_comment",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0012_post_author_post_author_image",
        "description": "paper_review.migrations.0012_post_author_post_author_image",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0011_comment'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='post',\n            name='author',\n            field=models.CharField(default='', max_length=50),\n        ),",
        "detail": "paper_review.migrations.0012_post_author_post_author_image",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0013_alter_post_created_at_and_more",
        "description": "paper_review.migrations.0013_alter_post_created_at_and_more",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0012_post_author_post_author_image'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name='post',\n            name='created_at',\n            field=models.DateTimeField(),\n        ),",
        "detail": "paper_review.migrations.0013_alter_post_created_at_and_more",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0014_post_card_image_alter_comment_created_at",
        "description": "paper_review.migrations.0014_post_card_image_alter_comment_created_at",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0013_alter_post_created_at_and_more'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='post',\n            name='card_image',\n            field=models.ImageField(blank=True, upload_to='paper_review/card_imgs', verbose_name=' '),\n        ),",
        "detail": "paper_review.migrations.0014_post_card_image_alter_comment_created_at",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "paper_review.migrations.0015_post_author2_post_author_image2",
        "description": "paper_review.migrations.0015_post_author2_post_author_image2",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('paper_review', '0014_post_card_image_alter_comment_created_at'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='post',\n            name='author2',\n            field=models.CharField(default='2', max_length=50),\n        ),",
        "detail": "paper_review.migrations.0015_post_author2_post_author_image2",
        "documentation": {}
    },
    {
        "label": "mark",
        "kind": 2,
        "importPath": "paper_review.templatetags.paper_review_filter",
        "description": "paper_review.templatetags.paper_review_filter",
        "peekOfCode": "def mark(value, inline_code_marker=\"$\"):\n    extensions = [\"nl2br\", \"fenced_code\", \"codehilite\"]\n    return mark_safe(markdown.markdown(value, extensions=extensions, inline_code_marker=inline_code_marker))",
        "detail": "paper_review.templatetags.paper_review_filter",
        "documentation": {}
    },
    {
        "label": "register",
        "kind": 5,
        "importPath": "paper_review.templatetags.paper_review_filter",
        "description": "paper_review.templatetags.paper_review_filter",
        "peekOfCode": "register = template.Library()\n@register.filter\ndef mark(value, inline_code_marker=\"$\"):\n    extensions = [\"nl2br\", \"fenced_code\", \"codehilite\"]\n    return mark_safe(markdown.markdown(value, extensions=extensions, inline_code_marker=inline_code_marker))",
        "detail": "paper_review.templatetags.paper_review_filter",
        "documentation": {}
    },
    {
        "label": "PostAdmin",
        "kind": 6,
        "importPath": "paper_review.admin",
        "description": "paper_review.admin",
        "peekOfCode": "class PostAdmin(admin.ModelAdmin):\n    save_on_top = True\nadmin.site.register(Post, MarkdownxModelAdmin)\nadmin.site.register(PostMonthlyPseudorec, MarkdownxModelAdmin)\nadmin.site.register(Comment)",
        "detail": "paper_review.admin",
        "documentation": {}
    },
    {
        "label": "PaperReviewConfig",
        "kind": 6,
        "importPath": "paper_review.apps",
        "description": "paper_review.apps",
        "peekOfCode": "class PaperReviewConfig(AppConfig):\n    default_auto_field = 'django.db.models.BigAutoField'\n    name = 'paper_review'",
        "detail": "paper_review.apps",
        "documentation": {}
    },
    {
        "label": "Post",
        "kind": 6,
        "importPath": "paper_review.models",
        "description": "paper_review.models",
        "peekOfCode": "class Post(models.Model):\n    title = models.CharField(max_length=100)\n    # content = models.TextField()\n    card_image = models.ImageField(\" \", upload_to=\"paper_review/card_imgs\", blank=True)\n    content = MarkdownxField()\n    created_at = models.DateTimeField()\n    updated_at = models.DateTimeField(auto_now=True)\n    author = models.CharField(max_length=50, default=\"\")\n    author_image = models.ImageField(\" \", upload_to=\"paper_review/author_imgs\", blank=True)\n    author2 = models.CharField(max_length=50, default=\"2\")",
        "detail": "paper_review.models",
        "documentation": {}
    },
    {
        "label": "PostMonthlyPseudorec",
        "kind": 6,
        "importPath": "paper_review.models",
        "description": "paper_review.models",
        "peekOfCode": "class PostMonthlyPseudorec(models.Model):\n    title = models.CharField(max_length=100, default=' ')\n    subtitle = models.CharField(max_length=100, default=' ')\n    month = models.CharField(max_length=10, default='203004')\n    card_image = models.ImageField(\" \", upload_to=\"paper_review/card_imgs\", blank=True)\n    content = MarkdownxField()\n    created_at = models.DateTimeField()\n    updated_at = models.DateTimeField(auto_now=True)\n    author = models.CharField(max_length=50, default='')\n    author_image = models.ImageField(\" \", upload_to=\"paper_review/author_imgs\", blank=True)",
        "detail": "paper_review.models",
        "documentation": {}
    },
    {
        "label": "Comment",
        "kind": 6,
        "importPath": "paper_review.models",
        "description": "paper_review.models",
        "peekOfCode": "class Comment(models.Model):\n    post = models.ForeignKey(Post, on_delete=models.CASCADE)\n    author = models.ForeignKey(User, on_delete=models.CASCADE)\n    content = models.TextField()\n    created_at = models.DateTimeField()\n    modified_at = models.DateTimeField(auto_now=True)\n    def __str__(self):\n        return f\"{self.author}::{self.content}\"",
        "detail": "paper_review.models",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "paper_review.urls",
        "description": "paper_review.urls",
        "peekOfCode": "urlpatterns = [\n    # path('<int:pk>/', views.PostDetail.as_view()),\n    # path('', views.PostList.as_view()),\n    path('paper_review/<int:pk>/', views.single_post_page_paper_review),\n    path('paper_review/', views.index_paper_review),\n    path('monthly_pseudorec/', views.index_monthly_pseudorec),\n    path('monthly_pseudorec/<int:pk>/', views.single_post_page_monthly_pseudorec)\n]",
        "detail": "paper_review.urls",
        "documentation": {}
    },
    {
        "label": "index_paper_review",
        "kind": 2,
        "importPath": "paper_review.views",
        "description": "paper_review.views",
        "peekOfCode": "def index_paper_review(request):\n    print(request)\n    posts = Post.objects.all().order_by('-pk')\n    return render(request=request,\n                  template_name='post_list.html',\n                  context={\n                      'posts': posts,\n                      'header': 'Paper Review'\n                  })\ndef index_monthly_pseudorec(request):",
        "detail": "paper_review.views",
        "documentation": {}
    },
    {
        "label": "index_monthly_pseudorec",
        "kind": 2,
        "importPath": "paper_review.views",
        "description": "paper_review.views",
        "peekOfCode": "def index_monthly_pseudorec(request):\n    posts = PostMonthlyPseudorec.objects.all().order_by('-pk')\n    return render(request=request,\n                  template_name='post_list_monthly_pseudorec.html',\n                  context={\n                      'posts': posts,\n                      'header': '',\n                      'description': '   '\n                  })\ndef single_post_page_paper_review(request, pk):",
        "detail": "paper_review.views",
        "documentation": {}
    },
    {
        "label": "single_post_page_paper_review",
        "kind": 2,
        "importPath": "paper_review.views",
        "description": "paper_review.views",
        "peekOfCode": "def single_post_page_paper_review(request, pk):\n    post = Post.objects.get(pk=pk)\n    md_mapper = {\n        1: \"post_markdowns/paper_review/kprn review.md\",\n        2: \"post_markdowns/paper_review/ngcf review.md\",\n        3: \"post_markdowns/paper_review/sasrec review.md\",\n        4: \"post_markdowns/paper_review/srgnn review.md\",\n        5: \"post_markdowns/paper_review/bert4rec review.md\",\n        6: \"post_markdowns/paper_review/Large Language Models are Zero-Shot Rankers for Recommender Systems.md\",\n        7: \"post_markdowns/paper_review/A Survey of Large Language Models for Graphs.md\",",
        "detail": "paper_review.views",
        "documentation": {}
    },
    {
        "label": "single_post_page_monthly_pseudorec",
        "kind": 2,
        "importPath": "paper_review.views",
        "description": "paper_review.views",
        "peekOfCode": "def single_post_page_monthly_pseudorec(request, pk):\n    post = PostMonthlyPseudorec.objects.get(pk=pk)\n    md_mapper = {\n        1: \"post_markdowns/monthly_pseudorec/202405/202404_kyungah.md\",\n        2: \"post_markdowns/monthly_pseudorec/202405/202404_minsang.md\",\n        3: \"post_markdowns/monthly_pseudorec/202405/202404_kyeongchan.md\",\n        4: \"post_markdowns/monthly_pseudorec/202405/202404_hyunwoo.md\",\n        5: \"post_markdowns/monthly_pseudorec/202405/202404_namjoon.md\",\n        6: \"post_markdowns/monthly_pseudorec/202405/202404_soonhyeok.md\",\n        7: \"post_markdowns/monthly_pseudorec/202406/202406_kyeongchan.md\",",
        "detail": "paper_review.views",
        "documentation": {}
    },
    {
        "label": "FunkSVDCF",
        "kind": 6,
        "importPath": "pytorch_models.cf.cf",
        "description": "pytorch_models.cf.cf",
        "peekOfCode": "class FunkSVDCF:\n    def __init__(self, num_users, num_items, num_factors, learning_rate, regularization, num_epochs):\n        self.num_users = num_users\n        self.num_items = num_items\n        self.num_factors = num_factors\n        self.alpha = learning_rate\n        self.lambda_ = regularization\n        self.num_epochs = num_epochs\n        # Initialize model parameters\n        self.global_bias = 0",
        "detail": "pytorch_models.cf.cf",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "data = pd.read_csv('pytorch_models/Data/daum/daum_movie.csv')\ndata.columns = ['unnamed', 'uid', 'iid', 'r', 'ts', 'nan', 'review']\ndata = data.drop(columns=['unnamed', 'ts', 'nan', 'review'])\n# %% rating 5   \ngb_inum = data[['uid', 'iid']].groupby(['uid']).count()\nover_20_idxs = gb_inum.loc[gb_inum.iid > 5].index.values\ndata = data.loc[data.uid.isin(over_20_idxs)].reset_index(drop=True)\n# %% uid, iid encoding\nuser_encoder = {id: idx for idx, id in enumerate(data['uid'].unique())}\nuser_decoder = {idx: id for id, idx in user_encoder.items()}",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "data.columns",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "data.columns = ['unnamed', 'uid', 'iid', 'r', 'ts', 'nan', 'review']\ndata = data.drop(columns=['unnamed', 'ts', 'nan', 'review'])\n# %% rating 5   \ngb_inum = data[['uid', 'iid']].groupby(['uid']).count()\nover_20_idxs = gb_inum.loc[gb_inum.iid > 5].index.values\ndata = data.loc[data.uid.isin(over_20_idxs)].reset_index(drop=True)\n# %% uid, iid encoding\nuser_encoder = {id: idx for idx, id in enumerate(data['uid'].unique())}\nuser_decoder = {idx: id for id, idx in user_encoder.items()}\nitem_encoder = {id: idx for idx, id in enumerate(data['iid'].unique())}",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "data = data.drop(columns=['unnamed', 'ts', 'nan', 'review'])\n# %% rating 5   \ngb_inum = data[['uid', 'iid']].groupby(['uid']).count()\nover_20_idxs = gb_inum.loc[gb_inum.iid > 5].index.values\ndata = data.loc[data.uid.isin(over_20_idxs)].reset_index(drop=True)\n# %% uid, iid encoding\nuser_encoder = {id: idx for idx, id in enumerate(data['uid'].unique())}\nuser_decoder = {idx: id for id, idx in user_encoder.items()}\nitem_encoder = {id: idx for idx, id in enumerate(data['iid'].unique())}\nitem_decoder = {idx: id for id, idx in item_encoder.items()}",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "gb_inum",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "gb_inum = data[['uid', 'iid']].groupby(['uid']).count()\nover_20_idxs = gb_inum.loc[gb_inum.iid > 5].index.values\ndata = data.loc[data.uid.isin(over_20_idxs)].reset_index(drop=True)\n# %% uid, iid encoding\nuser_encoder = {id: idx for idx, id in enumerate(data['uid'].unique())}\nuser_decoder = {idx: id for id, idx in user_encoder.items()}\nitem_encoder = {id: idx for idx, id in enumerate(data['iid'].unique())}\nitem_decoder = {idx: id for id, idx in item_encoder.items()}\ndata['uid'] = data['uid'].apply(lambda x: user_encoder[x])\ndata['iid'] = data['iid'].apply(lambda x: item_encoder[x])",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "over_20_idxs",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "over_20_idxs = gb_inum.loc[gb_inum.iid > 5].index.values\ndata = data.loc[data.uid.isin(over_20_idxs)].reset_index(drop=True)\n# %% uid, iid encoding\nuser_encoder = {id: idx for idx, id in enumerate(data['uid'].unique())}\nuser_decoder = {idx: id for id, idx in user_encoder.items()}\nitem_encoder = {id: idx for idx, id in enumerate(data['iid'].unique())}\nitem_decoder = {idx: id for id, idx in item_encoder.items()}\ndata['uid'] = data['uid'].apply(lambda x: user_encoder[x])\ndata['iid'] = data['iid'].apply(lambda x: item_encoder[x])\nx_train, x_valid, y_train, y_valid = train_test_split(data, data['uid'].values, test_size=0.2, shuffle=True,",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "data = data.loc[data.uid.isin(over_20_idxs)].reset_index(drop=True)\n# %% uid, iid encoding\nuser_encoder = {id: idx for idx, id in enumerate(data['uid'].unique())}\nuser_decoder = {idx: id for id, idx in user_encoder.items()}\nitem_encoder = {id: idx for idx, id in enumerate(data['iid'].unique())}\nitem_decoder = {idx: id for id, idx in item_encoder.items()}\ndata['uid'] = data['uid'].apply(lambda x: user_encoder[x])\ndata['iid'] = data['iid'].apply(lambda x: item_encoder[x])\nx_train, x_valid, y_train, y_valid = train_test_split(data, data['uid'].values, test_size=0.2, shuffle=True,\n                                                      stratify=data['uid'].values, random_state=42)",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "user_encoder",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "user_encoder = {id: idx for idx, id in enumerate(data['uid'].unique())}\nuser_decoder = {idx: id for id, idx in user_encoder.items()}\nitem_encoder = {id: idx for idx, id in enumerate(data['iid'].unique())}\nitem_decoder = {idx: id for id, idx in item_encoder.items()}\ndata['uid'] = data['uid'].apply(lambda x: user_encoder[x])\ndata['iid'] = data['iid'].apply(lambda x: item_encoder[x])\nx_train, x_valid, y_train, y_valid = train_test_split(data, data['uid'].values, test_size=0.2, shuffle=True,\n                                                      stratify=data['uid'].values, random_state=42)\ntrn_data = x_train.copy()\n# print(trn_data)",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "user_decoder",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "user_decoder = {idx: id for id, idx in user_encoder.items()}\nitem_encoder = {id: idx for idx, id in enumerate(data['iid'].unique())}\nitem_decoder = {idx: id for id, idx in item_encoder.items()}\ndata['uid'] = data['uid'].apply(lambda x: user_encoder[x])\ndata['iid'] = data['iid'].apply(lambda x: item_encoder[x])\nx_train, x_valid, y_train, y_valid = train_test_split(data, data['uid'].values, test_size=0.2, shuffle=True,\n                                                      stratify=data['uid'].values, random_state=42)\ntrn_data = x_train.copy()\n# print(trn_data)\nval_data = x_valid.copy()",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "item_encoder",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "item_encoder = {id: idx for idx, id in enumerate(data['iid'].unique())}\nitem_decoder = {idx: id for id, idx in item_encoder.items()}\ndata['uid'] = data['uid'].apply(lambda x: user_encoder[x])\ndata['iid'] = data['iid'].apply(lambda x: item_encoder[x])\nx_train, x_valid, y_train, y_valid = train_test_split(data, data['uid'].values, test_size=0.2, shuffle=True,\n                                                      stratify=data['uid'].values, random_state=42)\ntrn_data = x_train.copy()\n# print(trn_data)\nval_data = x_valid.copy()\n# %% rating matrix about train/test set.",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "item_decoder",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "item_decoder = {idx: id for id, idx in item_encoder.items()}\ndata['uid'] = data['uid'].apply(lambda x: user_encoder[x])\ndata['iid'] = data['iid'].apply(lambda x: item_encoder[x])\nx_train, x_valid, y_train, y_valid = train_test_split(data, data['uid'].values, test_size=0.2, shuffle=True,\n                                                      stratify=data['uid'].values, random_state=42)\ntrn_data = x_train.copy()\n# print(trn_data)\nval_data = x_valid.copy()\n# %% rating matrix about train/test set.\nn_item = len(set(data['iid']))",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "data['uid']",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "data['uid'] = data['uid'].apply(lambda x: user_encoder[x])\ndata['iid'] = data['iid'].apply(lambda x: item_encoder[x])\nx_train, x_valid, y_train, y_valid = train_test_split(data, data['uid'].values, test_size=0.2, shuffle=True,\n                                                      stratify=data['uid'].values, random_state=42)\ntrn_data = x_train.copy()\n# print(trn_data)\nval_data = x_valid.copy()\n# %% rating matrix about train/test set.\nn_item = len(set(data['iid']))\nn_user = len(set(data['uid']))",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "data['iid']",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "data['iid'] = data['iid'].apply(lambda x: item_encoder[x])\nx_train, x_valid, y_train, y_valid = train_test_split(data, data['uid'].values, test_size=0.2, shuffle=True,\n                                                      stratify=data['uid'].values, random_state=42)\ntrn_data = x_train.copy()\n# print(trn_data)\nval_data = x_valid.copy()\n# %% rating matrix about train/test set.\nn_item = len(set(data['iid']))\nn_user = len(set(data['uid']))\n# train_df = pd.DataFrame(columns={'uid','iid'})",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "trn_data",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "trn_data = x_train.copy()\n# print(trn_data)\nval_data = x_valid.copy()\n# %% rating matrix about train/test set.\nn_item = len(set(data['iid']))\nn_user = len(set(data['uid']))\n# train_df = pd.DataFrame(columns={'uid','iid'})\n# for u in range(len(trn_data['uid'].unique())) :\n#     item = sorted(list(set(trn_data['iid'][trn_data['uid']==u].values)))\n#     u = str(u)",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "val_data = x_valid.copy()\n# %% rating matrix about train/test set.\nn_item = len(set(data['iid']))\nn_user = len(set(data['uid']))\n# train_df = pd.DataFrame(columns={'uid','iid'})\n# for u in range(len(trn_data['uid'].unique())) :\n#     item = sorted(list(set(trn_data['iid'][trn_data['uid']==u].values)))\n#     u = str(u)\n#     item =' '.join(map(str, item))\n#     train_df.loc[u]=[u, item]",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "n_item",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "n_item = len(set(data['iid']))\nn_user = len(set(data['uid']))\n# train_df = pd.DataFrame(columns={'uid','iid'})\n# for u in range(len(trn_data['uid'].unique())) :\n#     item = sorted(list(set(trn_data['iid'][trn_data['uid']==u].values)))\n#     u = str(u)\n#     item =' '.join(map(str, item))\n#     train_df.loc[u]=[u, item]\nwith open(r'test.txt', 'w') as f:\n    for u in range(val_data['uid'].nunique()):",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "n_user",
        "kind": 5,
        "importPath": "pytorch_models.Data.daum.train_test_split",
        "description": "pytorch_models.Data.daum.train_test_split",
        "peekOfCode": "n_user = len(set(data['uid']))\n# train_df = pd.DataFrame(columns={'uid','iid'})\n# for u in range(len(trn_data['uid'].unique())) :\n#     item = sorted(list(set(trn_data['iid'][trn_data['uid']==u].values)))\n#     u = str(u)\n#     item =' '.join(map(str, item))\n#     train_df.loc[u]=[u, item]\nwith open(r'test.txt', 'w') as f:\n    for u in range(val_data['uid'].nunique()):\n        item = sorted(list(set(val_data['iid'][val_data['uid'] == u].values)))",
        "detail": "pytorch_models.Data.daum.train_test_split",
        "documentation": {}
    },
    {
        "label": "RatingDataset",
        "kind": 6,
        "importPath": "pytorch_models.general_mf.models.neural_bpr_MF",
        "description": "pytorch_models.general_mf.models.neural_bpr_MF",
        "peekOfCode": "class RatingDataset(Dataset):\n    def __init__(self, data):\n        self.users = torch.LongTensor(data[:, 0])\n        self.items = torch.LongTensor(data[:, 1])\n        self.ratings = torch.FloatTensor(data[:, 2])\n    def __len__(self):\n        return len(self.ratings)\n    def __getitem__(self, idx):\n        return self.users[idx], self.items[idx], self.ratings[idx]\nclass Neural_MF(nn.Module):",
        "detail": "pytorch_models.general_mf.models.neural_bpr_MF",
        "documentation": {}
    },
    {
        "label": "Neural_MF",
        "kind": 6,
        "importPath": "pytorch_models.general_mf.models.neural_bpr_MF",
        "description": "pytorch_models.general_mf.models.neural_bpr_MF",
        "peekOfCode": "class Neural_MF(nn.Module):\n    def __init__(self, num_users, num_items, n_features):\n        super().__init__()\n        self.user_emb = nn.Embedding(num_users, n_features, sparse=False)\n        self.item_emb = nn.Embedding(num_items, n_features, sparse=False)\n        self.predict_layer = nn.Sequential(nn.Linear(n_features, 1, bias=False))\n        self._init_weight_()\n    def _init_weight_(self):\n        nn.init.normal_(self.user_emb.weight, std=0.01)\n        nn.init.normal_(self.item_emb.weight, std=0.01)",
        "detail": "pytorch_models.general_mf.models.neural_bpr_MF",
        "documentation": {}
    },
    {
        "label": "BPRLoss",
        "kind": 6,
        "importPath": "pytorch_models.general_mf.models.neural_bpr_MF",
        "description": "pytorch_models.general_mf.models.neural_bpr_MF",
        "peekOfCode": "class BPRLoss(nn.Module):\n    def __init__(self):\n        super(BPRLoss, self).__init__()\n    def forward(self, pos, neg):\n        bpr_loss = -torch.mean(torch.log(torch.sigmoid(pos - neg)))\n        return bpr_loss\nclass BPRMFTrainer:\n    def __init__(self, train_dataset, valid_dataset, n_features=20, learning_rate=1e-2, reg_lambda=1e-2, num_epochs=100, batch_size=32, patience=10, num_negatives=5, device='cpu', path=None):\n        self.device = device\n        self.num_negatives = num_negatives",
        "detail": "pytorch_models.general_mf.models.neural_bpr_MF",
        "documentation": {}
    },
    {
        "label": "BPRMFTrainer",
        "kind": 6,
        "importPath": "pytorch_models.general_mf.models.neural_bpr_MF",
        "description": "pytorch_models.general_mf.models.neural_bpr_MF",
        "peekOfCode": "class BPRMFTrainer:\n    def __init__(self, train_dataset, valid_dataset, n_features=20, learning_rate=1e-2, reg_lambda=1e-2, num_epochs=100, batch_size=32, patience=10, num_negatives=5, device='cpu', path=None):\n        self.device = device\n        self.num_negatives = num_negatives\n        self.criterion = BPRLoss()\n        self.num_epochs = num_epochs\n        self.patience = patience\n        self.patience_counter = 0\n        self.best_loss = float('inf')\n        self.best_model = None",
        "detail": "pytorch_models.general_mf.models.neural_bpr_MF",
        "documentation": {}
    },
    {
        "label": "NewUserPredictor",
        "kind": 6,
        "importPath": "pytorch_models.general_mf.utils.user_simialrity",
        "description": "pytorch_models.general_mf.utils.user_simialrity",
        "peekOfCode": "class NewUserPredictor:\n    def __init__(self, model, item_factors, num_features, num_users, device='cpu'):\n        \"\"\"\n        Initialize the NewUserPredictor.\n        :param model: Pre-trained MF model (BiasedMF_explicit_model instance).\n        :param item_factors: Pre-trained item factors (torch.tensor).\n        :param num_features: Number of latent features.\n        :param device: Compute device ('cpu' or 'cuda').\n        \"\"\"\n        self.model = model",
        "detail": "pytorch_models.general_mf.utils.user_simialrity",
        "documentation": {}
    },
    {
        "label": "find_similar_items",
        "kind": 2,
        "importPath": "pytorch_models.general_mf.utils.user_simialrity",
        "description": "pytorch_models.general_mf.utils.user_simialrity",
        "peekOfCode": "def find_similar_items(item_index, item_factors, top_k=3):\n    \"\"\"\n          .\n    :param item_index:      \n    :param item_factors:     \n    :param top_k:     \n    :return:     top_k    \n    \"\"\"\n    #    \n    target_item_vector = item_factors[item_index].reshape(1, -1)",
        "detail": "pytorch_models.general_mf.utils.user_simialrity",
        "documentation": {}
    },
    {
        "label": "RatingDataset",
        "kind": 6,
        "importPath": "pytorch_models.general_mf.utils.utils",
        "description": "pytorch_models.general_mf.utils.utils",
        "peekOfCode": "class RatingDataset(Dataset):\n    def __init__(self, data):\n        self.users = torch.LongTensor(data[:, 0])\n        self.items = torch.LongTensor(data[:, 1])\n        self.ratings = torch.FloatTensor(data[:, 2])\n    def __len__(self):\n        return len(self.ratings)\n    def __getitem__(self, idx):\n        return self.users[idx], self.items[idx], self.ratings[idx]\n# Checkpoints",
        "detail": "pytorch_models.general_mf.utils.utils",
        "documentation": {}
    },
    {
        "label": "save_checkpoint",
        "kind": 2,
        "importPath": "pytorch_models.general_mf.utils.utils",
        "description": "pytorch_models.general_mf.utils.utils",
        "peekOfCode": "def save_checkpoint(model, model_dir):\n    torch.save(model.state_dict(), model_dir)\ndef resume_checkpoint(model, model_dir, device_id):\n    state_dict = torch.load(model_dir,\n                            map_location=lambda storage, loc: storage.cuda(device=device_id))  # ensure all storage are on gpu\n    model.load_state_dict(state_dict)\ndef load_data(data_name, implicit=True):\n    data_path = './data/%s' % (data_name)\n    column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n    movie_data = pd.read_csv(data_path, names=column_names)",
        "detail": "pytorch_models.general_mf.utils.utils",
        "documentation": {}
    },
    {
        "label": "resume_checkpoint",
        "kind": 2,
        "importPath": "pytorch_models.general_mf.utils.utils",
        "description": "pytorch_models.general_mf.utils.utils",
        "peekOfCode": "def resume_checkpoint(model, model_dir, device_id):\n    state_dict = torch.load(model_dir,\n                            map_location=lambda storage, loc: storage.cuda(device=device_id))  # ensure all storage are on gpu\n    model.load_state_dict(state_dict)\ndef load_data(data_name, implicit=True):\n    data_path = './data/%s' % (data_name)\n    column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n    movie_data = pd.read_csv(data_path, names=column_names)\n    if implicit:\n        movie_data['rating'] = 1",
        "detail": "pytorch_models.general_mf.utils.utils",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "pytorch_models.general_mf.utils.utils",
        "description": "pytorch_models.general_mf.utils.utils",
        "peekOfCode": "def load_data(data_name, implicit=True):\n    data_path = './data/%s' % (data_name)\n    column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n    movie_data = pd.read_csv(data_path, names=column_names)\n    if implicit:\n        movie_data['rating'] = 1\n    user_list = list(movie_data['user_id'].unique())\n    item_list = list(movie_data['item_id'].unique())\n    num_users = len(user_list)\n    num_items = len(item_list)",
        "detail": "pytorch_models.general_mf.utils.utils",
        "documentation": {}
    },
    {
        "label": "eval_implicit",
        "kind": 2,
        "importPath": "pytorch_models.general_mf.utils.utils",
        "description": "pytorch_models.general_mf.utils.utils",
        "peekOfCode": "def eval_implicit(model, train_data, test_data, top_k):\n    prec_list = []\n    recall_list = []\n    ndcg_list = []\n    rr_list = []\n    ap_list = []\n    hit_rate_list = []  # Hit Rate      \n    if 'Item' in model.__class__.__name__:\n        num_users, num_items = train_data.shape\n        pred_matrix = np.zeros((num_users, num_items))",
        "detail": "pytorch_models.general_mf.utils.utils",
        "documentation": {}
    },
    {
        "label": "MFPredictor",
        "kind": 6,
        "importPath": "pytorch_models.general_mf.mf_model",
        "description": "pytorch_models.general_mf.mf_model",
        "peekOfCode": "class MFPredictor:\n    def __init__(self):\n        self.dir = 'pytorch_models/general_mf'\n        self.topk = 30\n        params = self.load_params()\n        self.mf_model = BPRMFTrainer(self.dir, params[\"n_features\"], params[\"learning_rate\"], \n                                     params[\"reg_lambda\"], params[\"num_epochs\"], params[\"batch_size\"], \n                                     params[\"patience\"], params[\"num_negatives\"], \n                                     path=os.path.join(self.dir, 'pth/bpr_mf_model_20.pth'))\n        self.item_id_map = self.load_dict_from_pickle(os.path.join(self.dir, 'data/item_dict.pkl'))",
        "detail": "pytorch_models.general_mf.mf_model",
        "documentation": {}
    },
    {
        "label": "mf_predictor",
        "kind": 5,
        "importPath": "pytorch_models.general_mf.mf_model",
        "description": "pytorch_models.general_mf.mf_model",
        "peekOfCode": "mf_predictor = MFPredictor()",
        "detail": "pytorch_models.general_mf.mf_model",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--movies_file',\n                        default='movies.csv',\n                        help='Path to the CSV file containing movie information')\n    parser.add_argument('--interactions_file',\n                        default='train.csv',\n                        help='Path to the CSV file containing user movie interactions')\n    parser.add_argument('--subnetwork',\n                        default='dense',",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "get_personId",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def get_personId(person_link):\n    try:\n        str_idx = person_link.find('personId=')\n        return person_link[str_idx+9:]\n    except:\n        return ''\ndef make_person_list(row):\n    try:\n        person_set = re.findall(r'personId=(\\d+)', row['cast'])\n        return list(set(person_set))",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "make_person_list",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def make_person_list(row):\n    try:\n        person_set = re.findall(r'personId=(\\d+)', row['cast'])\n        return list(set(person_set))\n    except TypeError:\n        return []\ndef movie_data_prep(movies_file, interactions_file, export_dir):\n    '''\n    :return: Write out 4 python dictionaries for the edges of KG\n    '''",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "movie_data_prep",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def movie_data_prep(movies_file, interactions_file, export_dir):\n    '''\n    :return: Write out 4 python dictionaries for the edges of KG\n    '''\n    movies = pd.read_csv(movies_file)\n    interactions = pd.read_csv(interactions_file)\n    # movie_person.dict\n    # dict where key = movieId, value = list of persons (, , ) of the movie\n    #  \n    person = movies[['movieId', 'cast']]",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "find_subnetwork",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def find_subnetwork(network_type, dir, factor=0.1):\n    if network_type == 'full':\n        return\n    # Load Data\n    with open(dir + consts.MOVIE_USER_DICT, 'rb') as handle:\n        movie_user = pickle.load(handle)\n    with open(dir + consts.USER_MOVIE_DICT, 'rb') as handle:\n        user_movie = pickle.load(handle)\n    with open(dir + consts.MOVIE_PERSON_DICT, 'rb') as handle:\n        movie_person = pickle.load(handle)",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "convert_to_ids",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def convert_to_ids(entity_to_ix, rel_dict, start_type, end_type):\n    new_rel = {}\n    for key, values in rel_dict.items():\n        key_id = entity_to_ix[(key, start_type)]\n        value_ids = []\n        for val in values:\n            try:\n                value_ids.append(entity_to_ix[(val, end_type)])\n            except KeyError:\n                print(key)",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "ix_mapping",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def ix_mapping(network_type, import_dir, export_dir, mapping_export_dir):\n    pad_token = consts.PAD_TOKEN\n    type_to_ix = {'person': consts.PERSON_TYPE, 'user': consts.USER_TYPE, 'movie': consts.MOVIE_TYPE,\n                  pad_token: consts.PAD_TYPE}\n    relation_to_ix = {'movie_person': consts.MOVIE_PERSON_REL, 'person_movie': consts.PERSON_MOVIE_REL,\n                      'user_movie': consts.USER_MOVIE_REL, 'movie_user': consts.MOVIE_USER_REL, '#UNK_RELATION': consts.UNK_REL,\n                      '#END_RELATION': consts.END_REL, pad_token: consts.PAD_REL}\n    # entity vocab set is combination of movies, users, and persons\n    movie_data_prefix = import_dir + network_type\n    with open(movie_data_prefix + consts.MOVIE_USER_DICT, 'rb') as handle:",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def train_test_split(network_type, dir):\n    with open(dir + network_type + '_ix_' + consts.USER_MOVIE_DICT, 'rb') as handle:\n        user_movie = pickle.load(handle)\n    # KG and positive\n    train_user_movie = {}\n    test_user_movie = {}\n    train_movie_user = defaultdict(list)\n    test_movie_user = defaultdict(list)\n    for user in user_movie:\n        pos_movies = user_movie[user]",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "create_directory",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def create_directory(dir):\n    print(\"Creating directory %s\" % dir)\n    try:\n        mkdir(dir)\n    except FileExistsError:\n        print(\"Directory already exists\")\ndef main():\n    print(\"Data preparation:\")\n    args = parse_args()\n    network_prefix = args.subnetwork",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.data_preparation",
        "description": "pytorch_models.kprn.kprn_data.data_preparation",
        "peekOfCode": "def main():\n    print(\"Data preparation:\")\n    args = parse_args()\n    network_prefix = args.subnetwork\n    if network_prefix == 'full':\n       network_prefix = ''\n    print(\"Forming knowledge graph...\")\n    create_directory(consts.MOVIE_DATA_DIR)\n    movie_data_prep(consts.MOVIE_DATASET_DIR + args.movies_file,\n                   consts.MOVIE_DATASET_DIR + args.interactions_file,",
        "detail": "pytorch_models.kprn.kprn_data.data_preparation",
        "documentation": {}
    },
    {
        "label": "format_paths",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.format",
        "description": "pytorch_models.kprn.kprn_data.format",
        "peekOfCode": "def format_paths(paths, e_to_ix, t_to_ix, r_to_ix):\n    '''\n    Pads paths up to max path length, converting each path into tuple\n    of (padded_path, path length).\n    '''\n    new_paths = []\n    for path in paths:\n        path_len = len(path)\n        pad_path(path, e_to_ix, t_to_ix, r_to_ix, MAX_PATH_LEN, PAD_TOKEN)\n        new_paths.append((path, path_len))",
        "detail": "pytorch_models.kprn.kprn_data.format",
        "documentation": {}
    },
    {
        "label": "find_max_train_length",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.format",
        "description": "pytorch_models.kprn.kprn_data.format",
        "peekOfCode": "def find_max_train_length(data_tuples):\n    '''\n    Finds max path length in a list of (interaction, target) tuples\n    '''\n    max_len = 0\n    for (paths, _) in data_tuples:\n        for path in paths:\n            max_len = max(len(path), max_len)\n    return max_len\ndef pad_path(seq, e_to_ix, t_to_ix, r_to_ix, max_len, padding_token):",
        "detail": "pytorch_models.kprn.kprn_data.format",
        "documentation": {}
    },
    {
        "label": "pad_path",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.format",
        "description": "pytorch_models.kprn.kprn_data.format",
        "peekOfCode": "def pad_path(seq, e_to_ix, t_to_ix, r_to_ix, max_len, padding_token):\n    '''\n    Pads paths up to max path length\n    '''\n    relation_padding =  r_to_ix[padding_token]\n    type_padding = t_to_ix[padding_token]\n    entity_padding = e_to_ix[padding_token]\n    while len(seq) < max_len:\n        seq.append([entity_padding, type_padding, relation_padding])\n    return seq",
        "detail": "pytorch_models.kprn.kprn_data.format",
        "documentation": {}
    },
    {
        "label": "MAX_PATH_LEN",
        "kind": 5,
        "importPath": "pytorch_models.kprn.kprn_data.format",
        "description": "pytorch_models.kprn.kprn_data.format",
        "peekOfCode": "MAX_PATH_LEN = 6\nPAD_TOKEN = \"#PAD_TOKEN\"\n'''\nfunctions used for converting path data into format for KPRN model\n'''\ndef format_paths(paths, e_to_ix, t_to_ix, r_to_ix):\n    '''\n    Pads paths up to max path length, converting each path into tuple\n    of (padded_path, path length).\n    '''",
        "detail": "pytorch_models.kprn.kprn_data.format",
        "documentation": {}
    },
    {
        "label": "PAD_TOKEN",
        "kind": 5,
        "importPath": "pytorch_models.kprn.kprn_data.format",
        "description": "pytorch_models.kprn.kprn_data.format",
        "peekOfCode": "PAD_TOKEN = \"#PAD_TOKEN\"\n'''\nfunctions used for converting path data into format for KPRN model\n'''\ndef format_paths(paths, e_to_ix, t_to_ix, r_to_ix):\n    '''\n    Pads paths up to max path length, converting each path into tuple\n    of (padded_path, path length).\n    '''\n    new_paths = []",
        "detail": "pytorch_models.kprn.kprn_data.format",
        "documentation": {}
    },
    {
        "label": "convert_train_paths_to_interactions",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "description": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "peekOfCode": "def convert_train_paths_to_interactions(file_name):\n    '''\n    Converts train path file to list of (user,song) interaction tuples\n    '''\n    pos_interactions = []\n    neg_interactions = []\n    data_path = PATH_DATA_DIR + file_name\n    with open(data_path, 'r') as f:\n        for line in f:\n            interaction = eval(line.rstrip(\"\\n\"))",
        "detail": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "documentation": {}
    },
    {
        "label": "convert_test_paths_to_interactions",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "description": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "peekOfCode": "def convert_test_paths_to_interactions(file_name):\n    '''\n    Converts test path file to list of (user,song) interaction tuples\n    '''\n    pos_interactions = []\n    neg_interactions = []\n    data_path = consts.PATH_DATA_DIR + file_name\n    with open(data_path, 'r') as f:\n        for line in f:\n            interactions = eval(line.rstrip(\"\\n\"))",
        "detail": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "documentation": {}
    },
    {
        "label": "save_interactions",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "description": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "peekOfCode": "def save_interactions(interactions, file_name):\n    with open('../baseline/interactions/'+ file_name, 'wb') as f:\n        pickle.dump(interactions, f, protocol=pickle.HIGHEST_PROTOCOL)\ndef main():\n    '''\n    Used to convert paths to interaction tuples for use with Baseline\n    This ensures we are evaluating on the same interactions across models\n    '''\n    # train_pos_inters, train_neg_inters = convert_train_paths_to_interactions(\"train_inters_rs_all.txt\")\n    # save_interactions(train_pos_inters, 'rs_train_pos_interactions.txt')",
        "detail": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "description": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "peekOfCode": "def main():\n    '''\n    Used to convert paths to interaction tuples for use with Baseline\n    This ensures we are evaluating on the same interactions across models\n    '''\n    # train_pos_inters, train_neg_inters = convert_train_paths_to_interactions(\"train_inters_rs_all.txt\")\n    # save_interactions(train_pos_inters, 'rs_train_pos_interactions.txt')\n    # save_interactions(train_neg_inters, 'rs_train_neg_interactions.txt')\n    # test_pos_inters, test_neg_inters = convert_test_paths_to_interactions(\"test_inters_rs_all.txt\")\n    # save_interactions(test_pos_inters, 'rs_test_pos_interactions.txt')",
        "detail": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "documentation": {}
    },
    {
        "label": "PATH_DATA_DIR",
        "kind": 5,
        "importPath": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "description": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "peekOfCode": "PATH_DATA_DIR = \"path_data/\"\ndef convert_train_paths_to_interactions(file_name):\n    '''\n    Converts train path file to list of (user,song) interaction tuples\n    '''\n    pos_interactions = []\n    neg_interactions = []\n    data_path = PATH_DATA_DIR + file_name\n    with open(data_path, 'r') as f:\n        for line in f:",
        "detail": "pytorch_models.kprn.kprn_data.interaction_conversion",
        "documentation": {}
    },
    {
        "label": "PathState",
        "kind": 6,
        "importPath": "pytorch_models.kprn.kprn_data.path_extraction",
        "description": "pytorch_models.kprn.kprn_data.path_extraction",
        "peekOfCode": "class PathState:\n    def __init__(self, path, length, entities):\n        self.path = path    # array of [entity, entity type, relation to next] triplets\n        self.length = length\n        self.entities = entities    # set to keep track of the entities alr in the path to avoid cycles\ndef get_random_index(nums, max_length):\n    index_list = list(range(max_length))\n    random.shuffle(index_list)\n    return index_list[:nums]\ndef find_paths_user_to_movies(start_user, movie_person, person_movie, movie_user, user_movie, max_length, sample_nums):",
        "detail": "pytorch_models.kprn.kprn_data.path_extraction",
        "documentation": {}
    },
    {
        "label": "get_random_index",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.path_extraction",
        "description": "pytorch_models.kprn.kprn_data.path_extraction",
        "peekOfCode": "def get_random_index(nums, max_length):\n    index_list = list(range(max_length))\n    random.shuffle(index_list)\n    return index_list[:nums]\ndef find_paths_user_to_movies(start_user, movie_person, person_movie, movie_user, user_movie, max_length, sample_nums):\n    '''\n    Finds sampled paths of max depth from a user to a sampling of movies\n    '''\n    movie_to_paths = defaultdict(list)\n    stack = []",
        "detail": "pytorch_models.kprn.kprn_data.path_extraction",
        "documentation": {}
    },
    {
        "label": "find_paths_user_to_movies",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.path_extraction",
        "description": "pytorch_models.kprn.kprn_data.path_extraction",
        "peekOfCode": "def find_paths_user_to_movies(start_user, movie_person, person_movie, movie_user, user_movie, max_length, sample_nums):\n    '''\n    Finds sampled paths of max depth from a user to a sampling of movies\n    '''\n    movie_to_paths = defaultdict(list)\n    stack = []\n    start = PathState([[start_user, params[\"USER_TYPE\"], params[\"END_REL\"]]], 0, {start_user})\n    stack.append(start)\n    while len(stack) > 0:\n        front = stack.pop()",
        "detail": "pytorch_models.kprn.kprn_data.path_extraction",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "pytorch_models.kprn.kprn_data.path_extraction",
        "description": "pytorch_models.kprn.kprn_data.path_extraction",
        "peekOfCode": "def main():\n    with open(\"movie_data_ix/dense_ix_movie_person.dict\", 'rb') as handle:\n        movie_person = pickle.load(handle)\n    with open(\"movie_data_ix/dense_ix_person_movie.dict\", 'rb') as handle:\n        person_movie = pickle.load(handle)\n    with open(\"movie_data_ix/dense_ix_movie_user.dict\", 'rb') as handle:\n        movie_user = pickle.load(handle)\n    with open(\"movie_data_ix/dense_ix_user_movie.dict\", 'rb') as handle:\n        user_movie = pickle.load(handle)\n    print(find_paths_user_to_movies('', movie_person, person_movie, movie_user, user_movie, 3, 1))",
        "detail": "pytorch_models.kprn.kprn_data.path_extraction",
        "documentation": {}
    },
    {
        "label": "KPRN",
        "kind": 6,
        "importPath": "pytorch_models.kprn.model",
        "description": "pytorch_models.kprn.model",
        "peekOfCode": "class KPRN(nn.Module):\n    def __init__(self, e_emb_dim, t_emb_dim, r_emb_dim, hidden_dim, e_vocab_size,\n                 t_vocab_size, r_vocab_size, tagset_size, no_rel):\n        super(KPRN, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.entity_embeddings = nn.Embedding(e_vocab_size, e_emb_dim)\n        self.type_embeddings = nn.Embedding(t_vocab_size, t_emb_dim)\n        self.rel_embeddings = nn.Embedding(r_vocab_size, r_emb_dim)\n        # The LSTM takes word embeddings as inputs, and outputs hidden states\n        # with dimensionality hidden_dim.",
        "detail": "pytorch_models.kprn.model",
        "documentation": {}
    },
    {
        "label": "TestInteractionData",
        "kind": 6,
        "importPath": "pytorch_models.kprn.predictor",
        "description": "pytorch_models.kprn.predictor",
        "peekOfCode": "class TestInteractionData(Dataset):\n    def __init__(self, formatted_data):\n        self.data = formatted_data\n    def __getitem__(self, index):\n        return self.data[index]\n    def __len__(self):\n        return len(self.data)\ndef convert_to_etr(e_to_ix, t_to_ix, r_to_ix, path, length):\n    '''\n    Converts a path of ids back to the original input format",
        "detail": "pytorch_models.kprn.predictor",
        "documentation": {}
    },
    {
        "label": "convert_to_etr",
        "kind": 2,
        "importPath": "pytorch_models.kprn.predictor",
        "description": "pytorch_models.kprn.predictor",
        "peekOfCode": "def convert_to_etr(e_to_ix, t_to_ix, r_to_ix, path, length):\n    '''\n    Converts a path of ids back to the original input format\n    -not used for anything right now but could be useful for visualization\n    '''\n    ix_to_t = {v: k for k, v in t_to_ix.items()}\n    ix_to_r = {v: k for k, v in r_to_ix.items()}\n    ix_to_e = {v: k for k, v in e_to_ix.items()}\n    new_path = []\n    for i,step in enumerate(path):",
        "detail": "pytorch_models.kprn.predictor",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "pytorch_models.kprn.predictor",
        "description": "pytorch_models.kprn.predictor",
        "peekOfCode": "def predict(model, formatted_data, batch_size, device, no_rel, gamma):\n    '''\n    -outputs predicted scores for the input test data\n    -formatted_data is a list of path lists, each of which consists of tuples of\n    (path, tag, path_length), where the path is padded to ensure same overall length\n    -Since we are evaluating we ignore the tag here\n    '''\n    prediction_scores = []\n    interaction_data = TestInteractionData(formatted_data)\n    #shuffle false since we want data to remain in order for comparison",
        "detail": "pytorch_models.kprn.predictor",
        "documentation": {}
    },
    {
        "label": "TrainInteractionData",
        "kind": 6,
        "importPath": "pytorch_models.kprn.train",
        "description": "pytorch_models.kprn.train",
        "peekOfCode": "class TrainInteractionData(Dataset):\n    '''\n    Dataset that can either store all interaction data in memory or load it line\n    by line when needed\n    '''\n    def __init__(self, train_path_file, in_memory=True):\n        self.in_memory = in_memory\n        self.file = 'data/path_data/' + train_path_file\n        self.num_interactions = 0\n        self.interactions = []",
        "detail": "pytorch_models.kprn.train",
        "documentation": {}
    },
    {
        "label": "my_collate",
        "kind": 2,
        "importPath": "pytorch_models.kprn.train",
        "description": "pytorch_models.kprn.train",
        "peekOfCode": "def my_collate(batch):\n    '''\n    Custom dataloader collate function since we have tuples of lists of paths\n    '''\n    data = [item[0] for item in batch]\n    target = [item[1] for item in batch]\n    target = torch.LongTensor(target)\n    return [data, target]\ndef sort_batch(batch, indexes, lengths):\n    '''",
        "detail": "pytorch_models.kprn.train",
        "documentation": {}
    },
    {
        "label": "sort_batch",
        "kind": 2,
        "importPath": "pytorch_models.kprn.train",
        "description": "pytorch_models.kprn.train",
        "peekOfCode": "def sort_batch(batch, indexes, lengths):\n    '''\n    sorts a batch of paths by path length, in decreasing order\n    '''\n    seq_lengths, perm_idx = lengths.sort(0, descending=True)\n    seq_tensor = batch[perm_idx]\n    indexes_tensor = indexes[perm_idx]\n    return seq_tensor, indexes_tensor, seq_lengths\ndef train(model, train_path_file, batch_size, epochs, model_path, load_checkpoint,\n         not_in_memory, lr, l2_reg, gamma, no_rel):",
        "detail": "pytorch_models.kprn.train",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pytorch_models.kprn.train",
        "description": "pytorch_models.kprn.train",
        "peekOfCode": "def train(model, train_path_file, batch_size, epochs, model_path, load_checkpoint,\n         not_in_memory, lr, l2_reg, gamma, no_rel):\n    '''\n    -trains and outputs a model using the input data\n    -formatted_data is a list of path lists, each of which consists of tuples of\n    (path, tag, path_length), where the path is padded to ensure same overall length\n    '''\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"Device is\", device)\n    model = model.to(device)",
        "detail": "pytorch_models.kprn.train",
        "documentation": {}
    },
    {
        "label": "NGCFServingModel",
        "kind": 6,
        "importPath": "pytorch_models.ngcf.serving.serving",
        "description": "pytorch_models.ngcf.serving.serving",
        "peekOfCode": "class NGCFServingModel(Model):\n    def __init__(self, name: str, model_path: str):\n        super().__init__(name)\n        self.name = name\n        self.model_path = model_path\n        self.model = None\n        self.device = 'cpu'  #  'cuda' if using GPU\n        self.load()\n        self.ngcf_predictor = ngcf_predictor\n    def load(self):",
        "detail": "pytorch_models.ngcf.serving.serving",
        "documentation": {}
    },
    {
        "label": "ranklist_by_heapq",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "def ranklist_by_heapq(user_pos_test, test_items, rating, Ks):\n    item_score = {}\n    for i in test_items:\n        item_score[i] = rating[i]\n    K_max = max(Ks)\n    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n    r = []\n    for i in K_max_item_score:\n        if i in user_pos_test:\n            r.append(1)",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "get_auc",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "def get_auc(item_score, user_pos_test):\n    item_score = sorted(item_score.items(), key=lambda kv: kv[1])\n    item_score.reverse()\n    item_sort = [x[0] for x in item_score]\n    posterior = [x[1] for x in item_score]\n    r = []\n    for i in item_sort:\n        if i in user_pos_test:\n            r.append(1)\n        else:",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "ranklist_by_sorted",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "def ranklist_by_sorted(user_pos_test, test_items, rating, Ks):\n    item_score = {}\n    for i in test_items:\n        item_score[i] = rating[i]\n    K_max = max(Ks)\n    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n    r = []\n    for i in K_max_item_score:\n        if i in user_pos_test:\n            r.append(1)",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "get_performance",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "def get_performance(user_pos_test, r, auc, Ks):\n    precision, recall, ndcg, hit_ratio = [], [], [], []\n    for K in Ks:\n        precision.append(metrics.precision_at_k(r, K))\n        recall.append(metrics.recall_at_k(r, K, len(user_pos_test)))\n        ndcg.append(metrics.ndcg_at_k(r, K))\n        hit_ratio.append(metrics.hit_at_k(r, K))\n    return {\n        \"recall\": np.array(recall),\n        \"precision\": np.array(precision),",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "test_one_user",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "def test_one_user(x):\n    # user u's ratings for user u\n    rating = x[0]\n    # uid\n    u = x[1]\n    # user u's items in the training set\n    try:\n        training_items = data_generator.train_items[u]\n    except Exception:\n        training_items = []",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "def test(model, g, users_to_test, batch_test_flag=False):\n    result = {\n        \"precision\": np.zeros(len(Ks)),\n        \"recall\": np.zeros(len(Ks)),\n        \"ndcg\": np.zeros(len(Ks)),\n        \"hit_ratio\": np.zeros(len(Ks)),\n        \"auc\": 0.0,\n    }\n    pool = multiprocessing.Pool(cores)\n    u_batch_size = 5000",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "cores",
        "kind": 5,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "cores = multiprocessing.cpu_count()\nargs = parse_args()\nKs = eval(args.Ks)\ndata_generator = Data(\n    path=args.data_path + args.dataset, batch_size=args.batch_size\n)\nUSR_NUM, ITEM_NUM = data_generator.n_users, data_generator.n_items\nN_TRAIN, N_TEST = data_generator.n_train, data_generator.n_test\nBATCH_SIZE = args.batch_size\ndef ranklist_by_heapq(user_pos_test, test_items, rating, Ks):",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "args = parse_args()\nKs = eval(args.Ks)\ndata_generator = Data(\n    path=args.data_path + args.dataset, batch_size=args.batch_size\n)\nUSR_NUM, ITEM_NUM = data_generator.n_users, data_generator.n_items\nN_TRAIN, N_TEST = data_generator.n_train, data_generator.n_test\nBATCH_SIZE = args.batch_size\ndef ranklist_by_heapq(user_pos_test, test_items, rating, Ks):\n    item_score = {}",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "Ks",
        "kind": 5,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "Ks = eval(args.Ks)\ndata_generator = Data(\n    path=args.data_path + args.dataset, batch_size=args.batch_size\n)\nUSR_NUM, ITEM_NUM = data_generator.n_users, data_generator.n_items\nN_TRAIN, N_TEST = data_generator.n_train, data_generator.n_test\nBATCH_SIZE = args.batch_size\ndef ranklist_by_heapq(user_pos_test, test_items, rating, Ks):\n    item_score = {}\n    for i in test_items:",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "data_generator",
        "kind": 5,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "data_generator = Data(\n    path=args.data_path + args.dataset, batch_size=args.batch_size\n)\nUSR_NUM, ITEM_NUM = data_generator.n_users, data_generator.n_items\nN_TRAIN, N_TEST = data_generator.n_train, data_generator.n_test\nBATCH_SIZE = args.batch_size\ndef ranklist_by_heapq(user_pos_test, test_items, rating, Ks):\n    item_score = {}\n    for i in test_items:\n        item_score[i] = rating[i]",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "BATCH_SIZE",
        "kind": 5,
        "importPath": "pytorch_models.ngcf.utility.batch_test",
        "description": "pytorch_models.ngcf.utility.batch_test",
        "peekOfCode": "BATCH_SIZE = args.batch_size\ndef ranklist_by_heapq(user_pos_test, test_items, rating, Ks):\n    item_score = {}\n    for i in test_items:\n        item_score[i] = rating[i]\n    K_max = max(Ks)\n    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n    r = []\n    for i in K_max_item_score:\n        if i in user_pos_test:",
        "detail": "pytorch_models.ngcf.utility.batch_test",
        "documentation": {}
    },
    {
        "label": "txt2list",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.helper",
        "description": "pytorch_models.ngcf.utility.helper",
        "peekOfCode": "def txt2list(file_src):\n    orig_file = open(file_src, \"r\")\n    lines = orig_file.readlines()\n    return lines\ndef ensureDir(dir_path):\n    d = os.path.dirname(dir_path)\n    if not os.path.exists(d):\n        os.makedirs(d)\ndef uni2str(unicode_str):\n    return str(unicode_str.encode(\"ascii\", \"ignore\")).replace(\"\\n\", \"\").strip()",
        "detail": "pytorch_models.ngcf.utility.helper",
        "documentation": {}
    },
    {
        "label": "ensureDir",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.helper",
        "description": "pytorch_models.ngcf.utility.helper",
        "peekOfCode": "def ensureDir(dir_path):\n    d = os.path.dirname(dir_path)\n    if not os.path.exists(d):\n        os.makedirs(d)\ndef uni2str(unicode_str):\n    return str(unicode_str.encode(\"ascii\", \"ignore\")).replace(\"\\n\", \"\").strip()\ndef hasNumbers(inputString):\n    return bool(re.search(r\"\\d\", inputString))\ndef delMultiChar(inputString, chars):\n    for ch in chars:",
        "detail": "pytorch_models.ngcf.utility.helper",
        "documentation": {}
    },
    {
        "label": "uni2str",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.helper",
        "description": "pytorch_models.ngcf.utility.helper",
        "peekOfCode": "def uni2str(unicode_str):\n    return str(unicode_str.encode(\"ascii\", \"ignore\")).replace(\"\\n\", \"\").strip()\ndef hasNumbers(inputString):\n    return bool(re.search(r\"\\d\", inputString))\ndef delMultiChar(inputString, chars):\n    for ch in chars:\n        inputString = inputString.replace(ch, \"\")\n    return inputString\ndef merge_two_dicts(x, y):\n    z = x.copy()  # start with x's keys and values",
        "detail": "pytorch_models.ngcf.utility.helper",
        "documentation": {}
    },
    {
        "label": "hasNumbers",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.helper",
        "description": "pytorch_models.ngcf.utility.helper",
        "peekOfCode": "def hasNumbers(inputString):\n    return bool(re.search(r\"\\d\", inputString))\ndef delMultiChar(inputString, chars):\n    for ch in chars:\n        inputString = inputString.replace(ch, \"\")\n    return inputString\ndef merge_two_dicts(x, y):\n    z = x.copy()  # start with x's keys and values\n    z.update(y)  # modifies z with y's keys and values & returns None\n    return z",
        "detail": "pytorch_models.ngcf.utility.helper",
        "documentation": {}
    },
    {
        "label": "delMultiChar",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.helper",
        "description": "pytorch_models.ngcf.utility.helper",
        "peekOfCode": "def delMultiChar(inputString, chars):\n    for ch in chars:\n        inputString = inputString.replace(ch, \"\")\n    return inputString\ndef merge_two_dicts(x, y):\n    z = x.copy()  # start with x's keys and values\n    z.update(y)  # modifies z with y's keys and values & returns None\n    return z\ndef early_stopping(\n    log_value, best_value, stopping_step, expected_order=\"acc\", flag_step=100",
        "detail": "pytorch_models.ngcf.utility.helper",
        "documentation": {}
    },
    {
        "label": "merge_two_dicts",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.helper",
        "description": "pytorch_models.ngcf.utility.helper",
        "peekOfCode": "def merge_two_dicts(x, y):\n    z = x.copy()  # start with x's keys and values\n    z.update(y)  # modifies z with y's keys and values & returns None\n    return z\ndef early_stopping(\n    log_value, best_value, stopping_step, expected_order=\"acc\", flag_step=100\n):\n    # early stopping strategy:\n    assert expected_order in [\"acc\", \"dec\"]\n    if (expected_order == \"acc\" and log_value >= best_value) or (",
        "detail": "pytorch_models.ngcf.utility.helper",
        "documentation": {}
    },
    {
        "label": "early_stopping",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.helper",
        "description": "pytorch_models.ngcf.utility.helper",
        "peekOfCode": "def early_stopping(\n    log_value, best_value, stopping_step, expected_order=\"acc\", flag_step=100\n):\n    # early stopping strategy:\n    assert expected_order in [\"acc\", \"dec\"]\n    if (expected_order == \"acc\" and log_value >= best_value) or (\n        expected_order == \"dec\" and log_value <= best_value\n    ):\n        stopping_step = 0\n        best_value = log_value",
        "detail": "pytorch_models.ngcf.utility.helper",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "pytorch_models.ngcf.utility.helper",
        "description": "pytorch_models.ngcf.utility.helper",
        "peekOfCode": "__author__ = \"xiangwang\"\nimport os\nimport re\ndef txt2list(file_src):\n    orig_file = open(file_src, \"r\")\n    lines = orig_file.readlines()\n    return lines\ndef ensureDir(dir_path):\n    d = os.path.dirname(dir_path)\n    if not os.path.exists(d):",
        "detail": "pytorch_models.ngcf.utility.helper",
        "documentation": {}
    },
    {
        "label": "Data",
        "kind": 6,
        "importPath": "pytorch_models.ngcf.utility.load_data",
        "description": "pytorch_models.ngcf.utility.load_data",
        "peekOfCode": "class Data(object):\n    def __init__(self, path, batch_size):\n        self.path = path\n        self.batch_size = batch_size\n        train_file = path + \"/train.txt\"\n        test_file = path + \"/test.txt\"\n        # get number of users and items\n        self.n_users, self.n_items = 0, 0\n        self.n_train, self.n_test = 0, 0\n        self.exist_users = []",
        "detail": "pytorch_models.ngcf.utility.load_data",
        "documentation": {}
    },
    {
        "label": "recall",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def recall(rank, ground_truth, N):\n    return len(set(rank[:N]) & set(ground_truth)) / float(\n        len(set(ground_truth))\n    )\ndef precision_at_k(r, k):\n    \"\"\"Score is precision @ k\n    Relevance is binary (nonzero is relevant).\n    Returns:\n        Precision @ k\n    Raises:",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "precision_at_k",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def precision_at_k(r, k):\n    \"\"\"Score is precision @ k\n    Relevance is binary (nonzero is relevant).\n    Returns:\n        Precision @ k\n    Raises:\n        ValueError: len(r) must be >= k\n    \"\"\"\n    assert k >= 1\n    r = np.asarray(r)[:k]",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "average_precision",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def average_precision(r, cut):\n    \"\"\"Score is average precision (area under PR curve)\n    Relevance is binary (nonzero is relevant).\n    Returns:\n        Average precision\n    \"\"\"\n    r = np.asarray(r)\n    out = [precision_at_k(r, k + 1) for k in range(cut) if r[k]]\n    if not out:\n        return 0.0",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "mean_average_precision",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def mean_average_precision(rs):\n    \"\"\"Score is mean average precision\n    Relevance is binary (nonzero is relevant).\n    Returns:\n        Mean average precision\n    \"\"\"\n    return np.mean([average_precision(r) for r in rs])\ndef dcg_at_k(r, k, method=1):\n    \"\"\"Score is discounted cumulative gain (dcg)\n    Relevance is positive real values.  Can use binary",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "dcg_at_k",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def dcg_at_k(r, k, method=1):\n    \"\"\"Score is discounted cumulative gain (dcg)\n    Relevance is positive real values.  Can use binary\n    as the previous methods.\n    Returns:\n        Discounted cumulative gain\n    \"\"\"\n    r = np.asfarray(r)[:k]\n    if r.size:\n        if method == 0:",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "ndcg_at_k",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def ndcg_at_k(r, k, method=1):\n    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n    Relevance is positive real values.  Can use binary\n    as the previous methods.\n    Returns:\n        Normalized discounted cumulative gain\n    \"\"\"\n    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n    if not dcg_max:\n        return 0.0",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "recall_at_k",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def recall_at_k(r, k, all_pos_num):\n    r = np.asfarray(r)[:k]\n    return np.sum(r) / all_pos_num\ndef hit_at_k(r, k):\n    r = np.array(r)[:k]\n    if np.sum(r) > 0:\n        return 1.0\n    else:\n        return 0.0\ndef F1(pre, rec):",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "hit_at_k",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def hit_at_k(r, k):\n    r = np.array(r)[:k]\n    if np.sum(r) > 0:\n        return 1.0\n    else:\n        return 0.0\ndef F1(pre, rec):\n    if pre + rec > 0:\n        return (2.0 * pre * rec) / (pre + rec)\n    else:",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "F1",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def F1(pre, rec):\n    if pre + rec > 0:\n        return (2.0 * pre * rec) / (pre + rec)\n    else:\n        return 0.0\ndef auc(ground_truth, prediction):\n    try:\n        res = roc_auc_score(y_true=ground_truth, y_score=prediction)\n    except Exception:\n        res = 0.0",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.metrics",
        "description": "pytorch_models.ngcf.utility.metrics",
        "peekOfCode": "def auc(ground_truth, prediction):\n    try:\n        res = roc_auc_score(y_true=ground_truth, y_score=prediction)\n    except Exception:\n        res = 0.0\n    return res",
        "detail": "pytorch_models.ngcf.utility.metrics",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.utility.parser",
        "description": "pytorch_models.ngcf.utility.parser",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(description=\"Run NGCF.\")\n    parser.add_argument(\n        \"--weights_path\", nargs=\"?\", default=\"model/\", help=\"Store model path.\"\n    )\n    parser.add_argument(\n        \"--data_path\", nargs=\"?\", default=\"pytorch_models/Data/\", help=\"Input data path.\"\n    )\n    parser.add_argument(\n        \"--model_name\", type=str, default=\"NGCF.pkl\", help=\"Saved model name.\"",
        "detail": "pytorch_models.ngcf.utility.parser",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.main",
        "description": "pytorch_models.ngcf.main",
        "peekOfCode": "def main(args):\n    # Step 1: Prepare graph data and device ================================================================= #\n    if args.gpu >= 0 and torch.cuda.is_available():\n        device = \"cuda:{}\".format(args.gpu)\n    else:\n        device = \"cpu\"\n    g = data_generator.g\n    g = g.to(device)\n    # Step 2: Create model and training components=========================================================== #\n    model = NGCF(",
        "detail": "pytorch_models.ngcf.main",
        "documentation": {}
    },
    {
        "label": "NGCFLayer",
        "kind": 6,
        "importPath": "pytorch_models.ngcf.model",
        "description": "pytorch_models.ngcf.model",
        "peekOfCode": "class NGCFLayer(nn.Module):\n    def __init__(self, in_size, out_size, norm_dict, dropout):\n        super(NGCFLayer, self).__init__()\n        self.in_size = in_size\n        self.out_size = out_size\n        # weights for different types of messages\n        self.W1 = nn.Linear(in_size, out_size, bias=True)\n        self.W2 = nn.Linear(in_size, out_size, bias=True)\n        # leaky relu\n        self.leaky_relu = nn.LeakyReLU(0.2)",
        "detail": "pytorch_models.ngcf.model",
        "documentation": {}
    },
    {
        "label": "NGCF",
        "kind": 6,
        "importPath": "pytorch_models.ngcf.model",
        "description": "pytorch_models.ngcf.model",
        "peekOfCode": "class NGCF(nn.Module):\n    def __init__(self, g, in_size, layer_size, dropout, lmbd=1e-5):\n        super(NGCF, self).__init__()\n        self.lmbd = lmbd\n        self.norm_dict = dict()\n        for srctype, etype, dsttype in g.canonical_etypes:\n            src, dst = g.edges(etype=(srctype, etype, dsttype))\n            dst_degree = g.in_degrees(\n                dst, etype=(srctype, etype, dsttype)\n            ).float()  # obtain degrees",
        "detail": "pytorch_models.ngcf.model",
        "documentation": {}
    },
    {
        "label": "bpr_loss",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.model",
        "description": "pytorch_models.ngcf.model",
        "peekOfCode": "def bpr_loss(scores, neg_scores):\n    return -torch.log(torch.sigmoid(scores - neg_scores)).mean()\ndef new_user_retrain_recommend(model, g, new_user_id, interacted_items, all_items, top_k=5, num_epochs=10, lr=0.0001):\n    device = next(model.parameters()).device\n    # Clone the model and graph to avoid modifying the original ones\n    retrained_model = model.to(device)\n    retrained_g = g.clone().to(device)\n    # Add the new user to the graph\n    retrained_g = dgl.add_nodes(retrained_g, 1, ntype='user')\n    retrained_g.add_edges(new_user_id, interacted_items, etype='ui')",
        "detail": "pytorch_models.ngcf.model",
        "documentation": {}
    },
    {
        "label": "new_user_retrain_recommend",
        "kind": 2,
        "importPath": "pytorch_models.ngcf.model",
        "description": "pytorch_models.ngcf.model",
        "peekOfCode": "def new_user_retrain_recommend(model, g, new_user_id, interacted_items, all_items, top_k=5, num_epochs=10, lr=0.0001):\n    device = next(model.parameters()).device\n    # Clone the model and graph to avoid modifying the original ones\n    retrained_model = model.to(device)\n    retrained_g = g.clone().to(device)\n    # Add the new user to the graph\n    retrained_g = dgl.add_nodes(retrained_g, 1, ntype='user')\n    retrained_g.add_edges(new_user_id, interacted_items, etype='ui')\n    # Create an optimizer for retraining\n    optimizer = torch.optim.Adam(retrained_model.parameters(), lr=lr)",
        "detail": "pytorch_models.ngcf.model",
        "documentation": {}
    },
    {
        "label": "PointWiseFeedForward",
        "kind": 6,
        "importPath": "pytorch_models.sasrec.serving.model",
        "description": "pytorch_models.sasrec.serving.model",
        "peekOfCode": "class PointWiseFeedForward(torch.nn.Module):\n    def __init__(self, hidden_units, dropout_rate):\n        super(PointWiseFeedForward, self).__init__()\n        self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n        self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n        self.relu = torch.nn.ReLU()\n        self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n        self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n    def forward(self, inputs):\n        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))",
        "detail": "pytorch_models.sasrec.serving.model",
        "documentation": {}
    },
    {
        "label": "SASRec",
        "kind": 6,
        "importPath": "pytorch_models.sasrec.serving.model",
        "description": "pytorch_models.sasrec.serving.model",
        "peekOfCode": "class SASRec(torch.nn.Module):\n    def __init__(self, user_num, item_num, args):\n        super(SASRec, self).__init__()\n        self.user_num = user_num\n        self.item_num = item_num\n        self.dev = args.device\n        # TODO: loss += args.l2_emb for regularizing embedding vectors during training\n        # https://stackoverflow.com/questions/42704283/adding-l1-l2-regularization-in-pytorch\n        self.item_emb = torch.nn.Embedding(self.item_num + 1, args.hidden_units, padding_idx=0)\n        self.pos_emb = torch.nn.Embedding(args.maxlen, args.hidden_units)  # TO IMPROVE",
        "detail": "pytorch_models.sasrec.serving.model",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "pytorch_models.sasrec.serving.req_test",
        "description": "pytorch_models.sasrec.serving.req_test",
        "peekOfCode": "data = {\n    \"log_seqs\" : [1,2,3],\n    \"item_indices\" : [1,2,3,4]\n}\nprint(requests.post(\"http://localhost:8080/v1/models/SASRec:predict\", json=data).json())",
        "detail": "pytorch_models.sasrec.serving.req_test",
        "documentation": {}
    },
    {
        "label": "SASRecServingModel",
        "kind": 6,
        "importPath": "pytorch_models.sasrec.serving.serving",
        "description": "pytorch_models.sasrec.serving.serving",
        "peekOfCode": "class SASRecServingModel(Model):\n    def __init__(self, name: str, model_path: str):\n        super().__init__(name)\n        self.name = name\n        self.load(model_path)\n    def get_args(self):\n        parser = argparse.ArgumentParser()\n        parser.add_argument('--ratings_dir', required=True)\n        parser.add_argument('--model_output_dir', required=True)\n        parser.add_argument('--batch_size', default=128, type=int)",
        "detail": "pytorch_models.sasrec.serving.serving",
        "documentation": {}
    },
    {
        "label": "str2bool",
        "kind": 2,
        "importPath": "pytorch_models.sasrec.args",
        "description": "pytorch_models.sasrec.args",
        "peekOfCode": "def str2bool(s):\n    if s not in {'false', 'true'}:\n        raise ValueError('Not a valid boolean string')\n    return s == 'true'\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--dataset', required=True)\n    parser.add_argument('--train_dir', required=True)\n    parser.add_argument('--batch_size', default=128, type=int)\n    parser.add_argument('--lr', default=0.001, type=float)",
        "detail": "pytorch_models.sasrec.args",
        "documentation": {}
    },
    {
        "label": "get_args",
        "kind": 2,
        "importPath": "pytorch_models.sasrec.args",
        "description": "pytorch_models.sasrec.args",
        "peekOfCode": "def get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--dataset', required=True)\n    parser.add_argument('--train_dir', required=True)\n    parser.add_argument('--batch_size', default=128, type=int)\n    parser.add_argument('--lr', default=0.001, type=float)\n    parser.add_argument('--maxlen', default=50, type=int)\n    parser.add_argument('--hidden_units', default=50, type=int)\n    parser.add_argument('--num_blocks', default=2, type=int)\n    parser.add_argument('--num_epochs', default=200, type=int)",
        "detail": "pytorch_models.sasrec.args",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "pytorch_models.sasrec.args",
        "description": "pytorch_models.sasrec.args",
        "peekOfCode": "args = get_args()",
        "detail": "pytorch_models.sasrec.args",
        "documentation": {}
    },
    {
        "label": "PointWiseFeedForward",
        "kind": 6,
        "importPath": "pytorch_models.sasrec.model",
        "description": "pytorch_models.sasrec.model",
        "peekOfCode": "class PointWiseFeedForward(torch.nn.Module):\n    def __init__(self, hidden_units, dropout_rate):\n        super(PointWiseFeedForward, self).__init__()\n        self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n        self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n        self.relu = torch.nn.ReLU()\n        self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n        self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n    def forward(self, inputs):\n        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))",
        "detail": "pytorch_models.sasrec.model",
        "documentation": {}
    },
    {
        "label": "SASRec",
        "kind": 6,
        "importPath": "pytorch_models.sasrec.model",
        "description": "pytorch_models.sasrec.model",
        "peekOfCode": "class SASRec(torch.nn.Module):\n    def __init__(self, user_num, item_num, args):\n        super(SASRec, self).__init__()\n        self.user_num = user_num\n        self.item_num = item_num\n        self.dev = args.device\n        # TODO: loss += args.l2_emb for regularizing embedding vectors during training\n        # https://stackoverflow.com/questions/42704283/adding-l1-l2-regularization-in-pytorch\n        self.item_emb = torch.nn.Embedding(self.item_num + 1, args.hidden_units, padding_idx=0)\n        self.pos_emb = torch.nn.Embedding(args.maxlen, args.hidden_units)  # TO IMPROVE",
        "detail": "pytorch_models.sasrec.model",
        "documentation": {}
    },
    {
        "label": "UploadToS3",
        "kind": 6,
        "importPath": "pytorch_models.s3",
        "description": "pytorch_models.s3",
        "peekOfCode": "class UploadToS3():\n    def __init__(self, access_key_id, secret_access_key, bucket_name):\n        self.s3 = boto3.client('s3', \n                               aws_access_key_id=access_key_id, \n                               aws_secret_access_key=secret_access_key)\n        self.bucket = bucket_name\n    def upload_files_to_s3(self, local_directory, model_name, model_version):\n        for root, _, files in os.walk(local_directory):\n            for file in files:\n                local_path = os.path.join(root, file)",
        "detail": "pytorch_models.s3",
        "documentation": {}
    },
    {
        "label": "SinglePagesConfig",
        "kind": 6,
        "importPath": "single_pages.apps",
        "description": "single_pages.apps",
        "peekOfCode": "class SinglePagesConfig(AppConfig):\n    default_auto_field = 'django.db.models.BigAutoField'\n    name = 'single_pages'",
        "detail": "single_pages.apps",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "single_pages.urls",
        "description": "single_pages.urls",
        "peekOfCode": "urlpatterns = [\n    path('', views.about_us),\n]",
        "detail": "single_pages.urls",
        "documentation": {}
    },
    {
        "label": "about_us",
        "kind": 2,
        "importPath": "single_pages.views",
        "description": "single_pages.views",
        "peekOfCode": "def about_us(request):\n    return render(\n        request,\n        'single_pages/about_us.html'\n    )",
        "detail": "single_pages.views",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "users.migrations.0001_initial",
        "description": "users.migrations.0001_initial",
        "peekOfCode": "class Migration(migrations.Migration):\n    initial = True\n    dependencies = [\n        ('auth', '0012_alter_user_first_name_max_length'),\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='User',\n            fields=[\n                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),",
        "detail": "users.migrations.0001_initial",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "users.migrations.0002_user_profile_image_user_short_description",
        "description": "users.migrations.0002_user_profile_image_user_short_description",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('users', '0001_initial'),\n    ]\n    operations = [\n        migrations.AddField(\n            model_name='user',\n            name='profile_image',\n            field=models.ImageField(blank=True, upload_to='users/profile', verbose_name=' '),\n        ),",
        "detail": "users.migrations.0002_user_profile_image_user_short_description",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "users.migrations.0003_alter_user_profile_image_and_more",
        "description": "users.migrations.0003_alter_user_profile_image_and_more",
        "peekOfCode": "class Migration(migrations.Migration):\n    dependencies = [\n        ('users', '0002_user_profile_image_user_short_description'),\n    ]\n    operations = [\n        migrations.AlterField(\n            model_name='user',\n            name='profile_image',\n            field=models.ImageField(blank=True, null=True, upload_to='users/profile', verbose_name=' '),\n        ),",
        "detail": "users.migrations.0003_alter_user_profile_image_and_more",
        "documentation": {}
    },
    {
        "label": "CustomUserAdmin",
        "kind": 6,
        "importPath": "users.admin",
        "description": "users.admin",
        "peekOfCode": "class CustomUserAdmin(UserAdmin):\n    fieldsets = [\n        (None, {\"fields\": (\"username\", \"password\")}),\n        (\"\", {\"fields\": (\"first_name\", \"last_name\", \"email\")}),\n        (\"\", {\"fields\": (\"profile_image\", \"short_description\")}),\n        (\n            \"\",\n            {\n                \"fields\": (\n                    \"is_active\",",
        "detail": "users.admin",
        "documentation": {}
    },
    {
        "label": "UsersConfig",
        "kind": 6,
        "importPath": "users.apps",
        "description": "users.apps",
        "peekOfCode": "class UsersConfig(AppConfig):\n    default_auto_field = 'django.db.models.BigAutoField'\n    name = 'users'",
        "detail": "users.apps",
        "documentation": {}
    },
    {
        "label": "LoginForm",
        "kind": 6,
        "importPath": "users.forms",
        "description": "users.forms",
        "peekOfCode": "class LoginForm(forms.Form):\n    username = forms.CharField(min_length=3, widget=forms.TextInput(attrs={\"placeholder\": \" (3 )\"}))\n    password = forms.CharField(min_length=3, widget=forms.PasswordInput(attrs={\"placeholder\": \" (4 )\"}))\nclass SignupForm(forms.Form):\n    username = forms.CharField()\n    password1 = forms.CharField(widget=forms.PasswordInput)\n    password2 = forms.CharField(widget=forms.PasswordInput)\n    profile_image = forms.ImageField(required=False, label='Profile image(optional)')\n    short_description = forms.CharField(required=False, label='Short description(optional)')\n    def clean_username(self):",
        "detail": "users.forms",
        "documentation": {}
    },
    {
        "label": "SignupForm",
        "kind": 6,
        "importPath": "users.forms",
        "description": "users.forms",
        "peekOfCode": "class SignupForm(forms.Form):\n    username = forms.CharField()\n    password1 = forms.CharField(widget=forms.PasswordInput)\n    password2 = forms.CharField(widget=forms.PasswordInput)\n    profile_image = forms.ImageField(required=False, label='Profile image(optional)')\n    short_description = forms.CharField(required=False, label='Short description(optional)')\n    def clean_username(self):\n        username = self.cleaned_data[\"username\"]\n        if User.objects.filter(username=username).exists():\n            raise ValidationError(f\"  ({username})   \")",
        "detail": "users.forms",
        "documentation": {}
    },
    {
        "label": "User",
        "kind": 6,
        "importPath": "users.models",
        "description": "users.models",
        "peekOfCode": "class User(AbstractUser):\n    profile_image = models.ImageField(\" \", upload_to=\"users/profile\", blank=True, null=True)\n    short_description = models.TextField(\"\", blank=True, null=True)",
        "detail": "users.models",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "users.urls",
        "description": "users.urls",
        "peekOfCode": "urlpatterns = [\n    path(\"login/\", login_view),\n    path(\"logout/\", logout_view),\n    path(\"signup/\", signup),\n]",
        "detail": "users.urls",
        "documentation": {}
    },
    {
        "label": "login_view",
        "kind": 2,
        "importPath": "users.views",
        "description": "users.views",
        "peekOfCode": "def login_view(request):\n    if request.user.is_authenticated:\n        return redirect(\"/\")\n    if request.method == \"POST\":\n        form = LoginForm(data=request.POST)\n        if form.is_valid():\n            username = form.cleaned_data[\"username\"]\n            password = form.cleaned_data[\"password\"]\n            user = authenticate(username=username, password=password)\n            if user:",
        "detail": "users.views",
        "documentation": {}
    },
    {
        "label": "logout_view",
        "kind": 2,
        "importPath": "users.views",
        "description": "users.views",
        "peekOfCode": "def logout_view(request):\n    logout(request)\n    return redirect(\"/\")\ndef signup(request):\n    if request.method == \"POST\":\n        form = SignupForm(data=request.POST, files=request.FILES)\n        if form.is_valid():\n            user = form.save()\n            login(request, user, backend='django.contrib.auth.backends.ModelBackend')\n            return redirect(\"/\")",
        "detail": "users.views",
        "documentation": {}
    },
    {
        "label": "signup",
        "kind": 2,
        "importPath": "users.views",
        "description": "users.views",
        "peekOfCode": "def signup(request):\n    if request.method == \"POST\":\n        form = SignupForm(data=request.POST, files=request.FILES)\n        if form.is_valid():\n            user = form.save()\n            login(request, user, backend='django.contrib.auth.backends.ModelBackend')\n            return redirect(\"/\")\n    else:  # GET   Form .\n        form = SignupForm()\n    # context  form    ",
        "detail": "users.views",
        "documentation": {}
    },
    {
        "label": "download_kprn_model",
        "kind": 2,
        "importPath": "utils.download_models",
        "description": "utils.download_models",
        "peekOfCode": "def download_kprn_model():\n    if not os.path.exists('pytorch_models/kprn/kprn.pt'):\n        s3 = boto3.client(\n            service_name=\"s3\",\n            region_name=\"ap-northeast-2\",\n            aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n            aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),\n        )\n        print(f\"Download kprn model\")\n        s3.download_file(Bucket='pseudorec-models', Key='kprn/kprn.pt', Filename='pytorch_models/kprn/kprn.pt')",
        "detail": "utils.download_models",
        "documentation": {}
    },
    {
        "label": "make_dir_n_download",
        "kind": 2,
        "importPath": "utils.download_vectordb",
        "description": "utils.download_vectordb",
        "peekOfCode": "def make_dir_n_download(s3, bucket, key, dir, filename):\n    file_dir = os.path.join(dir, filename)\n    if not os.path.exists(dir):\n        os.makedirs(dir)\n    if not os.path.exists(file_dir):\n        print(f\"download {key} -> {file_dir}...\")\n        s3.download_file(Bucket=bucket, Key=key, Filename=os.path.join(dir, filename))\n    else:\n        print(f\"file exists : {file_dir}\")\ndef download_vectordb():",
        "detail": "utils.download_vectordb",
        "documentation": {}
    },
    {
        "label": "download_vectordb",
        "kind": 2,
        "importPath": "utils.download_vectordb",
        "description": "utils.download_vectordb",
        "peekOfCode": "def download_vectordb():\n    print(f\"Download chroma.sqlite3\".ljust(60, '-'))\n    s3 = boto3.client(\n        service_name=\"s3\",\n        region_name=\"ap-northeast-2\",\n        aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n        aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),\n    )\n    if not os.path.exists('llmrec/vector_dbs/hyeonwoo'):\n        os.makedirs('llmrec/vector_dbs/hyeonwoo')",
        "detail": "utils.download_vectordb",
        "documentation": {}
    },
    {
        "label": "get_broker_url",
        "kind": 2,
        "importPath": "utils.kafka",
        "description": "utils.kafka",
        "peekOfCode": "def get_broker_url():\n    if os.getenv('IN_CONTAINER') == 'YES':\n        broker_url = os.getenv('BROKER_URL_IN_CONTAINER')\n    else:\n        broker_url = 'localhost:9092'\n    print(f\"\\tL [IN_CONTAINER? {os.getenv('IN_CONTAINER', 'NO')}] broker url : {broker_url}\")\n    return broker_url",
        "detail": "utils.kafka",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "utils.log_config",
        "description": "utils.log_config",
        "peekOfCode": "logger = logging.getLogger(__name__)",
        "detail": "utils.log_config",
        "documentation": {}
    },
    {
        "label": "get_korea_now_ts",
        "kind": 2,
        "importPath": "utils.pop_movies",
        "description": "utils.pop_movies",
        "peekOfCode": "def get_korea_now_ts():\n    #     \n    korea_tz = pytz.timezone('Asia/Seoul')\n    #   UTC \n    utc_now = datetime.utcnow()\n    # UTC   \n    korea_now = utc_now.replace(tzinfo=pytz.utc).astimezone(korea_tz)\n    #     \n    korea_timestamp = korea_now.timestamp()\n    return korea_timestamp",
        "detail": "utils.pop_movies",
        "documentation": {}
    },
    {
        "label": "save_file",
        "kind": 2,
        "importPath": "utils.pop_movies",
        "description": "utils.pop_movies",
        "peekOfCode": "def save_file(local_file_dir):\n    daum_pop_movies_last_updated = {'timestamp': get_korea_now_ts()}\n    with open(local_file_dir, 'w') as json_file:\n        json.dump(daum_pop_movies_last_updated, json_file)\ndef load_last_updated_ts(local_file_dir):\n    with open(local_file_dir, 'r') as json_file:\n        loaded_data = json.load(json_file)\n    return loaded_data['timestamp']\ndef get_pop(mysql):\n    local_file_dir = 'utils/daum_pop_movies_last_updated.json'",
        "detail": "utils.pop_movies",
        "documentation": {}
    },
    {
        "label": "load_last_updated_ts",
        "kind": 2,
        "importPath": "utils.pop_movies",
        "description": "utils.pop_movies",
        "peekOfCode": "def load_last_updated_ts(local_file_dir):\n    with open(local_file_dir, 'r') as json_file:\n        loaded_data = json.load(json_file)\n    return loaded_data['timestamp']\ndef get_pop(mysql):\n    local_file_dir = 'utils/daum_pop_movies_last_updated.json'\n    os.path.exists(local_file_dir)\n    last_updated_ts = load_last_updated_ts(local_file_dir)\n    last_updated_dt = datetime.fromtimestamp(last_updated_ts)\n    now_ts = get_korea_now_ts()",
        "detail": "utils.pop_movies",
        "documentation": {}
    },
    {
        "label": "get_pop",
        "kind": 2,
        "importPath": "utils.pop_movies",
        "description": "utils.pop_movies",
        "peekOfCode": "def get_pop(mysql):\n    local_file_dir = 'utils/daum_pop_movies_last_updated.json'\n    os.path.exists(local_file_dir)\n    last_updated_ts = load_last_updated_ts(local_file_dir)\n    last_updated_dt = datetime.fromtimestamp(last_updated_ts)\n    now_ts = get_korea_now_ts()\n    now_dt = datetime.fromtimestamp(now_ts)\n    time_difference = now_dt - last_updated_dt\n    print(f\"[pop movies] now : {now_dt}, last updated at : {last_updated_dt} \")\n    # if time_difference > timedelta(hours=24):",
        "detail": "utils.pop_movies",
        "documentation": {}
    },
    {
        "label": "MysqlClient",
        "kind": 6,
        "importPath": "clients",
        "description": "clients",
        "peekOfCode": "class MysqlClient:\n    def __init__(self):\n        self.endpoint = \"pseudorec.cvhv2t0obyv3.ap-northeast-2.rds.amazonaws.com\"\n        self.port = 3306\n        self.user = \"admin\"\n        self.region = \"ap-northeast-2c\"\n        self.dbname = \"movielens25m\"\n        self.passwd = os.getenv('RDS_MYSQL_PW')\n        os.environ['LIBMYSQL_ENABLE_CLEARTEXT_PLUGIN'] = '1'\n        # self.connection = pymysql.connect(host=endpoint, user=user, passwd=passwd, port=port, database=dbname)",
        "detail": "clients",
        "documentation": {}
    },
    {
        "label": "process_messages",
        "kind": 2,
        "importPath": "consumer",
        "description": "consumer",
        "peekOfCode": "def process_messages():\n    for message in consumer:\n        log_data = message.value\n        print(f\"message.value : {message.value}\")\n        # DynamoDB  \n        try:\n            response = table_clicklog.put_item(click_log=log_data)\n            print('Successfully saving data')\n            #      \n        except Exception as e:",
        "detail": "consumer",
        "documentation": {}
    },
    {
        "label": "consumer",
        "kind": 5,
        "importPath": "consumer",
        "description": "consumer",
        "peekOfCode": "consumer = KafkaConsumer(\n    'log_movie_click',\n    bootstrap_servers=[os.getenv('BROKER_URL_IN_CONTAINER', 'localhost:9092')],\n    auto_offset_reset='earliest',\n    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n)\ntable_clicklog = DynamoDBClient(table_name='clicklog')\n# Kafka Consumer   \ndef process_messages():\n    for message in consumer:",
        "detail": "consumer",
        "documentation": {}
    },
    {
        "label": "table_clicklog",
        "kind": 5,
        "importPath": "consumer",
        "description": "consumer",
        "peekOfCode": "table_clicklog = DynamoDBClient(table_name='clicklog')\n# Kafka Consumer   \ndef process_messages():\n    for message in consumer:\n        log_data = message.value\n        print(f\"message.value : {message.value}\")\n        # DynamoDB  \n        try:\n            response = table_clicklog.put_item(click_log=log_data)\n            print('Successfully saving data')",
        "detail": "consumer",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "manage",
        "description": "manage",
        "peekOfCode": "def main():\n    \"\"\"Run administrative tasks.\"\"\"\n    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')\n    # wait_for_kafka_broker('[Broker waiting in manage.py]')\n    download_kprn_model()\n    download_vectordb()\n    try:\n        from django.core.management import execute_from_command_line\n    except ImportError as exc:\n        raise ImportError(",
        "detail": "manage",
        "documentation": {}
    },
    {
        "label": "wait_for_kafka_broker",
        "kind": 2,
        "importPath": "producer",
        "description": "producer",
        "peekOfCode": "def wait_for_kafka_broker(comment='wait_for_kafka_broker'):\n    print(f\"{comment}\")\n    max_retries = 10\n    retries = 0\n    while retries < max_retries:\n        try:\n            broker_url = get_broker_url()\n            producer = KafkaProducer(\n                bootstrap_servers=[broker_url]\n            )",
        "detail": "producer",
        "documentation": {}
    }
]