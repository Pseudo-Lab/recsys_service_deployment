import json
import re
from llm_response.langgraph_graph_state import GraphState
from prompt.final_selecting_for_recomm import FINAL_SELECTING_FOR_RECOMM_v2
from pprint import pprint


def final_selecting_for_recomm(llm, state: GraphState):
    print("Selecting for recomm".ljust(100, '='))
    print(f"state['query'] : {state['query']}")
    print()
    print(f"state['rewritten_query'] : {state['rewritten_query']}")
    print()
    print(f"state['candidate_str'] : {state['candidate_str']}")
    print()
    
    prompt = FINAL_SELECTING_FOR_RECOMM_v2.format(
        query=state['query'],
        intent=state['rewritten_query'],
        candidates=state['candidate_str']
    )
    print(f"prompt : {prompt}")

    response = llm.invoke(prompt)

    raw = response.content.strip()

    # ì½”ë“œ ë¸”ë¡/ì£¼ì„ ì œê±°
    cleaned = (
        raw.replace("```", "")
            .replace("json", "")
            .strip()
    )
    print(f"cleaned : {cleaned}")

    cleaned_json_like = re.sub(r"'", '"', cleaned)
    print(f"cleaned_json_like : {cleaned_json_like}")
    try:
        state["selected_recommendations"] = eval(cleaned_json_like)
    except json.JSONDecodeError as e:
        print("âš ï¸ JSON ë””ì½”ë”© ì‹¤íŒ¨!")
        print("ğŸ”¹ ì›ë³¸ ì‘ë‹µ:\n", raw)
        raise ValueError(f"LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    return state
