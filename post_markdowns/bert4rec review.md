## Abstract

ì¶”ì²œ ì‹œìŠ¤í…œì—ì„œ ë‹¨ë°©í–¥ ëª¨ë¸ì€ ê³¼ê±°ì˜ ì •ë³´ë§Œì„ ì‚¬ìš©í•´ ì˜ˆì¸¡ì„ ì§„í–‰í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‚¬ìš©ìì˜ í–‰ë™ì€ í…ìŠ¤íŠ¸ë‚˜ ì‹œê³„ì—´ ë°ì´í„°ì²˜ëŸ¼ ì—„ê²©í•œ ìˆœì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì‚¬ìš©ìì˜ í–‰ë™ ìˆœì„œë¥¼ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ ì–‘ë°©í–¥ context ì •ë³´ë¥¼ ê³ ë ¤í•˜ëŠ” **BERT4Rec**ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë•Œ, í•™ìŠµ ì‹œ ë°œìƒí•˜ëŠ” ì •ë³´ì˜ ìœ ì¶œì„ ì¤„ì´ê³  í•™ìŠµì˜ íš¨ìœ¨ì„±ì„ ìœ„í•´ **Cloze** ë¼ëŠ” random masking ê¸°ë²•ì„ í™œìš©í•©ë‹ˆë‹¤.

## 1. INTRODUCTION

<div class="custom-class">
<p>
ğŸ’¡ In many real-world applications, usersâ€™ current interests are intrinsically <strong>dynamic</strong> and <strong>evolving</strong>, influenced by their <strong>historical behaviors</strong>.
</p>
<p>
ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ëŠ” ê³¼ê±° í–‰ë™ì— ì˜í–¥ì„ ë°›ì•„ ë™ì ìœ¼ë¡œ ë³€í•©ë‹ˆë‹¤.
</p>
<p>
<strong>ex.</strong> ì•„ì´í°ì„ êµ¬ë§¤í•œ ì‚¬ìš©ìëŠ” ë‹¤ìŒì— ì•„ì´í° ì¶©ì „ê¸°ë¥¼ êµ¬ë§¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°¤ëŸ­ì‹œ ì¶©ì „ê¸°ë¥¼ êµ¬ë§¤í•˜ì§„ ì•Šì„ ê²ƒì…ë‹ˆë‹¤.
</p>
</div>


<div class="custom-class">
<p>
- ğŸ’¡ To model such sequential dynamics in user behaviors, various methods have been proposed to make ***sequential recommendations*** based on usersâ€™ **historical interactions**. They aim to predict the successive item(s) that a user is likely to interact with given her/his past interactions.
</p>
<p>
ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì— ì„ íƒí•  ì•„ì´í…œì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ Sequential recommendationì´ë¼ê³  í•©ë‹ˆë‹¤.
</p>
</div>

<div class="custom-class">
<p>
ğŸ’¡ The basic paradigm of previous work is to encode a userâ€™s historical interactions into a vector using a **left-to-right sequential model** and make recommendations based on this hidden representation.
</p>
<p>
ê¸°ì¡´ ì ‘ê·¼ë²•ë“¤ì€ ì´ë¥¼ ìœ„í•´ ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš©ë§Œì„ hidden representaionìœ¼ë¡œ ìƒì„±í•˜ì—¬ ì¶”ì²œì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.
</p>
<p>
ex. Recurrent Neural Network (RNN)
</p>
<p>
ì´ëŸ¬í•œ ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ì€ í•œê³„ê°€ ì¡´ì¬í•©ë‹ˆë‹¤ :
</p>
<p>
- ì•„ì´í…œì— ëŒ€í•œ hidden representationì´ ê³¼ê±°ì˜ ì •ë³´ë§Œì„ ê³ ë ¤
</p>
<p>
- ê¸°ì¡´ì— ì‚¬ìš©í•œ ëª¨ë¸ë“¤ì€ ì—„ê²©í•œ ìˆœì„œê°€ ìˆë‹¤ê³  ì—¬ê²¨ì§€ëŠ” ë°ì´í„°ë¥¼ ìœ„í•´ ê³ ì•ˆëœ ëª¨ë¸
</p>
<p>
â‡’ ë°˜ë©´, ì‚¬ìš©ìì˜ í–‰ë™ì˜ ìˆœì„œëŠ” ë’¤ë°”ë€” ìˆ˜ ìˆìŒ
</p>
</div>


<div class="custom-class">
<p>
ğŸ’¡ To address the limitations mentioned above, we seek to use a bidirectional model to learn the representations for usersâ€™ historical behavior sequences. Specifically, inspired by the success of **BERT** in text understanding, we propose to apply the deep bidirectional self-attention model to sequential recommendation.
</p>
<p>
ìœ„ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” sequential recommendationì— **BERT** ëª¨ë¸ì„ í™œìš©í•˜ëŠ” ê²ƒì„ ì œì•ˆí•©ë‹ˆë‹¤.
</p>
<p>
â‡’ ê³¼ê±°ì™€ ë¯¸ë˜ ì •ë³´ë¡œë¶€í„° ì–»ëŠ” contextë¥¼ ëª¨ë‘ í™œìš©í•  ìˆ˜ ìˆìŒ
</p>
</div>


<div class="custom-class">
<p>
ğŸ’¡ Jointly conditioning on both left and right context in BERT cause information leakage. To tackle this problem, we introduce the ***Cloze*** task to take the place of the objective in unidirectional models.
</p>
<p>
ê³¼ê±°ì™€ ë¯¸ë˜ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµí•˜ê²Œ ë˜ë©´ ê°„ì ‘ì ìœ¼ë¡œ ì˜ˆì¸¡ ì•„ì´í…œì„ ë³´ê²Œ ë©ë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **Cloze** ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤.
</p>
<p>
**Cloze**
</p>
<p>
ëœë¤í•˜ê²Œ ì•„ì´í…œì„ [mask] í† í°ìœ¼ë¡œ ìˆ¨ê¸°ê³ , contextë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ë‹¹ itemì˜ idë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•™ìŠµ ë°©ë²•
</p>
<p>
â‡’ í•™ìŠµ ë°ì´í„°ê°€ ëŠ˜ì–´ë‚˜ëŠ” íš¨ê³¼
</p>
</div>


<div class="custom-class">
<p>
ğŸ’¡ However, a downside of the Cloze task is that it is not consistent with the final task. To fix this, during the test, we a**ppend the special token â€œ[mask]â€ at the end of the input sequence** to indicate the item that we need to predict, and then make recommendations base on its final hidden vector.
</p>
<p>
ê·¸ëŸ¬ë‚˜ Cloze ë°©ë²•ë¡ ì€ sequential ì¶”ì²œì˜ ìµœì¢… ëª©í‘œì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œëŠ” [mask] í† í°ì„ ì…ë ¥ì˜ ë§ˆì§€ë§‰ì— ì¶”ê°€í•˜ì—¬ ë‹¤ìŒì— ë‚˜íƒ€ë‚  ì•„ì´í…œì„ ì˜ˆì¸¡í•˜ë„ë¡ í•©ë‹ˆë‹¤.
</p>
</div>


**Contributions:**

- ì‚¬ìš©ìì˜ í–‰ë™ sequenceë¥¼ Cloze taskë¥¼ ê¸°ë°˜ìœ¼ë¡œ bidirectional self-attentionì„ í™œìš©í•˜ì—¬ ì¸ì½”ë”©
- 4ê°œì˜ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•´ SOTA ëª¨ë¸ë“¤ê³¼ BERT4Rec ì„±ëŠ¥ ë¹„êµ
- BERT4Recì˜ í•µì‹¬ ìš”ì†Œë“¤ì´ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„

# 2. RELATED WORK

## 2.1. General Recommendation

- **Collaborative Filtering (CF)**
ì‚¬ìš©ìì˜ ****ê³¼ê±° ìƒí˜¸ì‘ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ ì œê³µ
    - **Matrix Factorization (MF)**
    CFì˜ ì¼ì¢…ìœ¼ë¡œ, userì™€ itemì„ ê³µí†µëœ vecotr spaceë¡œ projectí•˜ê³  inner productë¥¼ í†µí•´ ì„ í˜¸ë„ ê³„ì‚°  ****
- **Item-based neighborhood**
ê³¼ê±° ìƒí˜¸ì‘ìš©í•œ ì•„ì´í…œ ê°„ì˜ similarity matrixì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œ ì œê³µ
- **Deep learning based recommendation**
    - ì¶”ê°€ì ì¸ ì •ë³´(text, images, acoustic features)ë¥¼ CF ëª¨ë¸ì— í†µí•©
    - Matrix Factorization ëŒ€ì²´
        - **Neural Collaborative Filtering (NCF)**
        MFì—ì„œ inner product ëŒ€ì‹  multi-layer perceptron (MLP)ë¡œ ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì •
        - **AutoRec, CDAE**
        Auto-encoder í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì •

## 2.2. Sequential Recommendation

ìƒí˜¸ì‘ìš©ì˜ ìˆœì„œë¥¼ ê³ ë ¤í•˜ëŠ” ì¶”ì²œ

- Markov Chains (MCs)
ê³¼ê±° ìƒí˜¸ì‘ìš©ìœ¼ë¡œë¶€í„° sequential patternsì„ í¬ì°©í•˜ì—¬ ì¶”ì²œ ì œê³µ
    - **Markov Decision Processes (MDPs)**
    - **Factorizing Personalized Markov Chains (FPMC)**
    MCsì™€ MFë¥¼ ê²°í•©í•˜ì—¬ ìƒí˜¸ì‘ìš©ì˜ ìˆœì„œì™€ ì¼ë°˜ì ì¸ ì„ í˜¸ë„ë¥¼ ê³ ë ¤
- **Deep Learning models**
    - **Recurrent Neural Networks (RNN)**
        - Gated Recurrent Unit (GRU)
            - session-based GRU with ranking loss (GRU4Rec)
            - user-based GRU
            - attention-based GRU (NARM)
            - improved GRU4Rec with new loss function (BPR-max, TOP1-max)
        - Long Short-Term Memory
    - **Convolutional Sequence Model (Caser)**
    convolution í•„í„°ë¥¼ í™œìš©í•˜ì—¬ ìƒí˜¸ì‘ìš©ì˜ ìˆœì„œì— ì¡´ì¬í•˜ëŠ” íŒ¨í„´ í•™ìŠµ
    - **Memory Netork**
    - **STAMP**
    MLPì™€ attentionì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì¼ë°˜ì ì¸ ê´€ì‹¬ì‚¬ì™€ í˜„ì¬ ê´€ì‹¬ì‚¬ë¥¼ í¬ì°©

## 2.3. Attention Mechanism

- **attention mechanism into GRU**
- **purely attention-based neural networks**
    - **SASREC**
    2ê°œì˜ Transformer decoder layerë¥¼ ì‚¬ìš©
    : attention maskë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ì „íˆ unidirectional model
    â‡’ BERT4Recì€ bi-directional modelë¡œ Cloze taskë¥¼ í™œìš©í•´ ì‚¬ìš©ìì˜ í–‰ë™ì„ encoding

# 3. BERT4REC

## 3.1 Problem Statement

$$
 U = [u1,u2, . . . ,u_{|U|} ]
$$

$$
V=[v1,v2, . . . ,v_{|V|}]
$$

$$
Su=[v^{(u)}\_1, . . . ,v^{(u)}\_t, . . . ,v^{(u)}\_{n\_u}]
$$

- ì‹œê³„ì—´ ì¶”ì²œì€ ìœ ì €(u) ê°€ t + 1ì—ì„œ ìƒí˜¸ì‘ìš©í•  ì•„ì´í…œì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒ

## 3.2 Model Architecture

- **B**idirectional **E**ncoder Representations from **T**ransformers to a new task, sequential **R**ecommendation
    
    ![Untitled](../../../static/img/paper_review/bert4rec_review/model_architecture.png)
    

## 3.3 Transformer Layer

![Untitled](../../../static/img/paper_review/bert4rec_review/transformer_layer.png)

- Multi-Head Self-Attention
    
    $$
    Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{d/h}})
    $$
    
    ![Untitled](../../../static/img/paper_review/bert4rec_review/mh_attention1.png)
    
    ![Untitled](../../../static/img/paper_review/bert4rec_review/mh_attention2.png)
    
    ![Untitled](../../../static/img/paper_review/bert4rec_review/mh_attention3.png)
    
    ![Untitled](../../../static/img/paper_review/bert4rec_review/mh_attention4.png)
    
```python
  
        class Attention(nn.Module):
            def forward(self, query, key, value, mask=None, dropout=None):
                scores = torch.matmul(query, key.tranpose(-2, 1)) / math.sqrt(query.size(-1))
    
                if mask is not None:
                    scores = scores.masked_fill(mask == 0, -1e9)
            
                p_attn = F.softmax(scores, dim=-1)
            
                if dropout is not None:
                    p_attn = dropout(p_attn)
            
                return torch.matmul(p_attn, value), p_attn
```
    
```python
class MultiHeadAttention(nn.Module):
    """
    ëª¨ë¸ í¬ê¸°ì™€ í—¤ë“œì˜ ìˆ˜ë¥¼ ì…ë ¥ì„ ë°›ìŒ
    """
    def __init__(self, num_heads, d_model, dropout=0.1):
        super().__init__()
        assert d_model % num_heads == 0
        
        self.d_k = d_model // num_heads
        self.num_heads = num_heads
        
        self.q_linear = nn.Linear(d_model, d_model)
        self.k_linear = nn.Linear(d_model, d_model)
        self.v_linear = nn.Linear(d_model, d_model)
        
        self.output_linear = nn.Linear(d_model, d_model)
        self.attention = Attention()
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, query, key, value, mask=None):
        batch_size = query.size(0)
        q = self.q_linear(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        k = self.k_linear(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        v = self.v_linear(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        
        # ì–´í…ì…˜ ì ìš©
        x, attn = self.attention(q, k, v, mask=mask, dropout=self.dropout)
        
        # concat í›„ output lienear ì ìš©
        output = x.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)
        output = self.output_linear(output)
        
        return output
```
    

- Position-wise Feed-Forward Network
    - ê° í—¤ë“œì˜ ì •ë³´ë¥¼ ì„ì–´ì£¼ëŠ” ì—­í™œ
    
```python
    class PositionwiseFeedForward(nn.Module):
        def __init__(self, d_model, d_ff, dropout=0.1):
            super().__init__()
            self.w_1 = nn.Linear(d_model, d_ff)
            self.w_2 = nn.Linear(d_ff, d_model)
            self.dropout = nn.Dropout(dropout)
            self.activation = nn.GELU()
            
        def forward(self, x):
            output = self.w_1(x)
            output = self.activation(output)
            output = self.dropout(output)
            output = self.w_2(output)
            
            return output
```
    
- Stacking Transformer Layer
    
    ![Untitled](../../../static/img/paper_review/bert4rec_review/stacking_transformer_layer.png)
    

## 3.4 Embedding Layer

```
we use the learnable positional embeddings instead of the fixed sinusoid embedding
```

```python
    class PositionalEmbedding(nn.Module):
        def __init__(self, max_len, d_model) -> None:
            super().__init__()
            
            # í•™ìŠµì´ ê°€ëŠ¥í•œ í˜•íƒœì˜ positional embedding
            self.pe = nn.Embedding(max_len, d_model)
    
                    """
                    pos_encoding = torch.zeros(position, d_model).to(device)
    
            pos = torch.arange(0, position).float().unsqueeze(1)
            _2i = torch.arange(0, d_model, 2).float()
    
            pos_encoding[:, 0::2] = torch.sin(pos / 10000 ** (_2i / d_model))
            pos_encoding[:, 1::2] = torch.cos(pos / 10000 ** (_2i / d_model))
            self.pos_encoding = pos_encoding.unsqueeze(0)
            self.pos_encoding.requires_grad = False
                    """
        
        def forward(self, x):
            batch_size = x.size(0)
            
            return self.pe.weight.unsqueeze(0).repeat(batch_size, 1, 1)
```

```python
class TokenEmbedding(nn.Embedding):
    def __init__(self, vocab_size, embedding_size=512):
        super().__init__(vocab_size, embedding_size, padding_idx=0)
```

```python
class BERTembedding(nn.Module):
    def __init__(self, vocab_size, embedding_size, max_len, dropout=0.1):
        super().__init__()
        
        self.token = TokenEmbedding(vocab_size, embedding_size)
        self.position = PositionalEmbedding(max_len, embedding_size)
        self.dropout = nn.Dropout(dropout)
        self.embedding_size = embedding_size
        
    def forward(self, sequence):
        output = self.token(sequence) + self.position(sequence) 
        output = self.dropout(output)
        
        return output
```

## 3.5 Output

$$
P(u) = softmax(GELU(h^L_tW^P+b^p)E^T + b^O)
$$

```python
class BERT4Rec(nn.Module):
    def __init__(self, max_len, num_items, n_layers, num_heads, hidden, dropout):
        super().__init__()
        vocab_size = num_items + 1
        self.hidden = hidden
        self.embedding = BERTembedding(vocab_size, hidden, max_len, dropout)
        
        self.encoder_blocks = nn.ModuleList([
            EncoderBlock(hidden, num_heads, hidden * 4, dropout) for _ in range(n_layers)
        ])
        
        self.out = nn.Linear(hidden, num_items + 1)
        
    def forward(self, x):
        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)
        x = self.embedding(x)
        for encoder in self.encoder_blocks:
            x = encoder.forward(x, mask)
        output = self.out(x)
        
        return output
```

## 3.6 Model Learning

- **Cloze í•™ìŠµ ë°©ë²•**
    
    ![Untitled](../../../static/img/paper_review/bert4rec_review/cloze.png)
    
```python
    class BertTrainDataset(Dataset):
        def __init__(self, u2seq, max_len, mask_prob, mask_token, num_items, rng):
            self.u2seq = u2seq
            self.users = sorted(self.u2seq.keys())
            self.max_len = max_len
            self.mask_prob = mask_prob
            self.mask_token = mask_token
            self.num_items = num_items
            self.rng = rng
    
        def __len__(self):
            return len(self.users)
    
        def __getitem__(self, index):
            user = self.users[index]
            seq = self._getseq(user)
    
            tokens = []
            labels = []
            for s in seq:
                prob = self.rng.random()
                if prob < self.mask_prob:
                    prob /= self.mask_prob
    
                    if prob < 0.8:
                        tokens.append(self.mask_token)
                    elif prob < 0.9:
                        tokens.append(self.rng.randint(1, self.num_items))
                    else:
                        tokens.append(s)
    
                    labels.append(s)
                else:
                    tokens.append(s)
                    labels.append(0)
    
            tokens = tokens[-self.max_len:]
            labels = labels[-self.max_len:]
    
            mask_len = self.max_len - len(tokens)
    
            tokens = [0] * mask_len + tokens
            labels = [0] * mask_len + labels
    
            return torch.LongTensor(tokens), torch.LongTensor(labels)
    
        def _getseq(self, user):
            return self.u2seq[user]z
```
    

## 3.7 Discussion

- SASRec
    - ì‹œí€€ìŠ¤ì˜ ê° ìœ„ì¹˜ì— ëŒ€í•œ ë‹¤ìŒ ì•„ì´í…œì„ ì˜ˆì¸¡
    - BERT4Recì€ Cloze ëª©í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œí€€ìŠ¤ì˜ ë§ˆìŠ¤í‚¹ëœ ì•„ì´í…œì„ ì˜ˆì¸¡
- CBOW & SG
    - CBOW : ì»¨í…ìŠ¤íŠ¸ì˜ ëª¨ë“  ë‹¨ì–´ ë²¡í„°ì˜ í‰ê· ì„ ì‚¬ìš©í•˜ì—¬ ëª©í‘œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡
    - SG : í•˜ë‚˜ë¥¼ ì œì™¸í•œ ëª¨ë“  ì•„ì´í…œì„ ë§ˆìŠ¤í‚¹
- BERT
    - ëŒ€ìš©ëŸ‰ ë§ë­‰ì¹˜ë¥¼ ì´ìš©í•œ ë¬¸ì¥ í‘œí˜„ ëª¨ë¸
    - BERT4Rec : ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì œê±°

# 4. EXPERIMENTS

![Untitled](../../../static/img/paper_review/bert4rec_review/experiments1.png)

![Untitled](../../../static/img/paper_review/bert4rec_review/experiments2.png)