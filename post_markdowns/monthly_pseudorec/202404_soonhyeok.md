ğŸ“„ paper :  <a href="https://arxiv.org/pdf/1905.08108.pdf" target="_blank" style="text-decoration: underline;">**Neural Graph Collaborative Filtering â†—**</a>


# Model

## NGCF í”„ë ˆì„ì›Œí¬

![Untitled](../../../static/img/monthly_pseudorec_202404/ngcf_framework.png)

Figure 1ì˜ ì¢Œì¸¡ì€ userì™€ itemê°„ì˜ interaction graph, ìš°ì¸¡ì€ High-order Connectivityë¥¼ ë‚˜íƒ€ëƒ„.

User-Item Interaction Graph : $u_1$ â†’ {$i_1$, $i_2$, $i_3$}, $u_2$ â†’ {$i_2$, $i_4$, $i_5$}

High-order Connectivity : $u_1$ â†’ $i_2$ â†’ $u_2$ â†’ {$i_4$, $i_5$}, $u_1$ â†’ $i_3$ â†’ $u_3$ â†’ {$i_4$}

$u_1$ì´ $i_5$ë³´ë‹¤ $i_4$ì— ë” í° ê´€ì‹¬ì„ ê°€ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ìŒ.

![Untitled](../../../static/img/monthly_pseudorec_202404/ngcf_architecture.png)

ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ í†µí•´ CF signalì„ ìº¡ì³í•˜ê¸° ìœ„í•´ì„œ GNNì˜ message-passing architecture ë¥¼ êµ¬ì¶•í•´ì„œ user, item ì„ë² ë”©ì„ refine í•¨.

refineëœ userì™€ itemì˜ ì„ë² ë”© ê°’ì„ ë‚´ì í•˜ì—¬ ìµœì¢… ê°’ ë„ì¶œ.

<br>

**ìµœì¢… PseudoRec TASK)**

ìœ ì €ì™€ ìƒí˜¸ì‘ìš©ì´ ì¡´ì¬í•˜ëŠ” ì˜í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ìœ ì €ì—ê²Œ ì˜í™” ì¶”ì²œ.

---

# Training & Predict

## ngcf_predictor.py

<br>

```python
import pandas as pd
import torch
import numpy as np

import dgl
import dgl.function as fn
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from collections import OrderedDict
import pytorch_models.ngcf.model
from pytorch_models.ngcf.model import NGCF
from pytorch_models.ngcf.utility.parser import parse_args

import pytorch_models.ngcf.utility.metrics as metrics
from pytorch_models.ngcf.utility.load_data import *
from pytorch_models.ngcf.utility.batch_test import *

import pytorch_models.Data.daum.train_test_split as ts

class NgcfPredictor:
    def __init__(self):
        self.args = parse_args()
        self.device = 'cpu'
        self.num_recommendations = 10
        self.num_epochs = 10

    def sample(self, users, items):

        def sample_pos_items_for_u(u, num):
            # sample num pos items for u-th user
            pos_items = items
            n_pos_items = len(pos_items)
            pos_batch = []
            while True:
                if len(pos_batch) == num:
                    break
                pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0]
                pos_i_id = pos_items[pos_id]

                if pos_i_id not in pos_batch:
                    pos_batch.append(pos_i_id)
            return pos_batch

        def sample_neg_items_for_u(u, num):
            # sample num neg items for u-th user
            neg_items = []
            while True:
                if len(neg_items) == num:
                    break
                neg_id = np.random.randint(low=0, high=3706, size=1)[0]
                if (
                        neg_id not in items
                        and neg_id not in neg_items
                ):
                    neg_items.append(neg_id)
            return neg_items

        pos_items, neg_items = [], []
        for u in users:
            pos_items += sample_pos_items_for_u(u, 1)
            neg_items += sample_neg_items_for_u(u, 1)

        return users, pos_items, neg_items

    def predict(self, interacted_items):
        """ # íšŒì›ê°€ì…í•œ ì‚¬ìš©ì ë²„ì „(ìƒˆë¡œ íšŒì›ê°€ì…ì„ í•œ ê²½ìš°ì—ëŠ” ìœ ì € ì„ë² ë”©ì´ ì¶”ê°€ë˜ê¸° ë•Œë¬¸ì— ì´ì „ì— ë°°ì¹˜ or ì˜¨ë¼ì¸ í•™ìŠµëœ ëª¨ë¸ì„ checkpointë¼ëŠ” ë³€ìˆ˜ë¡œ ë¶ˆëŸ¬ì™€ì„œ ìœ ì €ì˜ ìˆ˜ë¥¼ new_num_user ë³€ìˆ˜ì— ìƒì„±) -> ì•„ì§ ê³ ë¯¼í•´ë´ì•¼í•¨..
        checkpoint = torch.load('NGCF.pkl')
        checkpoint_dict = dict(OrderedDict(checkpoint))
        new_num_user = len(checkpoint_dict['feature_dict.user'])
        
        user_id = new_num_user + 1
        print(user_id)
        """
        print(f"interacted_items : {interacted_items}")
        # ë¹„íšŒì› ë°ì´í„° ì ì¬ X
        user_id = 10538
        print(user_id)

        data_generator.train_items[user_id - 1] = interacted_items

        new_user_item_dst = interacted_items
        new_user_item_src = [user_id - 1] * len(new_user_item_dst)
        user_selfs = list(range(user_id))
        item_selfs = list(range(25139))
        data_dict = {
            ("user", "user_self", "user"): (user_selfs, user_selfs),
            ("item", "item_self", "item"): (item_selfs, item_selfs),
            ("user", "ui", "item"): (
            data_generator.user_item_src + new_user_item_src, data_generator.user_item_dst + new_user_item_dst),
            ("item", "iu", "user"): (
            data_generator.user_item_dst + new_user_item_dst, data_generator.user_item_src + new_user_item_src),
        }
        num_dict = {"user": user_id, "item": 25139}

        data_generator.g = dgl.heterograph(data_dict, num_nodes_dict=num_dict)

        model = NGCF(
            data_generator.g, 64, [64, 64, 64], [0.1, 0.1, 0.1], 1e-5).to(self.device)
        optimizer = optim.Adam(model.parameters(), lr=self.args.lr)

        for epoch in range(self.num_epochs):
            loss, mf_loss, emb_loss = 0.0, 0.0, 0.0
            users, pos_items, neg_items = self.sample(new_user_item_src, new_user_item_dst)
            u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings = model(
                data_generator.g, "user", "item", users, pos_items, neg_items
            )
            batch_loss, batch_mf_loss, batch_emb_loss = model.create_bpr_loss(
                u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings
            )
            optimizer.zero_grad()
            batch_loss.backward()
            optimizer.step()

            loss += batch_loss

        # torch.save(model.state_dict(),self.args.model_name)

        model.eval()
        rec_items = {}

        # all-item test
        item = torch.tensor(list(set(item_selfs) - set(new_user_item_dst))).to(self.device)
        u_g_embeddings, pos_i_g_embeddings, _ = model(
            data_generator.g, "user", "item", user_id - 1, item, []
        )
        rate_batch = (
            model.rating(u_g_embeddings, pos_i_g_embeddings).detach().cpu()
        )
        _, top_indices = torch.topk(rate_batch.view(-1), self.num_recommendations)
        recommended_items = item[top_indices]

        rec = []

        for i in recommended_items:
            rec.append(i)

        rec_list = [item.item() for item in rec]

        recomm_result = []

        for i in rec_list:
            recomm_result.append(ts.item_decoder[i])

        print(f"ngcf recomm_result : {recomm_result}")
        return recomm_result

ngcf_predictor = NgcfPredictor()

```

### CODE ì„¤ëª…

**ìƒˆë¡œìš´ userì˜ interaction ì •ë³´ ì¶”ê°€**

```python
def predict(self, interacted_items):
        new_user_item_dst = interacted_items
        new_user_item_src = [user_id - 1] * len(new_user_item_dst)
        user_selfs = list(range(user_id))
        item_selfs = list(range(25139))
        data_dict = {
            ("user", "user_self", "user"): (user_selfs, user_selfs),
            ("item", "item_self", "item"): (item_selfs, item_selfs),
            ("user", "ui", "item"): (
            data_generator.user_item_src + new_user_item_src, data_generator.user_item_dst + new_user_item_dst),
            ("item", "iu", "user"): (
            data_generator.user_item_dst + new_user_item_dst, data_generator.user_item_src + new_user_item_src),
        }
```

- ê¸°ì¡´ í•™ìŠµëœ modelì— ì €ì¥ëœ userì™€ movieì˜ bipartite ê·¸ë˜í”„ ì •ë³´ì—(data_generator.user_item_src, data_generator.user_item_dst) ìƒˆë¡œìš´ userì™€ movieì˜ interaction ì •ë³´ë¥¼(new_user_item_dst, new_user_item_src) ì¶”ê°€

**Re-training**

```python
def predict(self, interacted_items):
        for epoch in range(self.num_epochs):
            loss, mf_loss, emb_loss = 0.0, 0.0, 0.0
            users, pos_items, neg_items = self.sample(new_user_item_src, new_user_item_dst)
            u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings = model(
                data_generator.g, "user", "item", users, pos_items, neg_items
            )
            batch_loss, batch_mf_loss, batch_emb_loss = model.create_bpr_loss(
                u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings
            )
            optimizer.zero_grad()
            batch_loss.backward()
            optimizer.step()

            loss += batch_loss
```

- 10ë²ˆì˜ epochìœ¼ë¡œ ì¬í•™ìŠµ ì§„í–‰. â†’ negative sampling ìœ¼ë¡œ BPR LOSS ì†ì‹¤í•¨ìˆ˜ ì‚¬ìš©!

### Inference

```python
def predict(self, interacted_items):
        model.eval()
        rec_items = {}

        # all-item test
        item = torch.tensor(list(set(item_selfs) - set(new_user_item_dst))).to(self.device)
        u_g_embeddings, pos_i_g_embeddings, _ = model(
            data_generator.g, "user", "item", user_id - 1, item, []
        )
        rate_batch = (
            model.rating(u_g_embeddings, pos_i_g_embeddings).detach().cpu()
        )
        _, top_indices = torch.topk(rate_batch.view(-1), self.num_recommendations)
        recommended_items = item[top_indices]

        rec = []

        for i in recommended_items:
            rec.append(i)

        rec_list = [item.item() for item in rec]

        recomm_result = []

        for i in rec_list:
            recomm_result.append(ts.item_decoder[i])

        print(f"ngcf recomm_result : {recomm_result}")
        return recomm_result
```

ê·¸ë ‡ê²Œ ì¬í•™ìŠµëœ ëª¨ë¸ì„ model.eval() ì¶”ë¡ ëª¨ë“œë¡œ ë³€ê²½í•˜ì—¬ ìƒˆë¡œìš´ userê°€ ìƒí˜¸ì‘ìš©í•œ movieë¥¼ ì œì™¸í•œ ëª¨ë“  movieì— ëŒ€í•´ ì ìˆ˜ë¥¼ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì˜í™” top k ë¥¼ ì¶”ì²œí•´ì¤Œ.

---

# MLOps

### views.py

```python
import json
import os
import time

import pandas as pd
from django.http import JsonResponse, HttpResponse
from django.shortcuts import render
from django.views.decorators.csrf import csrf_exempt
from dotenv import load_dotenv
from kafka import KafkaConsumer, KafkaProducer

from clients import MysqlClient
from db_clients.dynamodb import DynamoDBClient
from movie.models import DaumMovies
from movie.predictors.sasrec_predictor import sasrec_predictor
# from movie.predictors.ngcf_predictor import ngcf_predictor
from movie.predictors.kprn_predictor import kprn_predictor
from movie.utils import add_past_rating, add_rank, get_username_sid, get_user_logs_df, get_interacted_movie_obs
from utils.kafka import get_broker_url
from utils.pop_movies import get_pop

load_dotenv('.env.dev')

broker_url = get_broker_url()
producer = KafkaProducer(bootstrap_servers=[broker_url],
                         value_serializer=lambda v: json.dumps(v).encode('utf-8'))

mysql = MysqlClient()
pop_movies_ids = get_pop(mysql)
pop_movies = list(DaumMovies.objects.filter(movieid__in=pop_movies_ids).values())
pop_movies = sorted(pop_movies, key=lambda x: pop_movies_ids.index(x['movieid']))

table_clicklog = DynamoDBClient(table_name='clicklog')

def ngcf(request):
    print(f"movie/ngcf view".ljust(100, '>'))
    username, session_id = get_username_sid(request, _from='movie/ngcf')
    user_logs_df = get_user_logs_df(username, session_id)
    
    if not user_logs_df.empty:  # í´ë¦­ë¡œê·¸ ìˆì„ ë•Œ
        interacted_movie_ids = [int(mid) for mid in user_logs_df['movieId'] if mid is not None and not pd.isna(mid)]
        interacted_movie_obs = get_interacted_movie_obs(interacted_movie_ids)
    
        ngcf_recomm_mids = ngcf_predictor.predict(interacted_items=interacted_movie_ids)
        ngcf_recomm = list(DaumMovies.objects.filter(movieid__in=ngcf_recomm_mids).values())
    
        # context êµ¬ì„±
        context = {
            'ngcf_on': True,
            'movie_list': add_rank(add_past_rating(username=username,
                                                   session_id=session_id,
                                                   recomm_result=ngcf_recomm
                                                   )),
            'watched_movie': interacted_movie_obs,
            'description1': 'NGCF ì¶”ì²œ ì˜í™”',
            'description2': "NGCF ì¶”ì²œê²°ê³¼ì…ë‹ˆë‹¤"
                            "<br><a href='http://127.0.0.1:8000/paper_review/2/'>ë…¼ë¬¸ë¦¬ë·° ë³´ëŸ¬ê°€ê¸°â†—</a>"
        }
        return render(request, "home.html", context=context)
    else:
        context = {
            'movie_list': [],
            'sasrec_on': True,
            'description1': 'SASRec ì¶”ì²œ ì˜í™”',
            'description2': 'ê¸°ë¡ì´ ì—†ì–´ ì¶”ì²œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\nì¸ê¸° ì˜í™”ì—ì„œ í‰ì ì„ ë§¤ê¸°ê±°ë‚˜ í¬ìŠ¤í„° í´ë¦­ ê¸°ë¡ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!'
        }
    return render(request, "home.html", context=context)
```