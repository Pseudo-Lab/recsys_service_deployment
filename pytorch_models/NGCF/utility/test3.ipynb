{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1580/3177861889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngcf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNGCF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_models'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import model\n",
    "from model import NGCF\n",
    "from utility.parser import parse_args\n",
    "\n",
    "import utility.metrics as metrics\n",
    "from utility.load_data import *\n",
    "from utility.batch_test import *\n",
    "args = parse_args()\n",
    "\n",
    "\n",
    "# if args.gpu >= 0 and torch.cuda.is_available():\n",
    "#     device = \"cuda:{}\".format(args.gpu)\n",
    "# else:\n",
    "#     device = \"cpu\"\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "def add_new_user(model, g, data_generator, user_id, interacted_items):\n",
    "    # Add the new user's interactions to the data generator\n",
    "    user_idx = 6041  # Get the index for the new user\n",
    "    data_generator.train_items[user_idx] = interacted_items\n",
    "    data_generator.test_set[user_idx] = []  # New user has no test interactions\n",
    "\n",
    "    # Convert the list of user-item interactions to tensors\n",
    "    users = torch.tensor([user_idx] * len(interacted_items))\n",
    "    pos_items = torch.tensor(interacted_items)\n",
    "    neg_items = torch.tensor([])  # For simplicity, we don't include negative items\n",
    "\n",
    "    # Update the model with the new user's interactions\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    n_batch = len(interacted_items) // args.batch_size + 1  # Adjust batch size accordingly\n",
    "    for epoch in range(args.epoch):\n",
    "        for idx in range(n_batch):\n",
    "            batch_start = idx * args.batch_size\n",
    "            batch_end = (idx + 1) * args.batch_size\n",
    "            batch_users = users[batch_start:batch_end]\n",
    "            batch_pos_items = pos_items[batch_start:batch_end]\n",
    "            batch_neg_items = neg_items  # No negative items for the new user\n",
    "\n",
    "            u_g_embeddings, pos_i_g_embeddings, _ = model(\n",
    "                data_generator.g, \"user\", \"item\", batch_users, batch_pos_items, batch_neg_items\n",
    "            )\n",
    "\n",
    "            batch_loss, _, _ = model.create_bpr_loss(\n",
    "                u_g_embeddings, pos_i_g_embeddings, torch.tensor([])  # No negative items\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Get recommendations for the new user\n",
    "    users_to_test = [user_idx]\n",
    "    ret = test(model, g, users_to_test)\n",
    "    recommendations = ret[\"recommendations\"]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "ngcf_model = NGCF(\n",
    "    data_generator.g, 64, [64,64,64], [0.1,0.1,0.1], [1e-5]\n",
    ").to(device)\n",
    "\n",
    "ngcf_model.load_state_dict(torch.load('NGCF.pkl'))\n",
    "\n",
    "ngcf_model.eval()\n",
    "\n",
    "# user_item_src=[]\n",
    "# user_item_dst=[]\n",
    "\n",
    "# for i in range(3):\n",
    "#     user_item_src.append(6040)\n",
    "#     user_item_dst.append(4)\n",
    "\n",
    "# user_selfs = list(range(6041))\n",
    "# item_selfs = list(range(3706))\n",
    "# data_dict = {\n",
    "#     (\"user\", \"user_self\", \"user\"): (user_selfs, user_selfs),\n",
    "#     (\"item\", \"item_self\", \"item\"): (item_selfs, item_selfs),\n",
    "#     (\"user\", \"ui\", \"item\"): (user_item_src, user_item_dst),\n",
    "#     (\"item\", \"iu\", \"user\"): (user_item_dst, user_item_src),\n",
    "# }\n",
    "# # num_dict = {\"user\": self.n_users, \"item\": self.n_items}\n",
    "# num_dict = {\"user\": 6041, \"item\": 3706}\n",
    "\n",
    "# data_generator.g = dgl.heterograph(data_dict, num_nodes_dict=num_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# new_user_id = 6040  # 예를 들어, 새로운 사용자 ID를 정의합니다.\n",
    "# new_user_interactions = [3, 4, 10]\n",
    "\n",
    "# recommendations = add_new_user(ngcf_model, data_generator.g, data_generator, new_user_id, new_user_interactions)\n",
    "# print(\"Recommended items for the new user:\")\n",
    "# for item_id in recommendations:\n",
    "#     print(\"Item ID:\", item_id)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(self):\n",
    "    if self.batch_size <= self.n_users:\n",
    "        users = rd.sample(self.exist_users, self.batch_size)\n",
    "    else:\n",
    "        users = [\n",
    "            rd.choice(self.exist_users) for _ in range(self.batch_size)\n",
    "        ]\n",
    "\n",
    "    def sample_pos_items_for_u(u, num):\n",
    "        # sample num pos items for u-th user\n",
    "        pos_items = self.train_items[u]\n",
    "        n_pos_items = len(pos_items)\n",
    "        pos_batch = []\n",
    "        while True:\n",
    "            if len(pos_batch) == num:\n",
    "                break\n",
    "            pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0]\n",
    "            pos_i_id = pos_items[pos_id]\n",
    "\n",
    "            if pos_i_id not in pos_batch:\n",
    "                pos_batch.append(pos_i_id)\n",
    "        return pos_batch\n",
    "\n",
    "    def sample_neg_items_for_u(u, num):\n",
    "        # sample num neg items for u-th user\n",
    "        neg_items = []\n",
    "        while True:\n",
    "            if len(neg_items) == num:\n",
    "                break\n",
    "            neg_id = np.random.randint(low=0, high=self.n_items, size=1)[0]\n",
    "            if (\n",
    "                neg_id not in self.train_items[u]\n",
    "                and neg_id not in neg_items\n",
    "            ):\n",
    "                neg_items.append(neg_id)\n",
    "        return neg_items\n",
    "\n",
    "    pos_items, neg_items = [], []\n",
    "    for u in users:\n",
    "        pos_items += sample_pos_items_for_u(u, 1)\n",
    "        neg_items += sample_neg_items_for_u(u, 1)\n",
    "\n",
    "    return users, pos_items, neg_items\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'item': 3706, 'user': 6040},\n",
       "      num_edges={('item', 'item_self', 'item'): 3706, ('item', 'iu', 'user'): 800167, ('user', 'ui', 'item'): 800167, ('user', 'user_self', 'user'): 6040},\n",
       "      metagraph=[('item', 'item', 'item_self'), ('item', 'user', 'iu'), ('user', 'item', 'ui'), ('user', 'user', 'user_self')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator.train_items[6040]=[4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 연결 정보 정의\n",
    "new_user_node = 6040\n",
    "new_user_item_dst = [4,5,6,7]  # 새로운 'item' 노드 ID들\n",
    "\n",
    "new_user_item_src = [new_user_node] * len(new_user_item_dst)\n",
    "\n",
    "\n",
    "\n",
    "# # 새로운 연결을 data_dict에 추가\n",
    "# data_generator.data_dict[(\"user\", \"ui\", \"item\")] = (data_generator.user_item_src + new_user_item_src, data_generator.user_item_dst + new_user_item_dst)\n",
    "# data_generator.data_dict[(\"item\", \"iu\", \"user\")] = (data_generator.user_item_dst + new_user_item_dst, data_generator.user_item_src + new_user_item_src)\n",
    "# data_generator.data_dict[(\"user\", \"user_self\", \"user\")] = \n",
    "\n",
    "#             (\"item\", \"item_self\", \"item\"): (item_selfs, item_selfs),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'item': 3706, 'user': 6040},\n",
       "      num_edges={('item', 'item_self', 'item'): 3706, ('item', 'iu', 'user'): 800167, ('user', 'ui', 'item'): 800167, ('user', 'user_self', 'user'): 6040},\n",
       "      metagraph=[('item', 'item', 'item_self'), ('item', 'user', 'iu'), ('user', 'item', 'ui'), ('user', 'user', 'user_self')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct graph from the train data and add self-loops\n",
    "user_selfs = list(range(6041))\n",
    "item_selfs = list(range(3706))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    (\"user\", \"user_self\", \"user\"): (user_selfs, user_selfs),\n",
    "    (\"item\", \"item_self\", \"item\"): (item_selfs, item_selfs),\n",
    "    (\"user\", \"ui\", \"item\"): (data_generator.user_item_src + new_user_item_src, data_generator.user_item_dst + new_user_item_dst),\n",
    "    (\"item\", \"iu\", \"user\"): (data_generator.user_item_dst + new_user_item_dst, data_generator.user_item_src + new_user_item_src),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dict = {\"user\": 6041, \"item\": 3706}\n",
    "\n",
    "data_generator.g = dgl.heterograph(data_dict, num_nodes_dict=num_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'item': 3706, 'user': 6041},\n",
       "      num_edges={('item', 'item_self', 'item'): 3706, ('item', 'iu', 'user'): 800171, ('user', 'ui', 'item'): 800171, ('user', 'user_self', 'user'): 6041},\n",
       "      metagraph=[('item', 'item', 'item_self'), ('item', 'user', 'iu'), ('user', 'item', 'ui'), ('user', 'user', 'user_self')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample():\n",
    "    users = new_user_item_src\n",
    "\n",
    "    def sample_pos_items_for_u(u, num):\n",
    "        # sample num pos items for u-th user\n",
    "        pos_items = new_user_item_dst\n",
    "        n_pos_items = len(pos_items)\n",
    "        pos_batch = []\n",
    "        while True:\n",
    "            if len(pos_batch) == num:\n",
    "                break\n",
    "            pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0]\n",
    "            pos_i_id = pos_items[pos_id]\n",
    "\n",
    "            if pos_i_id not in pos_batch:\n",
    "                pos_batch.append(pos_i_id)\n",
    "        return pos_batch\n",
    "\n",
    "    def sample_neg_items_for_u(u, num):\n",
    "        # sample num neg items for u-th user\n",
    "        neg_items = []\n",
    "        while True:\n",
    "            if len(neg_items) == num:\n",
    "                break\n",
    "            neg_id = np.random.randint(low=0, high=3707, size=1)[0]\n",
    "            if (\n",
    "                neg_id not in new_user_item_dst\n",
    "                and neg_id not in neg_items\n",
    "            ):\n",
    "                neg_items.append(neg_id)\n",
    "        return neg_items\n",
    "\n",
    "    pos_items, neg_items = [], []\n",
    "    for u in users:\n",
    "        pos_items += sample_pos_items_for_u(u, 1)\n",
    "        neg_items += sample_neg_items_for_u(u, 1)\n",
    "\n",
    "    return users, pos_items, neg_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NGCF(\n",
    "    data_generator.g, 64, [64,64,64], [0.1,0.1,0.1], [1e-5]\n",
    ").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings = model(\n",
    "    data_generator.g, \"user\", \"item\", users, pos_items, neg_items\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14709/1859348913.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m     batch_loss, batch_mf_loss, batch_emb_loss = model.create_bpr_loss(\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mu_g_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_i_g_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_i_g_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/recsys_service_deployment-main_NGCF/recsys_service_deployment-main/pytorch_models/ngcf/model.py\u001b[0m in \u001b[0;36mcreate_bpr_loss\u001b[0;34m(self, users, pos_items, neg_items)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_items\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         ) / 2\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0memb_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmbd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmf_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memb_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epoch):\n",
    "\n",
    "    loss, mf_loss, emb_loss = 0.0, 0.0, 0.0\n",
    "    users, pos_items, neg_items = data_generator.sample()\n",
    "    u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings = model(\n",
    "        data_generator.g, \"user\", \"item\", users, pos_items, neg_items\n",
    "    )\n",
    "    batch_loss, batch_mf_loss, batch_emb_loss = model.create_bpr_loss(\n",
    "        u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings\n",
    "    )\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss += batch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_g_embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users, num_items = data_generator.get_num_users_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
